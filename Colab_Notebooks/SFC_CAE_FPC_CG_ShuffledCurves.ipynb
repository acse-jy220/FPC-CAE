{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"SFC_CAE_FPC_CG_ShuffledCurves.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"3mBN38-pzJRP"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive/')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1hSb7WeDzKL7"},"source":["# !git clone https://github.com/acse-jy220/SFC-CAE-Ready-to-use"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vB2IDPJBzat-"},"source":["%cd gdrive/MyDrive/DISSERTATION/SFC-CAE-AdaptiveFinal/"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sB2BO1dtX_js"},"source":["# !git pull"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"psNEoVIXtirz"},"source":["### Install dependencies"]},{"cell_type":"code","metadata":{"id":"mCAqgswwUqiR"},"source":["modulelist = !pip list                         #This is just to check whether the requirements are already installed\n","if str(modulelist).find(\"vtk\") == -1:          #If vtk is already installed don't start the installation process because it will take a couple minutes to verify that everything is there.\n","  !pip install -e ."],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dp1x1ZtVtn-7"},"source":["### Import useful functions inside this repo, very important, don't forget!!!"]},{"cell_type":"code","metadata":{"id":"Q1O9kBUQzfaO"},"source":["from sfc_cae import *"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wSoW9nfOujMF"},"source":["## (Example) Get the Flow Past Cylinder data `CG_Mesh_new` (2000 snapshots) \n","Try to specify you own `data_dir` !!!!"]},{"cell_type":"code","metadata":{"id":"rRVbp9BbAV5b"},"source":["# !mkdir FPC_Re3900_CG_new\n","# !wget https://www.dropbox.com/sh/aid0yv2685nln51/AADmtVChECW_B85M8O2cDmR0a\n","# !unzip AADmtVChECW_B85M8O2cDmR0a -d './FPC_Re3900_CG_new/'\n","# !rm -rf AADmtVChECW_B85M8O2cDmR0a"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"V-6l2HlzjngO"},"source":["# Specify the folder of the data and load the full_tensors from `vtu` files, or `txt` files, like following, check the folder you specified only contains `vtu` and `txt` files!!!"]},{"cell_type":"markdown","metadata":{"id":"2uUae0wxu6s-"},"source":["### specify your own {DATA_DIR} of vtu files here."]},{"cell_type":"code","metadata":{"id":"q5liu8GegVnP"},"source":["# data_path = 'FPC_Re3900_CG_new/'\n","# vtu_fields = ['Velocity']"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qcQAcXV-Az8s"},"source":["### Specify the `vtu_fields` (a list) of an unadapted mesh to read in, returns:\n","**full_tensor**: The tensor of all `vtu_fields` you specified for all snapshots in the {data_path}, 3-dimension, the first dimension is number of snapshots in that {data_path}, the second is the number of Nodes in each snapshots, the last is number of components in the `vtu_fields`, for example, in this FPC test case,\n","two components for `Velocity`, one for `Pressure`. <br> <br>\n","**coords**: The coordinates of the unadapted mesh Nodes from the `vtu` file, 3-dimension."]},{"cell_type":"code","metadata":{"id":"4e86ipaRVioU"},"source":["# full_tensor, coords, cells = read_in_files(data_path, vtu_fields = vtu_fields)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ejPBE_73Krri"},"source":["For reading tensor from `txt` files, check the `read_in_files` function from `util.py` at https://github.com/acse-jy220/SFC-CAE-Ready-to-use"]},{"cell_type":"markdown","metadata":{"id":"1PxP4LlQO8c5"},"source":["### Save the full tensor in your `google_drive` for further use."]},{"cell_type":"code","metadata":{"id":"Y3EjoOmgO6f9"},"source":["# torch.save(full_tensor, '/content/gdrive/MyDrive/FPC_CG_new_velocity.pt')\n","# torch.save(coords, '/content/gdrive/MyDrive/FPC_CG_new_mesh.pt')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cX9UJ9a1a9qE"},"source":["Or download a premade one from the link in the readme"]},{"cell_type":"markdown","metadata":{"id":"EkaBK5xeHKVJ"},"source":["### Load tensor from google drive"]},{"cell_type":"code","metadata":{"id":"vWh7BX5GjJgt"},"source":["full_tensor = torch.load('./savedtensors/FPC_new_velocity.pt')[1:]\n","coords = torch.load('./savedtensors/FPC_new_mesh.pt')\n","cells = torch.load('./savedtensors/FPC_new_mesh_cells.pt')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rl0obICyPGiM"},"source":["### Generate space-filling-curves from coords (unadapted) of the `vtu` files"]},{"cell_type":"code","metadata":{"id":"Q3q2AkVJkTQ-"},"source":["# ncurves = 20 # specify space-filling curve numbers\n","# # for DG mesh\n","# # space_filling_orderings, invert_space_filling_orderings = get_sfc_curves_from_coords(coords, ncurves)\n","\n","# # for CG mesh, according to Claire's code, we need to input an additional template vtu file to it.\n","# template_vtu = vtktools.vtu(glob.glob(data_path + '*')[0])\n","# space_filling_orderings, invert_space_filling_orderings = get_sfc_curves_from_coords_CG(coords, ncurves, template_vtu)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ALjOk9u5bHGE"},"source":["# #You should probably clean them of duplicates:\n","\n","# nonduplicates = []\n","\n","\n","# for i in range(len(space_filling_orderings)):\n","\n","#   duplicate = False\n","\n","#   for j in range(len(nonduplicates)):\n","#     if np.diff(space_filling_orderings[i],nonduplicates[j]) == 0:\n","#       duplicate = True\n","  \n","#   if not duplicate:\n","#     nonduplicates.append(space_filling_orderings[i])\n","\n","# space_filling_orderings = nonduplicates"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FQT4l4P6elwv"},"source":["# #And regenerate the inverted space filling curves:\n","# nonduplicatesinverse = [np.argsort(i) for i in nonduplicates]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7ZlPAkxszWJi"},"source":["# # see this in get_sfc_curves_from_coords_CG() func in utils.py, find sparse connectivity for CG meshes.\n","# ncolm=0\n","# colm=[]\n","# findm=[0]\n","# for nod in range(coords.shape[0]):\n","#     nodes = template_vtu.GetPointPoints(nod)\n","#     nodes2 = np.sort(nodes) #sort_assed(nodes) \n","#     colm.extend(nodes2[:]) \n","#     nlength = nodes2.shape[0]\n","#     ncolm=ncolm+nlength\n","#     findm.append(ncolm)\n","\n","# colm = np.array(colm)\n","# colm = colm + 1\n","# findm = np.array(findm)\n","# findm = findm + 1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6ePDHfHvyr3P"},"source":["# edge_list = csr_to_edges(findm, colm)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gebM7OnqTlRS"},"source":["#Or load previously compiled ones!\n","\n","import pickle\n","\n","infile = open(\"./savedcurves/956differentfpccurves.pickle\",'rb')\n","space_filling_orderings = pickle.load(infile)\n","infile.close()\n","\n","infile = open(\"./savedcurves/956differentfpcicurves.pickle\",'rb')\n","invert_space_filling_orderings = pickle.load(infile)\n","infile.close()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tNooeHB0zxKK"},"source":["### Print out the filled connectivity by the space-filling curves."]},{"cell_type":"code","metadata":{"id":"lTJ4SMV_zlT-"},"source":["# filled_edges_for_sfcs(edge_list, space_filling_orderings)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hvF8pqqedWZp"},"source":["#visualize the space-filling curve, only works for the FPC example\n","# plot_trace_vtu_2D(coords[space_filling_orderings[0]], 25)\n","countour_plot_vtu_2D(coords[space_filling_orderings[0]], 25, cmap = cmocean.cm.dense_r)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"91x2FnQJ5gNo"},"source":["countour_plot_vtu_2D(coords[space_filling_orderings[930]], 25, cmap = cmocean.cm.dense_r)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HNpswnjiMjFI"},"source":["### Random split the tensor into training_set: valid_set: test_set = 0.8:0.1:0.1 = 8:1:1"]},{"cell_type":"code","metadata":{"id":"d4odlOJDZGUc"},"source":["train_ratio = 0.8\n","valid_ratio = 0.1\n","test_ratio = 0.1 \n","train_index, valid_index, test_index = index_split(train_ratio, valid_ratio, test_ratio, total_num = full_tensor.shape[0])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HnD66ouCqbPp"},"source":["full_set, k, b = standardlize_tensor(full_tensor, lower = -1, upper = 1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"T3WLEQT_eLo3"},"source":["k.detach().numpy()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kCCHuttBJAgX"},"source":["torch.save(k, \"fpc_cg_tk.pt\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"b2JRx4gYeNEu"},"source":["b.detach().numpy()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-y2uT1mJJGzO"},"source":["torch.save(b, \"fpc_cg_tb.pt\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Zw11QTSWqhh1"},"source":["train_set = full_set[train_index - 1]\n","valid_set = full_set[valid_index - 1]\n","test_set = full_set[test_index - 1]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vAXt8JUghZsZ"},"source":["### The following cell is quite vital, as it indicates the parameters for the **autoencoder**\n","\n","`input_size` is the number of Node, for example 20550 <br> `dimension` is the dimension of the data in Vtu file, 2 or 3.<br> `components` is the number of components you are compressing, if the tensor is 2 dimension, then it's default of 1. `self_concat` is chennel copying operation, you could keep it default as 1, or 2 when you have multiple SFCs. <br> `structured`: bool, whether you are training SFC-CAE on a structured mesh or not.<br>`nearest_neighboring`: bool, adding sparse layers or not, suggest to turn on.<br>\n","`dims_letent`: The dimension of the compressed data after applying decoder. <br>\n","`space_filling_orderings`, `invert_space_filling_orderings` : lists of sfc\\inverse_sfc nums, generated by `get_sfc_curves_from_coords` function, or read the orderings from a `csv` file on your own. <br>\n","`activation`: Can be customly defined, but if you not spcify, the activation would be `ReLU()` for structured mesh, and `Tanh()` for unstructured mesh."]},{"cell_type":"code","metadata":{"id":"2pJWVZ4fM5tA"},"source":["# input_size = full_tensor.shape[1]\n","# dimension = 2\n","# if full_tensor.ndim == 2: components = 1\n","# else: components = full_tensor.shape[-1]\n","# self_concat = 1\n","# structured = False\n","# nearest_neighbouring = True #True # shut down this may lead to a slightly poorer performance, but a quicker training spped\n","# dims_latent = 64\n","# activation = nn.Tanh()\n","# variational = False\n","# space_filling_orderings = (mannully spcify it if you didn't generate in the cells before)\n","# invert_space_filling_orderings = "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"f2LcLWgVkL66"},"source":["### The following are just normal Hyperparameters for training, free to tune it yourself."]},{"cell_type":"code","metadata":{"id":"mV_I8qXKi0bd"},"source":["batch_size = 64\n","seed = 27\n","lr = 1e-4\n","n_epochs = 2000\n","weight_decay = 0\n","criterion_type = 'MSE'\n","valid_batch_size = valid_set.shape[0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jStujwHSjKH1"},"source":["train_loader = DataLoader(dataset=train_set, batch_size=batch_size, shuffle=True)\n","valid_loader = DataLoader(dataset=valid_set, batch_size=valid_batch_size, shuffle=True)\n","test_loader = DataLoader(dataset=test_set, batch_size=valid_batch_size, shuffle=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zx3pg7UuabA8"},"source":["coords = torch.Tensor(coords)[:,:2].permute(1,0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"V7s38QsEfBQP"},"source":["input_size = full_tensor.shape[1]\n","dimension = 2\n","if full_tensor.ndim == 2: components = 1\n","else: components = full_tensor.shape[-1]\n","self_concat = 1\n","structured = False\n","nearest_neighbouring = True #True # shut down this may lead to a slightly poorer performance, but a quicker training spped\n","dims_latent = 64\n","activation = nn.Tanh()\n","variational = False"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hDU2eZlDfD93"},"source":["#Create autoencoder \n","autoencoder = SFC_CAE(input_size,\n","                      dimension,\n","                      components,\n","                      structured,\n","                      self_concat,\n","                      True,\n","                      dims_latent,\n","                      space_filling_orderings[:2], \n","                      invert_space_filling_orderings[:2],\n","                      activation,\n","                      variational = variational,\n","                      force_initialising_param=None,\n","                      verbose = False,\n","                      nfclayers = 0,\n","                      smoothinglayers = [[(8,33)],[(32,31),(16,27)]])\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fs79ftdyfbcN"},"source":["# Train\n","autoencoder = train_model(autoencoder, \n","                        train_loader = train_loader,\n","                        valid_loader = valid_loader,\n","                        test_loader = test_loader,\n","                        n_epochs =3000, \n","                        lr = 1e-4, \n","                        seed = seed,\n","                        shuffle = True,\n","                        sfcstoshuffle = space_filling_orderings[:-36],\n","                        isfcstoshuffle = invert_space_filling_orderings[:-36],\n","                        changevalid = True,\n","                        validsfcs = space_filling_orderings[-36:],\n","                        validisfcs = invert_space_filling_orderings[-36:],\n","                        visualize = True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Lxh4vlilkjqu"},"source":["### Other functions need to be add, like convert the result back to `csv`/`vtu` files....."]},{"cell_type":"code","metadata":{"id":"aJ_t-7dOtJwk"},"source":["# added functions to output vtu files from reconstruct\n","model_device = torch.device('cuda')\n","autoencoder = autoencoder.to(model_device)\n","save_path = 'reconstructed_FPC_CG'\n","import os\n","os.system(F'mkdir -p {save_path}')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"R4zZZjIbkwpo"},"source":["data_path = 'FPC_Re3900_CG_new/'\n","vtu_fields = ['Velocity']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"72pKAgeHk2cu"},"source":["autoencoder.set_sfcs(space_filling_orderings[930:932],invert_space_filling_orderings[930:932]) #Change the space filling orderings to unseen ones"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"D2Iq4oFq5W7H"},"source":["# torch.save(autoencoder.state_dict, \"FPC_Trained_Model.pth\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"61-HMk03HTIG"},"source":["result_vtu_to_vtu(data_path, save_path, vtu_fields, autoencoder, k.detach().numpy(), b.detach().numpy(), model_device = model_device)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BUEsKMa-QDle"},"source":["Please find the reconstructed files in `reconstructed` folder"]}]}