{'data_dir': '/rds/general/user/jy220/home/tensors/', 'data_type': 'tensors', 'vtu_fields': 'Component1::ComponentMassFractionPhase1, phase1::Velocity', 'variational': 'False', 'structured': 'False', 'changing_lr': 'False', 'self_concat': '2', 'dimension': '3', 'sfc_nums': '3', 'components': '4', 'nearest_neighbouring': 'True', 'dims_latent': '256', 'activation': 'Tanh', 'sfc_file': '/rds/general/user/jy220/home/SFC-CAE-Ready-to-use/sfcs.pt', 'inv_sfc_file': '/rds/general/user/jy220/home/SFC-CAE-Ready-to-use/inv_sfcs.pt', 'coords_file': '/rds/general/user/jy220/home/SFC-CAE-Ready-to-use/coords.pt', 'cells_file': '/rds/general/user/jy220/home/SFC-CAE-Ready-to-use/cells.npy', 'state_load': '/rds/general/user/jy220/home/results/Variational_False_Changelr_False_Latent_256_Nearest_neighbouring_True_SFC_nums_3_startlr_0.0005_n_epoches_200_dict.pth', 'batch_size': '16', 'lr': '0.0005', 'n_epoches': '200', 'seed': '15', 'visualize': 'False', 'reconstructed_path': 'None', 'reconstruct_start_index': '0', 'reconstruct_end_index': '50', 'save_path': '/rds/general/user/jy220/home/new_results/'}
[[ 2.50825269e-01 -1.67256990e-02 -1.22268730e-03]
 [ 2.38611959e-01 -5.50627777e-03 -5.06451913e-03]
 [ 2.39454874e-01 -1.59563257e-02  3.96778323e-03]
 ...
 [ 9.11361096e+00 -2.21908381e-02  2.22384902e-03]
 [ 9.11847310e+00 -2.84346931e-02 -2.34839590e-04]
 [ 9.11039661e+00 -2.51498573e-02 -8.70661044e-03]]
{'tetra': array([[      0,       1,       2,       3],
       [      4,       5,       6,       7],
       [      8,       9,      10,      11],
       ...,
       [1342744, 1342745, 1342746, 1342747],
       [1342748, 1342749, 1342750, 1342751],
       [1342752, 1342753, 1342754, 1342755]])}
structured  False 
 activation  Tanh() 
 self concat  2 
 sfc_nums  3 

dims_latent  256 
 components  4 
 nearest_neighbouring  True 

visualize  False 
 sample number  1706 

reading sfc nums......
[array([  41684,   41685,   41674, ..., 1235560, 1235564, 1235558]), array([954289, 954290, 954291, ..., 420685, 420687, 420688]), array([  40156,   40155,   40158, ..., 1123478, 1123475, 1123467])]
reading inverse sfc nums......
[array([   8146,    8145,    8144, ..., 1274444, 1274445, 1273166]), array([547280, 547283, 593037, ..., 933933, 933932, 864488]), array([ 66437,  66439, 122512, ..., 459416, 415130, 459418])]
Computing min and max......

tk:  tensor([0.7581, 0.0418, 0.1840, 0.1464], dtype=torch.float64) 

tb:  tensor([-0.3816, -0.3618, -0.0308,  0.1446], dtype=torch.float64) 

length of train set: 1505 

length of valid set: 100 

length of test set: 101 

torch device num: 4 

Let's use 4 GPUs!
epoch 200 starting......
Epoch:  200 | train loss: 1.162962e-02 | valid loss: 1.104888e-02 
      	| train loss (relative): 2.850903e-01 | valid loss (relative): 2.699273e-01 
Epoch 200 use: 405.03 second.

epoch 201 starting......
Epoch:  201 | train loss: 1.162093e-02 | valid loss: 1.104339e-02 
      	| train loss (relative): 2.852211e-01 | valid loss (relative): 2.702124e-01 
Epoch 201 use: 399.95 second.

epoch 202 starting......
Epoch:  202 | train loss: 1.162234e-02 | valid loss: 1.104590e-02 
      	| train loss (relative): 2.840995e-01 | valid loss (relative): 2.701774e-01 
Epoch 202 use: 348.48 second.

epoch 203 starting......
Epoch:  203 | train loss: 1.162155e-02 | valid loss: 1.104587e-02 
      	| train loss (relative): 2.852141e-01 | valid loss (relative): 2.705916e-01 
Epoch 203 use: 324.90 second.

epoch 204 starting......
Epoch:  204 | train loss: 1.161818e-02 | valid loss: 1.104769e-02 
      	| train loss (relative): 2.843291e-01 | valid loss (relative): 2.705643e-01 
Epoch 204 use: 373.36 second.

epoch 205 starting......
Epoch:  205 | train loss: 1.162063e-02 | valid loss: 1.104312e-02 
      	| train loss (relative): 2.862847e-01 | valid loss (relative): 2.708107e-01 
Epoch 205 use: 384.49 second.

epoch 206 starting......
Epoch:  206 | train loss: 1.162331e-02 | valid loss: 1.105462e-02 
      	| train loss (relative): 2.845878e-01 | valid loss (relative): 2.717601e-01 
Epoch 206 use: 351.20 second.

epoch 207 starting......
Epoch:  207 | train loss: 1.162331e-02 | valid loss: 1.106094e-02 
      	| train loss (relative): 2.868809e-01 | valid loss (relative): 2.731060e-01 
Epoch 207 use: 368.67 second.

epoch 208 starting......
Epoch:  208 | train loss: 1.162204e-02 | valid loss: 1.105502e-02 
      	| train loss (relative): 2.847815e-01 | valid loss (relative): 2.712375e-01 
Epoch 208 use: 359.43 second.

epoch 209 starting......
Epoch:  209 | train loss: 1.161773e-02 | valid loss: 1.104935e-02 
      	| train loss (relative): 2.841549e-01 | valid loss (relative): 2.713925e-01 
Epoch 209 use: 369.63 second.

epoch 210 starting......
Epoch:  210 | train loss: 1.162149e-02 | valid loss: 1.106196e-02 
      	| train loss (relative): 2.855971e-01 | valid loss (relative): 2.726738e-01 
Epoch 210 use: 340.73 second.

epoch 211 starting......
Epoch:  211 | train loss: 1.162208e-02 | valid loss: 1.105046e-02 
      	| train loss (relative): 2.870333e-01 | valid loss (relative): 2.713015e-01 
Epoch 211 use: 363.39 second.

epoch 212 starting......
Epoch:  212 | train loss: 1.161772e-02 | valid loss: 1.104695e-02 
      	| train loss (relative): 2.848215e-01 | valid loss (relative): 2.705425e-01 
Epoch 212 use: 327.95 second.

epoch 213 starting......
Epoch:  213 | train loss: 1.161844e-02 | valid loss: 1.104865e-02 
      	| train loss (relative): 2.849867e-01 | valid loss (relative): 2.709458e-01 
Epoch 213 use: 320.20 second.

epoch 214 starting......
Epoch:  214 | train loss: 1.161900e-02 | valid loss: 1.104775e-02 
      	| train loss (relative): 2.844528e-01 | valid loss (relative): 2.719113e-01 
Epoch 214 use: 367.18 second.

epoch 215 starting......
Epoch:  215 | train loss: 1.161798e-02 | valid loss: 1.105685e-02 
      	| train loss (relative): 2.837460e-01 | valid loss (relative): 2.722487e-01 
Epoch 215 use: 332.36 second.

epoch 216 starting......
Epoch:  216 | train loss: 1.161972e-02 | valid loss: 1.105947e-02 
      	| train loss (relative): 2.846273e-01 | valid loss (relative): 2.718560e-01 
Epoch 216 use: 326.19 second.

epoch 217 starting......
Epoch:  217 | train loss: 1.161891e-02 | valid loss: 1.105844e-02 
      	| train loss (relative): 2.852557e-01 | valid loss (relative): 2.715161e-01 
Epoch 217 use: 331.26 second.

epoch 218 starting......
Epoch:  218 | train loss: 1.161791e-02 | valid loss: 1.104811e-02 
      	| train loss (relative): 2.853001e-01 | valid loss (relative): 2.706637e-01 
Epoch 218 use: 343.75 second.

epoch 219 starting......
Epoch:  219 | train loss: 1.161755e-02 | valid loss: 1.105446e-02 
      	| train loss (relative): 2.835986e-01 | valid loss (relative): 2.717478e-01 
Epoch 219 use: 331.91 second.

epoch 220 starting......
Epoch:  220 | train loss: 1.161851e-02 | valid loss: 1.106274e-02 
      	| train loss (relative): 2.847141e-01 | valid loss (relative): 2.725714e-01 
Epoch 220 use: 330.92 second.

epoch 221 starting......
Epoch:  221 | train loss: 1.161746e-02 | valid loss: 1.105358e-02 
      	| train loss (relative): 2.854361e-01 | valid loss (relative): 2.713258e-01 
Epoch 221 use: 327.07 second.

epoch 222 starting......
Epoch:  222 | train loss: 1.161996e-02 | valid loss: 1.105981e-02 
      	| train loss (relative): 2.840649e-01 | valid loss (relative): 2.719867e-01 
Epoch 222 use: 320.80 second.

epoch 223 starting......
Epoch:  223 | train loss: 1.161730e-02 | valid loss: 1.105421e-02 
      	| train loss (relative): 2.844270e-01 | valid loss (relative): 2.721704e-01 
Epoch 223 use: 310.80 second.

epoch 224 starting......
Epoch:  224 | train loss: 1.161814e-02 | valid loss: 1.105413e-02 
      	| train loss (relative): 2.852284e-01 | valid loss (relative): 2.720263e-01 
Epoch 224 use: 337.83 second.

epoch 225 starting......
Epoch:  225 | train loss: 1.161839e-02 | valid loss: 1.105549e-02 
      	| train loss (relative): 2.842015e-01 | valid loss (relative): 2.714080e-01 
Epoch 225 use: 327.63 second.

epoch 226 starting......
Epoch:  226 | train loss: 1.161801e-02 | valid loss: 1.104840e-02 
      	| train loss (relative): 2.849751e-01 | valid loss (relative): 2.711610e-01 
Epoch 226 use: 362.88 second.

epoch 227 starting......
Epoch:  227 | train loss: 1.161919e-02 | valid loss: 1.105325e-02 
      	| train loss (relative): 2.840539e-01 | valid loss (relative): 2.717731e-01 
Epoch 227 use: 353.48 second.

epoch 228 starting......
Epoch:  228 | train loss: 1.162722e-02 | valid loss: 1.107890e-02 
      	| train loss (relative): 2.877851e-01 | valid loss (relative): 2.688927e-01 
Epoch 228 use: 427.44 second.

epoch 229 starting......
Epoch:  229 | train loss: 1.162445e-02 | valid loss: 1.104235e-02 
      	| train loss (relative): 2.854736e-01 | valid loss (relative): 2.698812e-01 
Epoch 229 use: 372.04 second.

epoch 230 starting......
Epoch:  230 | train loss: 1.162088e-02 | valid loss: 1.104203e-02 
      	| train loss (relative): 2.840386e-01 | valid loss (relative): 2.690196e-01 
Epoch 230 use: 381.53 second.

epoch 231 starting......
Epoch:  231 | train loss: 1.161646e-02 | valid loss: 1.105051e-02 
      	| train loss (relative): 2.842580e-01 | valid loss (relative): 2.705235e-01 
Epoch 231 use: 338.50 second.

epoch 232 starting......
Epoch:  232 | train loss: 1.161919e-02 | valid loss: 1.105032e-02 
      	| train loss (relative): 2.838592e-01 | valid loss (relative): 2.701878e-01 
Epoch 232 use: 371.68 second.

epoch 233 starting......
Epoch:  233 | train loss: 1.162200e-02 | valid loss: 1.104779e-02 
      	| train loss (relative): 2.855789e-01 | valid loss (relative): 2.705729e-01 
Epoch 233 use: 364.40 second.

epoch 234 starting......
Epoch:  234 | train loss: 1.161864e-02 | valid loss: 1.105313e-02 
      	| train loss (relative): 2.839770e-01 | valid loss (relative): 2.712443e-01 
Epoch 234 use: 329.33 second.

epoch 235 starting......
Epoch:  235 | train loss: 1.161583e-02 | valid loss: 1.105286e-02 
      	| train loss (relative): 2.850094e-01 | valid loss (relative): 2.709720e-01 
Epoch 235 use: 322.47 second.

epoch 236 starting......
Epoch:  236 | train loss: 1.161917e-02 | valid loss: 1.105419e-02 
      	| train loss (relative): 2.844816e-01 | valid loss (relative): 2.716756e-01 
Epoch 236 use: 351.12 second.

epoch 237 starting......
Epoch:  237 | train loss: 1.162492e-02 | valid loss: 1.106326e-02 
      	| train loss (relative): 2.869097e-01 | valid loss (relative): 2.728264e-01 
Epoch 237 use: 372.96 second.

epoch 238 starting......
Epoch:  238 | train loss: 1.161769e-02 | valid loss: 1.105227e-02 
      	| train loss (relative): 2.852320e-01 | valid loss (relative): 2.713509e-01 
Epoch 238 use: 364.90 second.

epoch 239 starting......
Epoch:  239 | train loss: 1.161691e-02 | valid loss: 1.105506e-02 
      	| train loss (relative): 2.846290e-01 | valid loss (relative): 2.711077e-01 
Epoch 239 use: 350.63 second.

epoch 240 starting......
Epoch:  240 | train loss: 1.162867e-02 | valid loss: 1.106346e-02 
      	| train loss (relative): 2.866516e-01 | valid loss (relative): 2.728857e-01 
Epoch 240 use: 365.91 second.

epoch 241 starting......
Epoch:  241 | train loss: 1.162185e-02 | valid loss: 1.105260e-02 
      	| train loss (relative): 2.855407e-01 | valid loss (relative): 2.705184e-01 
Epoch 241 use: 422.49 second.

epoch 242 starting......
Epoch:  242 | train loss: 1.161886e-02 | valid loss: 1.104758e-02 
      	| train loss (relative): 2.848392e-01 | valid loss (relative): 2.706451e-01 
Epoch 242 use: 331.83 second.

epoch 243 starting......
Epoch:  243 | train loss: 1.161751e-02 | valid loss: 1.104941e-02 
      	| train loss (relative): 2.854594e-01 | valid loss (relative): 2.704400e-01 
Epoch 243 use: 324.12 second.

epoch 244 starting......
Epoch:  244 | train loss: 1.161884e-02 | valid loss: 1.104770e-02 
      	| train loss (relative): 2.838095e-01 | valid loss (relative): 2.702045e-01 
Epoch 244 use: 325.65 second.

epoch 245 starting......
Epoch:  245 | train loss: 1.161602e-02 | valid loss: 1.105165e-02 
      	| train loss (relative): 2.843686e-01 | valid loss (relative): 2.713787e-01 
Epoch 245 use: 343.94 second.

epoch 246 starting......
Epoch:  246 | train loss: 1.161717e-02 | valid loss: 1.106169e-02 
      	| train loss (relative): 2.846090e-01 | valid loss (relative): 2.726743e-01 
Epoch 246 use: 329.56 second.

epoch 247 starting......
Epoch:  247 | train loss: 1.162125e-02 | valid loss: 1.105680e-02 
      	| train loss (relative): 2.854300e-01 | valid loss (relative): 2.718024e-01 
Epoch 247 use: 327.93 second.

epoch 248 starting......
Epoch:  248 | train loss: 1.161598e-02 | valid loss: 1.104899e-02 
      	| train loss (relative): 2.852174e-01 | valid loss (relative): 2.709382e-01 
Epoch 248 use: 360.04 second.

epoch 249 starting......
Epoch:  249 | train loss: 1.161923e-02 | valid loss: 1.105679e-02 
      	| train loss (relative): 2.836453e-01 | valid loss (relative): 2.713297e-01 
Epoch 249 use: 335.39 second.

epoch 250 starting......
Epoch:  250 | train loss: 1.161938e-02 | valid loss: 1.105107e-02 
      	| train loss (relative): 2.854529e-01 | valid loss (relative): 2.721312e-01 
Epoch 250 use: 329.74 second.

epoch 251 starting......
Epoch:  251 | train loss: 1.161957e-02 | valid loss: 1.105831e-02 
      	| train loss (relative): 2.846054e-01 | valid loss (relative): 2.720169e-01 
Epoch 251 use: 326.21 second.

epoch 252 starting......
Epoch:  252 | train loss: 1.161769e-02 | valid loss: 1.104683e-02 
      	| train loss (relative): 2.852234e-01 | valid loss (relative): 2.709608e-01 
Epoch 252 use: 349.04 second.

epoch 253 starting......
Epoch:  253 | train loss: 1.161766e-02 | valid loss: 1.104887e-02 
      	| train loss (relative): 2.848574e-01 | valid loss (relative): 2.702640e-01 
Epoch 253 use: 323.71 second.

epoch 254 starting......
Epoch:  254 | train loss: 1.161852e-02 | valid loss: 1.104933e-02 
      	| train loss (relative): 2.845235e-01 | valid loss (relative): 2.712002e-01 
Epoch 254 use: 348.76 second.

epoch 255 starting......
Epoch:  255 | train loss: 1.161804e-02 | valid loss: 1.105253e-02 
      	| train loss (relative): 2.843310e-01 | valid loss (relative): 2.710998e-01 
Epoch 255 use: 346.22 second.

epoch 256 starting......
Epoch:  256 | train loss: 1.161682e-02 | valid loss: 1.105422e-02 
      	| train loss (relative): 2.839221e-01 | valid loss (relative): 2.710271e-01 
Epoch 256 use: 330.32 second.

epoch 257 starting......
Epoch:  257 | train loss: 1.162079e-02 | valid loss: 1.104030e-02 
      	| train loss (relative): 2.860672e-01 | valid loss (relative): 2.696894e-01 
Epoch 257 use: 329.37 second.

epoch 258 starting......
Epoch:  258 | train loss: 1.161828e-02 | valid loss: 1.105072e-02 
      	| train loss (relative): 2.838851e-01 | valid loss (relative): 2.711399e-01 
Epoch 258 use: 390.22 second.

epoch 259 starting......
Epoch:  259 | train loss: 1.161925e-02 | valid loss: 1.104814e-02 
      	| train loss (relative): 2.851594e-01 | valid loss (relative): 2.735100e-01 
Epoch 259 use: 358.60 second.

epoch 260 starting......
Epoch:  260 | train loss: 1.161860e-02 | valid loss: 1.105267e-02 
      	| train loss (relative): 2.846208e-01 | valid loss (relative): 2.720285e-01 
Epoch 260 use: 336.06 second.

epoch 261 starting......
Epoch:  261 | train loss: 1.162020e-02 | valid loss: 1.115662e-02 
      	| train loss (relative): 2.870109e-01 | valid loss (relative): 2.774355e-01 
Epoch 261 use: 362.33 second.

epoch 262 starting......
Epoch:  262 | train loss: 1.163419e-02 | valid loss: 1.104616e-02 
      	| train loss (relative): 2.855622e-01 | valid loss (relative): 2.696453e-01 
Epoch 262 use: 328.06 second.

epoch 263 starting......
Epoch:  263 | train loss: 1.161892e-02 | valid loss: 1.105208e-02 
      	| train loss (relative): 2.834216e-01 | valid loss (relative): 2.704727e-01 
Epoch 263 use: 363.52 second.

epoch 264 starting......
Epoch:  264 | train loss: 1.161707e-02 | valid loss: 1.104708e-02 
      	| train loss (relative): 2.854604e-01 | valid loss (relative): 2.706284e-01 
Epoch 264 use: 331.11 second.

epoch 265 starting......
Epoch:  265 | train loss: 1.161976e-02 | valid loss: 1.104825e-02 
      	| train loss (relative): 2.841802e-01 | valid loss (relative): 2.695925e-01 
Epoch 265 use: 348.37 second.

epoch 266 starting......
Epoch:  266 | train loss: 1.161756e-02 | valid loss: 1.105766e-02 
      	| train loss (relative): 2.833616e-01 | valid loss (relative): 2.721516e-01 
Epoch 266 use: 357.01 second.

epoch 267 starting......
Epoch:  267 | train loss: 1.162312e-02 | valid loss: 1.106088e-02 
      	| train loss (relative): 2.867031e-01 | valid loss (relative): 2.720481e-01 
Epoch 267 use: 365.08 second.

epoch 268 starting......
Epoch:  268 | train loss: 1.162013e-02 | valid loss: 1.105548e-02 
      	| train loss (relative): 2.857884e-01 | valid loss (relative): 2.713503e-01 
Epoch 268 use: 375.54 second.

epoch 269 starting......
Epoch:  269 | train loss: 1.161952e-02 | valid loss: 1.105113e-02 
      	| train loss (relative): 2.841016e-01 | valid loss (relative): 2.709327e-01 
Epoch 269 use: 321.42 second.

epoch 270 starting......
Epoch:  270 | train loss: 1.161742e-02 | valid loss: 1.105644e-02 
      	| train loss (relative): 2.845921e-01 | valid loss (relative): 2.721325e-01 
Epoch 270 use: 400.68 second.

epoch 271 starting......
Epoch:  271 | train loss: 1.161645e-02 | valid loss: 1.104723e-02 
      	| train loss (relative): 2.852680e-01 | valid loss (relative): 2.703304e-01 
Epoch 271 use: 328.52 second.

epoch 272 starting......
Epoch:  272 | train loss: 1.161852e-02 | valid loss: 1.105030e-02 
      	| train loss (relative): 2.841463e-01 | valid loss (relative): 2.714477e-01 
Epoch 272 use: 323.63 second.

epoch 273 starting......
Epoch:  273 | train loss: 1.161969e-02 | valid loss: 1.105091e-02 
      	| train loss (relative): 2.845549e-01 | valid loss (relative): 2.708966e-01 
Epoch 273 use: 326.50 second.

epoch 274 starting......
Epoch:  274 | train loss: 1.161966e-02 | valid loss: 1.105060e-02 
      	| train loss (relative): 2.849269e-01 | valid loss (relative): 2.702709e-01 
Epoch 274 use: 329.68 second.

epoch 275 starting......
Epoch:  275 | train loss: 1.161681e-02 | valid loss: 1.105988e-02 
      	| train loss (relative): 2.847376e-01 | valid loss (relative): 2.718489e-01 
Epoch 275 use: 345.62 second.

epoch 276 starting......
Epoch:  276 | train loss: 1.162730e-02 | valid loss: 1.106749e-02 
      	| train loss (relative): 2.875472e-01 | valid loss (relative): 2.718350e-01 
Epoch 276 use: 342.78 second.

epoch 277 starting......
Epoch:  277 | train loss: 1.163183e-02 | valid loss: 1.105670e-02 
      	| train loss (relative): 2.875855e-01 | valid loss (relative): 2.720666e-01 
Epoch 277 use: 329.61 second.

epoch 278 starting......
Epoch:  278 | train loss: 1.162672e-02 | valid loss: 1.104774e-02 
      	| train loss (relative): 2.855521e-01 | valid loss (relative): 2.706748e-01 
Epoch 278 use: 330.46 second.

epoch 279 starting......
Epoch:  279 | train loss: 1.161709e-02 | valid loss: 1.104703e-02 
      	| train loss (relative): 2.844601e-01 | valid loss (relative): 2.707008e-01 
Epoch 279 use: 332.86 second.

epoch 280 starting......
Epoch:  280 | train loss: 1.161835e-02 | valid loss: 1.105260e-02 
      	| train loss (relative): 2.837627e-01 | valid loss (relative): 2.711903e-01 
Epoch 280 use: 379.20 second.

epoch 281 starting......
Epoch:  281 | train loss: 1.161849e-02 | valid loss: 1.105575e-02 
      	| train loss (relative): 2.842385e-01 | valid loss (relative): 2.721453e-01 
Epoch 281 use: 365.16 second.

epoch 282 starting......
Epoch:  282 | train loss: 1.161815e-02 | valid loss: 1.105399e-02 
      	| train loss (relative): 2.850191e-01 | valid loss (relative): 2.708459e-01 
Epoch 282 use: 411.74 second.

epoch 283 starting......
Epoch:  283 | train loss: 1.161832e-02 | valid loss: 1.105129e-02 
      	| train loss (relative): 2.846554e-01 | valid loss (relative): 2.710813e-01 
Epoch 283 use: 375.50 second.

epoch 284 starting......
Epoch:  284 | train loss: 1.161935e-02 | valid loss: 1.105805e-02 
      	| train loss (relative): 2.841301e-01 | valid loss (relative): 2.717108e-01 
Epoch 284 use: 329.47 second.

epoch 285 starting......
Epoch:  285 | train loss: 1.161896e-02 | valid loss: 1.105149e-02 
      	| train loss (relative): 2.848682e-01 | valid loss (relative): 2.703625e-01 
Epoch 285 use: 341.90 second.

epoch 286 starting......
Epoch:  286 | train loss: 1.162256e-02 | valid loss: 1.104885e-02 
      	| train loss (relative): 2.843562e-01 | valid loss (relative): 2.702511e-01 
Epoch 286 use: 319.59 second.

epoch 287 starting......
Epoch:  287 | train loss: 1.162064e-02 | valid loss: 1.104623e-02 
      	| train loss (relative): 2.857291e-01 | valid loss (relative): 2.705950e-01 
Epoch 287 use: 331.08 second.

epoch 288 starting......
Epoch:  288 | train loss: 1.162012e-02 | valid loss: 1.104194e-02 
      	| train loss (relative): 2.849309e-01 | valid loss (relative): 2.696872e-01 
Epoch 288 use: 328.39 second.

epoch 289 starting......
Epoch:  289 | train loss: 1.161941e-02 | valid loss: 1.105189e-02 
      	| train loss (relative): 2.828855e-01 | valid loss (relative): 2.709420e-01 
Epoch 289 use: 358.92 second.

epoch 290 starting......
Epoch:  290 | train loss: 1.161756e-02 | valid loss: 1.104901e-02 
      	| train loss (relative): 2.850101e-01 | valid loss (relative): 2.704091e-01 
Epoch 290 use: 363.63 second.

epoch 291 starting......
Epoch:  291 | train loss: 1.161739e-02 | valid loss: 1.104843e-02 
      	| train loss (relative): 2.842091e-01 | valid loss (relative): 2.708001e-01 
Epoch 291 use: 331.20 second.

epoch 292 starting......
Epoch:  292 | train loss: 1.161789e-02 | valid loss: 1.105509e-02 
      	| train loss (relative): 2.840346e-01 | valid loss (relative): 2.710515e-01 
Epoch 292 use: 346.96 second.

epoch 293 starting......
Epoch:  293 | train loss: 1.162048e-02 | valid loss: 1.105921e-02 
      	| train loss (relative): 2.840580e-01 | valid loss (relative): 2.720741e-01 
Epoch 293 use: 359.56 second.

epoch 294 starting......
Epoch:  294 | train loss: 1.161819e-02 | valid loss: 1.105784e-02 
      	| train loss (relative): 2.843484e-01 | valid loss (relative): 2.730192e-01 
Epoch 294 use: 435.30 second.

epoch 295 starting......
Epoch:  295 | train loss: 1.162101e-02 | valid loss: 1.105468e-02 
      	| train loss (relative): 2.873158e-01 | valid loss (relative): 2.722353e-01 
Epoch 295 use: 400.71 second.

epoch 296 starting......
Epoch:  296 | train loss: 1.162015e-02 | valid loss: 1.105398e-02 
      	| train loss (relative): 2.844159e-01 | valid loss (relative): 2.707458e-01 
Epoch 296 use: 421.56 second.

epoch 297 starting......
Epoch:  297 | train loss: 1.161930e-02 | valid loss: 1.105962e-02 
      	| train loss (relative): 2.843125e-01 | valid loss (relative): 2.718416e-01 
Epoch 297 use: 377.25 second.

epoch 298 starting......
Epoch:  298 | train loss: 1.161820e-02 | valid loss: 1.105067e-02 
      	| train loss (relative): 2.843367e-01 | valid loss (relative): 2.711545e-01 
Epoch 298 use: 449.89 second.

epoch 299 starting......
Epoch:  299 | train loss: 1.161727e-02 | valid loss: 1.105005e-02 
      	| train loss (relative): 2.843705e-01 | valid loss (relative): 2.710761e-01 
Epoch 299 use: 434.13 second.

epoch 300 starting......
Epoch:  300 | train loss: 1.162113e-02 | valid loss: 1.104473e-02 
      	| train loss (relative): 2.851184e-01 | valid loss (relative): 2.703755e-01 
Epoch 300 use: 385.50 second.

epoch 301 starting......
Epoch:  301 | train loss: 1.161960e-02 | valid loss: 1.106774e-02 
      	| train loss (relative): 2.829436e-01 | valid loss (relative): 2.725530e-01 
Epoch 301 use: 384.20 second.

epoch 302 starting......
Epoch:  302 | train loss: 1.162036e-02 | valid loss: 1.104887e-02 
      	| train loss (relative): 2.862495e-01 | valid loss (relative): 2.708775e-01 
Epoch 302 use: 358.24 second.

epoch 303 starting......
Epoch:  303 | train loss: 1.162148e-02 | valid loss: 1.104561e-02 
      	| train loss (relative): 2.849632e-01 | valid loss (relative): 2.696342e-01 
Epoch 303 use: 358.39 second.

epoch 304 starting......
Epoch:  304 | train loss: 1.161750e-02 | valid loss: 1.105023e-02 
      	| train loss (relative): 2.842390e-01 | valid loss (relative): 2.707917e-01 
Epoch 304 use: 344.00 second.

epoch 305 starting......
Epoch:  305 | train loss: 1.161971e-02 | valid loss: 1.105792e-02 
      	| train loss (relative): 2.857810e-01 | valid loss (relative): 2.713215e-01 
Epoch 305 use: 361.24 second.

epoch 306 starting......
Epoch:  306 | train loss: 1.161958e-02 | valid loss: 1.105610e-02 
      	| train loss (relative): 2.844314e-01 | valid loss (relative): 2.711670e-01 
Epoch 306 use: 336.44 second.

epoch 307 starting......
Epoch:  307 | train loss: 1.161858e-02 | valid loss: 1.104587e-02 
      	| train loss (relative): 2.858863e-01 | valid loss (relative): 2.700260e-01 
Epoch 307 use: 393.39 second.

epoch 308 starting......
Epoch:  308 | train loss: 1.161887e-02 | valid loss: 1.105178e-02 
      	| train loss (relative): 2.841046e-01 | valid loss (relative): 2.709481e-01 
Epoch 308 use: 344.36 second.

epoch 309 starting......
Epoch:  309 | train loss: 1.162081e-02 | valid loss: 1.105331e-02 
      	| train loss (relative): 2.842267e-01 | valid loss (relative): 2.721233e-01 
Epoch 309 use: 358.29 second.

epoch 310 starting......
Epoch:  310 | train loss: 1.161755e-02 | valid loss: 1.106250e-02 
      	| train loss (relative): 2.843898e-01 | valid loss (relative): 2.720704e-01 
Epoch 310 use: 332.37 second.

epoch 311 starting......
Epoch:  311 | train loss: 1.162325e-02 | valid loss: 1.104732e-02 
      	| train loss (relative): 2.875306e-01 | valid loss (relative): 2.705938e-01 
Epoch 311 use: 351.50 second.

epoch 312 starting......
Epoch:  312 | train loss: 1.162418e-02 | valid loss: 1.104712e-02 
      	| train loss (relative): 2.860496e-01 | valid loss (relative): 2.705040e-01 
Epoch 312 use: 361.80 second.

epoch 313 starting......
Epoch:  313 | train loss: 1.162286e-02 | valid loss: 1.105727e-02 
      	| train loss (relative): 2.833764e-01 | valid loss (relative): 2.706275e-01 
Epoch 313 use: 344.33 second.

epoch 314 starting......
Epoch:  314 | train loss: 1.162021e-02 | valid loss: 1.105237e-02 
      	| train loss (relative): 2.848030e-01 | valid loss (relative): 2.715563e-01 
Epoch 314 use: 378.70 second.

epoch 315 starting......
Epoch:  315 | train loss: 1.161667e-02 | valid loss: 1.104727e-02 
      	| train loss (relative): 2.848777e-01 | valid loss (relative): 2.701870e-01 
Epoch 315 use: 327.08 second.

epoch 316 starting......
Epoch:  316 | train loss: 1.161951e-02 | valid loss: 1.105920e-02 
      	| train loss (relative): 2.835587e-01 | valid loss (relative): 2.707495e-01 
Epoch 316 use: 354.40 second.

epoch 317 starting......
Epoch:  317 | train loss: 1.161870e-02 | valid loss: 1.104779e-02 
      	| train loss (relative): 2.856763e-01 | valid loss (relative): 2.707623e-01 
Epoch 317 use: 334.09 second.

epoch 318 starting......
Epoch:  318 | train loss: 1.161865e-02 | valid loss: 1.105812e-02 
      	| train loss (relative): 2.848761e-01 | valid loss (relative): 2.726637e-01 
Epoch 318 use: 365.95 second.

epoch 319 starting......
Epoch:  319 | train loss: 1.162011e-02 | valid loss: 1.105131e-02 
      	| train loss (relative): 2.862058e-01 | valid loss (relative): 2.710963e-01 
Epoch 319 use: 340.82 second.

epoch 320 starting......
Epoch:  320 | train loss: 1.161882e-02 | valid loss: 1.105301e-02 
      	| train loss (relative): 2.843629e-01 | valid loss (relative): 2.717220e-01 
Epoch 320 use: 319.71 second.

epoch 321 starting......
Epoch:  321 | train loss: 1.161921e-02 | valid loss: 1.104887e-02 
      	| train loss (relative): 2.857507e-01 | valid loss (relative): 2.708181e-01 
Epoch 321 use: 340.19 second.

epoch 322 starting......
Epoch:  322 | train loss: 1.161942e-02 | valid loss: 1.104715e-02 
      	| train loss (relative): 2.845680e-01 | valid loss (relative): 2.708679e-01 
Epoch 322 use: 339.05 second.

epoch 323 starting......
Epoch:  323 | train loss: 1.161775e-02 | valid loss: 1.105450e-02 
      	| train loss (relative): 2.841649e-01 | valid loss (relative): 2.715310e-01 
Epoch 323 use: 374.69 second.

epoch 324 starting......
Epoch:  324 | train loss: 1.161962e-02 | valid loss: 1.104898e-02 
      	| train loss (relative): 2.848346e-01 | valid loss (relative): 2.711806e-01 
Epoch 324 use: 316.37 second.

epoch 325 starting......
Epoch:  325 | train loss: 1.161875e-02 | valid loss: 1.104983e-02 
      	| train loss (relative): 2.858703e-01 | valid loss (relative): 2.709161e-01 
Epoch 325 use: 335.04 second.

epoch 326 starting......
Epoch:  326 | train loss: 1.161874e-02 | valid loss: 1.105134e-02 
      	| train loss (relative): 2.843117e-01 | valid loss (relative): 2.710388e-01 
Epoch 326 use: 357.86 second.

epoch 327 starting......
Epoch:  327 | train loss: 1.161703e-02 | valid loss: 1.104593e-02 
      	| train loss (relative): 2.842652e-01 | valid loss (relative): 2.706155e-01 
Epoch 327 use: 363.27 second.

epoch 328 starting......
Epoch:  328 | train loss: 1.161804e-02 | valid loss: 1.104700e-02 
      	| train loss (relative): 2.848553e-01 | valid loss (relative): 2.703269e-01 
Epoch 328 use: 365.89 second.

epoch 329 starting......
Epoch:  329 | train loss: 1.161890e-02 | valid loss: 1.104496e-02 
      	| train loss (relative): 2.842674e-01 | valid loss (relative): 2.699795e-01 
Epoch 329 use: 314.63 second.

epoch 330 starting......
Epoch:  330 | train loss: 1.161604e-02 | valid loss: 1.105723e-02 
      	| train loss (relative): 2.841209e-01 | valid loss (relative): 2.719583e-01 
Epoch 330 use: 336.08 second.

epoch 331 starting......
Epoch:  331 | train loss: 1.161755e-02 | valid loss: 1.105136e-02 
      	| train loss (relative): 2.848524e-01 | valid loss (relative): 2.713274e-01 
Epoch 331 use: 326.59 second.

epoch 332 starting......
Epoch:  332 | train loss: 1.161717e-02 | valid loss: 1.105228e-02 
      	| train loss (relative): 2.847182e-01 | valid loss (relative): 2.710584e-01 
Epoch 332 use: 362.86 second.

epoch 333 starting......
Epoch:  333 | train loss: 1.161622e-02 | valid loss: 1.104771e-02 
      	| train loss (relative): 2.850744e-01 | valid loss (relative): 2.702843e-01 
Epoch 333 use: 348.39 second.

epoch 334 starting......
Epoch:  334 | train loss: 1.162147e-02 | valid loss: 1.105315e-02 
      	| train loss (relative): 2.846455e-01 | valid loss (relative): 2.712737e-01 
Epoch 334 use: 362.41 second.

epoch 335 starting......
Epoch:  335 | train loss: 1.161826e-02 | valid loss: 1.105469e-02 
      	| train loss (relative): 2.844627e-01 | valid loss (relative): 2.709725e-01 
Epoch 335 use: 329.81 second.

epoch 336 starting......
Epoch:  336 | train loss: 1.161920e-02 | valid loss: 1.104728e-02 
      	| train loss (relative): 2.853285e-01 | valid loss (relative): 2.702382e-01 
Epoch 336 use: 329.93 second.

epoch 337 starting......
Epoch:  337 | train loss: 1.161743e-02 | valid loss: 1.105202e-02 
      	| train loss (relative): 2.842664e-01 | valid loss (relative): 2.707818e-01 
Epoch 337 use: 365.98 second.

epoch 338 starting......
Epoch:  338 | train loss: 1.161856e-02 | valid loss: 1.104725e-02 
      	| train loss (relative): 2.854639e-01 | valid loss (relative): 2.711836e-01 
Epoch 338 use: 319.85 second.

epoch 339 starting......
Epoch:  339 | train loss: 1.162346e-02 | valid loss: 1.104161e-02 
      	| train loss (relative): 2.858405e-01 | valid loss (relative): 2.701122e-01 
Epoch 339 use: 356.96 second.

epoch 340 starting......
Epoch:  340 | train loss: 1.162086e-02 | valid loss: 1.104404e-02 
      	| train loss (relative): 2.845109e-01 | valid loss (relative): 2.690411e-01 
Epoch 340 use: 329.53 second.

epoch 341 starting......
Epoch:  341 | train loss: 1.161993e-02 | valid loss: 1.105015e-02 
      	| train loss (relative): 2.840993e-01 | valid loss (relative): 2.703870e-01 
Epoch 341 use: 323.70 second.

epoch 342 starting......
Epoch:  342 | train loss: 1.161899e-02 | valid loss: 1.105291e-02 
      	| train loss (relative): 2.848114e-01 | valid loss (relative): 2.715939e-01 
Epoch 342 use: 313.28 second.

epoch 343 starting......
Epoch:  343 | train loss: 1.161744e-02 | valid loss: 1.104712e-02 
      	| train loss (relative): 2.853174e-01 | valid loss (relative): 2.708544e-01 
Epoch 343 use: 335.35 second.

epoch 344 starting......
Epoch:  344 | train loss: 1.162048e-02 | valid loss: 1.104673e-02 
      	| train loss (relative): 2.849519e-01 | valid loss (relative): 2.702039e-01 
Epoch 344 use: 339.22 second.

epoch 345 starting......
Epoch:  345 | train loss: 1.162201e-02 | valid loss: 1.104223e-02 
      	| train loss (relative): 2.849378e-01 | valid loss (relative): 2.690345e-01 
Epoch 345 use: 317.15 second.

epoch 346 starting......
Epoch:  346 | train loss: 1.161871e-02 | valid loss: 1.105890e-02 
      	| train loss (relative): 2.831246e-01 | valid loss (relative): 2.714210e-01 
Epoch 346 use: 352.75 second.

epoch 347 starting......
Epoch:  347 | train loss: 1.161715e-02 | valid loss: 1.104832e-02 
      	| train loss (relative): 2.849546e-01 | valid loss (relative): 2.701344e-01 
Epoch 347 use: 333.92 second.

epoch 348 starting......
Epoch:  348 | train loss: 1.161815e-02 | valid loss: 1.104569e-02 
      	| train loss (relative): 2.847447e-01 | valid loss (relative): 2.694238e-01 
Epoch 348 use: 435.01 second.

epoch 349 starting......
Epoch:  349 | train loss: 1.161770e-02 | valid loss: 1.105258e-02 
      	| train loss (relative): 2.840895e-01 | valid loss (relative): 2.709276e-01 
Epoch 349 use: 352.39 second.

epoch 350 starting......
Epoch:  350 | train loss: 1.161764e-02 | valid loss: 1.105336e-02 
      	| train loss (relative): 2.845367e-01 | valid loss (relative): 2.702696e-01 
Epoch 350 use: 325.17 second.

epoch 351 starting......
Epoch:  351 | train loss: 1.161689e-02 | valid loss: 1.104690e-02 
      	| train loss (relative): 2.846987e-01 | valid loss (relative): 2.705141e-01 
Epoch 351 use: 353.23 second.

epoch 352 starting......
Epoch:  352 | train loss: 1.161899e-02 | valid loss: 1.104687e-02 
      	| train loss (relative): 2.847824e-01 | valid loss (relative): 2.704684e-01 
Epoch 352 use: 335.51 second.

epoch 353 starting......
Epoch:  353 | train loss: 1.161799e-02 | valid loss: 1.104938e-02 
      	| train loss (relative): 2.846695e-01 | valid loss (relative): 2.714662e-01 
Epoch 353 use: 315.77 second.

epoch 354 starting......
Epoch:  354 | train loss: 1.161737e-02 | valid loss: 1.105167e-02 
      	| train loss (relative): 2.850535e-01 | valid loss (relative): 2.716330e-01 
Epoch 354 use: 346.95 second.

epoch 355 starting......
Epoch:  355 | train loss: 1.161924e-02 | valid loss: 1.105047e-02 
      	| train loss (relative): 2.851013e-01 | valid loss (relative): 2.708158e-01 
Epoch 355 use: 361.13 second.

epoch 356 starting......
Epoch:  356 | train loss: 1.161959e-02 | valid loss: 1.105368e-02 
      	| train loss (relative): 2.860251e-01 | valid loss (relative): 2.716976e-01 
Epoch 356 use: 344.25 second.

epoch 357 starting......
Epoch:  357 | train loss: 1.162294e-02 | valid loss: 1.111834e-02 
      	| train loss (relative): 2.856058e-01 | valid loss (relative): 2.730700e-01 
Epoch 357 use: 318.14 second.

epoch 358 starting......
Epoch:  358 | train loss: 1.163259e-02 | valid loss: 1.104988e-02 
      	| train loss (relative): 2.850604e-01 | valid loss (relative): 2.704767e-01 
Epoch 358 use: 320.97 second.

epoch 359 starting......
Epoch:  359 | train loss: 1.161875e-02 | valid loss: 1.104868e-02 
      	| train loss (relative): 2.845409e-01 | valid loss (relative): 2.705925e-01 
Epoch 359 use: 326.10 second.

epoch 360 starting......
Epoch:  360 | train loss: 1.161917e-02 | valid loss: 1.105138e-02 
      	| train loss (relative): 2.843585e-01 | valid loss (relative): 2.706892e-01 
Epoch 360 use: 358.63 second.

epoch 361 starting......
Epoch:  361 | train loss: 1.161792e-02 | valid loss: 1.105194e-02 
      	| train loss (relative): 2.848756e-01 | valid loss (relative): 2.709937e-01 
Epoch 361 use: 375.49 second.

epoch 362 starting......
Epoch:  362 | train loss: 1.162191e-02 | valid loss: 1.105247e-02 
      	| train loss (relative): 2.846338e-01 | valid loss (relative): 2.723019e-01 
Epoch 362 use: 342.41 second.

epoch 363 starting......
Epoch:  363 | train loss: 1.161875e-02 | valid loss: 1.105078e-02 
      	| train loss (relative): 2.842498e-01 | valid loss (relative): 2.710975e-01 
Epoch 363 use: 327.32 second.

epoch 364 starting......
Epoch:  364 | train loss: 1.161955e-02 | valid loss: 1.105580e-02 
      	| train loss (relative): 2.842561e-01 | valid loss (relative): 2.716582e-01 
Epoch 364 use: 394.02 second.

epoch 365 starting......
Epoch:  365 | train loss: 1.161845e-02 | valid loss: 1.104750e-02 
      	| train loss (relative): 2.857937e-01 | valid loss (relative): 2.706880e-01 
Epoch 365 use: 351.92 second.

epoch 366 starting......
Epoch:  366 | train loss: 1.161862e-02 | valid loss: 1.105494e-02 
      	| train loss (relative): 2.845063e-01 | valid loss (relative): 2.715076e-01 
Epoch 366 use: 323.83 second.

epoch 367 starting......
Epoch:  367 | train loss: 1.162343e-02 | valid loss: 1.105255e-02 
      	| train loss (relative): 2.868076e-01 | valid loss (relative): 2.715389e-01 
Epoch 367 use: 322.99 second.

epoch 368 starting......
Epoch:  368 | train loss: 1.161812e-02 | valid loss: 1.105290e-02 
      	| train loss (relative): 2.851565e-01 | valid loss (relative): 2.707219e-01 
Epoch 368 use: 351.56 second.

epoch 369 starting......
Epoch:  369 | train loss: 1.161885e-02 | valid loss: 1.105598e-02 
      	| train loss (relative): 2.846373e-01 | valid loss (relative): 2.712798e-01 
Epoch 369 use: 339.88 second.

epoch 370 starting......
Epoch:  370 | train loss: 1.161789e-02 | valid loss: 1.104778e-02 
      	| train loss (relative): 2.844993e-01 | valid loss (relative): 2.709188e-01 
Epoch 370 use: 382.19 second.

epoch 371 starting......
Epoch:  371 | train loss: 1.162116e-02 | valid loss: 1.104976e-02 
      	| train loss (relative): 2.865453e-01 | valid loss (relative): 2.705570e-01 
Epoch 371 use: 368.52 second.

epoch 372 starting......
Epoch:  372 | train loss: 1.161957e-02 | valid loss: 1.105166e-02 
      	| train loss (relative): 2.841953e-01 | valid loss (relative): 2.708442e-01 
Epoch 372 use: 318.10 second.

epoch 373 starting......
Epoch:  373 | train loss: 1.161715e-02 | valid loss: 1.105337e-02 
      	| train loss (relative): 2.837764e-01 | valid loss (relative): 2.716414e-01 
Epoch 373 use: 357.93 second.

epoch 374 starting......
Epoch:  374 | train loss: 1.161745e-02 | valid loss: 1.105043e-02 
      	| train loss (relative): 2.856603e-01 | valid loss (relative): 2.711945e-01 
Epoch 374 use: 320.76 second.

epoch 375 starting......
Epoch:  375 | train loss: 1.161863e-02 | valid loss: 1.105793e-02 
      	| train loss (relative): 2.843336e-01 | valid loss (relative): 2.716634e-01 
Epoch 375 use: 346.42 second.

epoch 376 starting......
Epoch:  376 | train loss: 1.161868e-02 | valid loss: 1.105576e-02 
      	| train loss (relative): 2.844104e-01 | valid loss (relative): 2.719899e-01 
Epoch 376 use: 334.06 second.

epoch 377 starting......
Epoch:  377 | train loss: 1.161586e-02 | valid loss: 1.105337e-02 
      	| train loss (relative): 2.847474e-01 | valid loss (relative): 2.716975e-01 
Epoch 377 use: 335.12 second.

epoch 378 starting......
Epoch:  378 | train loss: 1.161680e-02 | valid loss: 1.105373e-02 
      	| train loss (relative): 2.845736e-01 | valid loss (relative): 2.713714e-01 
Epoch 378 use: 361.38 second.

epoch 379 starting......
Epoch:  379 | train loss: 1.161726e-02 | valid loss: 1.105393e-02 
      	| train loss (relative): 2.848395e-01 | valid loss (relative): 2.711060e-01 
Epoch 379 use: 346.57 second.

epoch 380 starting......
Epoch:  380 | train loss: 1.161875e-02 | valid loss: 1.105409e-02 
      	| train loss (relative): 2.850340e-01 | valid loss (relative): 2.711805e-01 
Epoch 380 use: 349.21 second.

epoch 381 starting......
Epoch:  381 | train loss: 1.161999e-02 | valid loss: 1.106708e-02 
      	| train loss (relative): 2.848395e-01 | valid loss (relative): 2.727206e-01 
Epoch 381 use: 354.32 second.

epoch 382 starting......
Epoch:  382 | train loss: 1.163326e-02 | valid loss: 1.106955e-02 
      	| train loss (relative): 2.880563e-01 | valid loss (relative): 2.716113e-01 
Epoch 382 use: 324.72 second.

epoch 383 starting......
Epoch:  383 | train loss: 1.162293e-02 | valid loss: 1.104823e-02 
      	| train loss (relative): 2.852585e-01 | valid loss (relative): 2.713107e-01 
Epoch 383 use: 355.23 second.

epoch 384 starting......
Epoch:  384 | train loss: 1.161722e-02 | valid loss: 1.105321e-02 
      	| train loss (relative): 2.849805e-01 | valid loss (relative): 2.710074e-01 
Epoch 384 use: 336.91 second.

epoch 385 starting......
Epoch:  385 | train loss: 1.162654e-02 | valid loss: 1.105851e-02 
      	| train loss (relative): 2.865809e-01 | valid loss (relative): 2.729599e-01 
Epoch 385 use: 321.35 second.

epoch 386 starting......
Epoch:  386 | train loss: 1.162018e-02 | valid loss: 1.104792e-02 
      	| train loss (relative): 2.846737e-01 | valid loss (relative): 2.703800e-01 
Epoch 386 use: 335.61 second.

epoch 387 starting......
Epoch:  387 | train loss: 1.161834e-02 | valid loss: 1.106055e-02 
      	| train loss (relative): 2.839324e-01 | valid loss (relative): 2.720900e-01 
Epoch 387 use: 433.70 second.

epoch 388 starting......
Epoch:  388 | train loss: 1.162247e-02 | valid loss: 1.108001e-02 
      	| train loss (relative): 2.867191e-01 | valid loss (relative): 2.744861e-01 
Epoch 388 use: 352.69 second.

epoch 389 starting......
Epoch:  389 | train loss: 1.162323e-02 | valid loss: 1.106945e-02 
      	| train loss (relative): 2.868008e-01 | valid loss (relative): 2.729782e-01 
Epoch 389 use: 342.12 second.

epoch 390 starting......
Epoch:  390 | train loss: 1.162416e-02 | valid loss: 1.105825e-02 
      	| train loss (relative): 2.877410e-01 | valid loss (relative): 2.721072e-01 
Epoch 390 use: 420.77 second.

epoch 391 starting......
Epoch:  391 | train loss: 1.163534e-02 | valid loss: 1.106877e-02 
      	| train loss (relative): 2.866080e-01 | valid loss (relative): 2.707566e-01 
Epoch 391 use: 388.51 second.

epoch 392 starting......
Epoch:  392 | train loss: 1.162042e-02 | valid loss: 1.104875e-02 
      	| train loss (relative): 2.847285e-01 | valid loss (relative): 2.704569e-01 
Epoch 392 use: 378.35 second.

epoch 393 starting......
Epoch:  393 | train loss: 1.161882e-02 | valid loss: 1.105430e-02 
      	| train loss (relative): 2.841346e-01 | valid loss (relative): 2.710599e-01 
Epoch 393 use: 388.19 second.

epoch 394 starting......
Epoch:  394 | train loss: 1.162162e-02 | valid loss: 1.105883e-02 
      	| train loss (relative): 2.861090e-01 | valid loss (relative): 2.714826e-01 
Epoch 394 use: 390.05 second.

epoch 395 starting......
Epoch:  395 | train loss: 1.161681e-02 | valid loss: 1.105202e-02 
      	| train loss (relative): 2.839402e-01 | valid loss (relative): 2.713950e-01 
Epoch 395 use: 374.83 second.

epoch 396 starting......
Epoch:  396 | train loss: 1.161910e-02 | valid loss: 1.105753e-02 
      	| train loss (relative): 2.846884e-01 | valid loss (relative): 2.720081e-01 
Epoch 396 use: 402.59 second.

epoch 397 starting......
Epoch:  397 | train loss: 1.162477e-02 | valid loss: 1.105678e-02 
      	| train loss (relative): 2.870619e-01 | valid loss (relative): 2.716544e-01 
Epoch 397 use: 382.15 second.

epoch 398 starting......
Epoch:  398 | train loss: 1.162050e-02 | valid loss: 1.105465e-02 
      	| train loss (relative): 2.847561e-01 | valid loss (relative): 2.712457e-01 
Epoch 398 use: 405.95 second.

epoch 399 starting......
Epoch:  399 | train loss: 1.161806e-02 | valid loss: 1.105395e-02 
      	| train loss (relative): 2.844518e-01 | valid loss (relative): 2.713388e-01 
Epoch 399 use: 478.93 second.

test MSE Error: 9.734378e-03 | relative MSE Error: 2.389476e-01 
 Total time used for training: 19.61 hour.
MESLoss saved to  /rds/general/user/jy220/home/new_results/Variational_False_Changelr_False_MSELoss_Latent_256_nearest_neighbouring_True_SFC_nums_3_startlr_0.0005_n_epoches_400.txt
relative MSELoss saved to  /rds/general/user/jy220/home/new_results/Variational_False_Changelr_False_reMSELoss_Latent_256_nearest_neighbouring_True_SFC_nums_3_startlr_0.0005_n_epoches_400.txt
model saved to /rds/general/user/jy220/home/new_results/Variational_False_Changelr_False_Latent_256_Nearest_neighbouring_True_SFC_nums_3_startlr_0.0005_n_epoches_400.pth
model_dict saved to /rds/general/user/jy220/home/new_results/Variational_False_Changelr_False_Latent_256_Nearest_neighbouring_True_SFC_nums_3_startlr_0.0005_n_epoches_400_dict.pth
... Training slugflow data completed, Run finished Thu  5 Aug 19:11:41 BST 2021 ...
{'data_dir': '/rds/general/user/jy220/home/tensors/', 'data_type': 'tensors', 'vtu_fields': 'Component1::ComponentMassFractionPhase1, phase1::Velocity', 'variational': 'False', 'optimizer': 'Adamax', 'structured': 'False', 'changing_lr': 'False', 'self_concat': '2', 'dimension': '3', 'sfc_nums': '3', 'components': '4', 'nearest_neighbouring': 'True', 'dims_latent': '256', 'activation': 'Tanh', 'sfc_file': '/rds/general/user/jy220/home/SFC-CAE-Ready-to-use/sfcs.pt', 'inv_sfc_file': '/rds/general/user/jy220/home/SFC-CAE-Ready-to-use/inv_sfcs.pt', 'coords_file': '/rds/general/user/jy220/home/SFC-CAE-Ready-to-use/coords.pt', 'cells_file': '/rds/general/user/jy220/home/SFC-CAE-Ready-to-use/cells.npy', 'state_load': 'None', 'batch_size': '16', 'lr': '0.001', 'n_epoches': '100', 'seed': '15', 'visualize': 'False', 'reconstructed_path': 'None', 'reconstruct_start_index': '0', 'reconstruct_end_index': '50', 'save_path': '/rds/general/user/jy220/home/new_results/'}
[[ 2.50825269e-01 -1.67256990e-02 -1.22268730e-03]
 [ 2.38611959e-01 -5.50627777e-03 -5.06451913e-03]
 [ 2.39454874e-01 -1.59563257e-02  3.96778323e-03]
 ...
 [ 9.11361096e+00 -2.21908381e-02  2.22384902e-03]
 [ 9.11847310e+00 -2.84346931e-02 -2.34839590e-04]
 [ 9.11039661e+00 -2.51498573e-02 -8.70661044e-03]]
{'tetra': array([[      0,       1,       2,       3],
       [      4,       5,       6,       7],
       [      8,       9,      10,      11],
       ...,
       [1342744, 1342745, 1342746, 1342747],
       [1342748, 1342749, 1342750, 1342751],
       [1342752, 1342753, 1342754, 1342755]])}
vtu fields:  ['Component1::ComponentMassFractionPhase1', 'phase1::Velocity'] 
 structured  False 
 activation  Tanh() 
 self concat  2 
 sfc_nums  3 

dims_latent  256 
 components  4 
 nearest_neighbouring  True 

visualize  False 
 sample number  1706 

reading sfc nums......
[array([  41684,   41685,   41674, ..., 1235560, 1235564, 1235558]), array([954289, 954290, 954291, ..., 420685, 420687, 420688]), array([  40156,   40155,   40158, ..., 1123478, 1123475, 1123467])]
reading inverse sfc nums......
[array([   8146,    8145,    8144, ..., 1274444, 1274445, 1273166]), array([547280, 547283, 593037, ..., 933933, 933932, 864488]), array([ 66437,  66439, 122512, ..., 459416, 415130, 459418])]
Computing min and max......

tk:  tensor([0.7581, 0.0418, 0.1840, 0.1464], dtype=torch.float64) 

tb:  tensor([-0.3816, -0.3618, -0.0308,  0.1446], dtype=torch.float64) 

length of train set: 1505 

length of valid set: 100 

length of test set: 101 

torch device num: 4 

Let's use 4 GPUs!
epoch 0 starting......
Epoch:  0 | train loss: 2.350615e-02 | valid loss: 1.588150e-02 
      	| train loss (relative): 5.509342e+00 | valid loss (relative): 5.882541e-01 
Epoch 0 use: 473.80 second.

epoch 1 starting......
Epoch:  1 | train loss: 1.288497e-02 | valid loss: 1.226869e-02 
      	| train loss (relative): 3.966451e-01 | valid loss (relative): 3.062897e-01 
Epoch 1 use: 399.07 second.

epoch 2 starting......
Epoch:  2 | train loss: 1.018872e-02 | valid loss: 9.096957e-03 
      	| train loss (relative): 2.417058e-01 | valid loss (relative): 2.123769e-01 
Epoch 2 use: 392.31 second.

epoch 3 starting......
Epoch:  3 | train loss: 7.494393e-03 | valid loss: 6.830836e-03 
      	| train loss (relative): 1.654824e-01 | valid loss (relative): 1.453838e-01 
Epoch 3 use: 403.14 second.

epoch 4 starting......
Epoch:  4 | train loss: 6.448993e-03 | valid loss: 6.141735e-03 
      	| train loss (relative): 1.400031e-01 | valid loss (relative): 1.345158e-01 
Epoch 4 use: 862.17 second.

epoch 5 starting......
Epoch:  5 | train loss: 6.008319e-03 | valid loss: 5.699250e-03 
      	| train loss (relative): 1.297802e-01 | valid loss (relative): 1.229182e-01 
Epoch 5 use: 1040.12 second.

epoch 6 starting......
Epoch:  6 | train loss: 5.549691e-03 | valid loss: 5.328008e-03 
      	| train loss (relative): 1.188988e-01 | valid loss (relative): 1.171871e-01 
Epoch 6 use: 969.81 second.

epoch 7 starting......
Epoch:  7 | train loss: 5.214875e-03 | valid loss: 4.980068e-03 
      	| train loss (relative): 1.112728e-01 | valid loss (relative): 1.065532e-01 
Epoch 7 use: 858.49 second.

epoch 8 starting......
Epoch:  8 | train loss: 4.976586e-03 | valid loss: 4.744073e-03 
      	| train loss (relative): 1.056533e-01 | valid loss (relative): 1.007971e-01 
Epoch 8 use: 520.19 second.

epoch 9 starting......
Epoch:  9 | train loss: 4.839825e-03 | valid loss: 4.638987e-03 
      	| train loss (relative): 1.023083e-01 | valid loss (relative): 9.857962e-02 
Epoch 9 use: 461.55 second.

epoch 10 starting......
Epoch:  10 | train loss: 4.733011e-03 | valid loss: 4.555170e-03 
      	| train loss (relative): 9.981956e-02 | valid loss (relative): 9.371562e-02 
Epoch 10 use: 428.61 second.

epoch 11 starting......
Epoch:  11 | train loss: 4.650610e-03 | valid loss: 4.509499e-03 
      	| train loss (relative): 9.779803e-02 | valid loss (relative): 9.408359e-02 
Epoch 11 use: 433.94 second.

epoch 12 starting......
Epoch:  12 | train loss: 4.625408e-03 | valid loss: 4.514809e-03 
      	| train loss (relative): 9.713828e-02 | valid loss (relative): 9.569976e-02 
Epoch 12 use: 375.23 second.

epoch 13 starting......
Epoch:  13 | train loss: 4.585510e-03 | valid loss: 4.455189e-03 
      	| train loss (relative): 9.619072e-02 | valid loss (relative): 9.461796e-02 
Epoch 13 use: 394.01 second.

epoch 14 starting......
Epoch:  14 | train loss: 4.525384e-03 | valid loss: 4.384658e-03 
      	| train loss (relative): 9.480065e-02 | valid loss (relative): 9.238312e-02 
Epoch 14 use: 407.51 second.

epoch 15 starting......
Epoch:  15 | train loss: 4.491180e-03 | valid loss: 4.358966e-03 
      	| train loss (relative): 9.394973e-02 | valid loss (relative): 8.976445e-02 
Epoch 15 use: 361.42 second.

epoch 16 starting......
Epoch:  16 | train loss: 4.489976e-03 | valid loss: 4.366985e-03 
      	| train loss (relative): 9.376865e-02 | valid loss (relative): 9.209517e-02 
Epoch 16 use: 370.80 second.

epoch 17 starting......
Epoch:  17 | train loss: 4.393832e-03 | valid loss: 4.267153e-03 
      	| train loss (relative): 9.151305e-02 | valid loss (relative): 8.803172e-02 
Epoch 17 use: 363.80 second.

epoch 18 starting......
Epoch:  18 | train loss: 4.365200e-03 | valid loss: 4.272874e-03 
      	| train loss (relative): 9.082968e-02 | valid loss (relative): 8.819032e-02 
Epoch 18 use: 418.38 second.

epoch 19 starting......
Epoch:  19 | train loss: 4.361274e-03 | valid loss: 4.218728e-03 
      	| train loss (relative): 9.069092e-02 | valid loss (relative): 8.717622e-02 
Epoch 19 use: 357.03 second.

epoch 20 starting......
Epoch:  20 | train loss: 4.304033e-03 | valid loss: 4.191580e-03 
      	| train loss (relative): 8.939412e-02 | valid loss (relative): 8.728150e-02 
Epoch 20 use: 360.12 second.

epoch 21 starting......
Epoch:  21 | train loss: 4.287797e-03 | valid loss: 4.200171e-03 
      	| train loss (relative): 8.902422e-02 | valid loss (relative): 8.662666e-02 
Epoch 21 use: 370.80 second.

epoch 22 starting......
Epoch:  22 | train loss: 4.254664e-03 | valid loss: 4.122580e-03 
      	| train loss (relative): 8.830956e-02 | valid loss (relative): 8.483618e-02 
Epoch 22 use: 330.13 second.

epoch 23 starting......
Epoch:  23 | train loss: 4.217791e-03 | valid loss: 4.118170e-03 
      	| train loss (relative): 8.742365e-02 | valid loss (relative): 8.615934e-02 
Epoch 23 use: 343.27 second.

epoch 24 starting......
Epoch:  24 | train loss: 4.202353e-03 | valid loss: 4.060225e-03 
      	| train loss (relative): 8.708552e-02 | valid loss (relative): 8.348780e-02 
Epoch 24 use: 345.84 second.

epoch 25 starting......
Epoch:  25 | train loss: 4.121399e-03 | valid loss: 3.986524e-03 
      	| train loss (relative): 8.530904e-02 | valid loss (relative): 8.121385e-02 
Epoch 25 use: 373.75 second.

epoch 26 starting......
Epoch:  26 | train loss: 4.055341e-03 | valid loss: 3.933671e-03 
      	| train loss (relative): 8.381355e-02 | valid loss (relative): 8.176882e-02 
Epoch 26 use: 353.39 second.

epoch 27 starting......
Epoch:  27 | train loss: 3.957798e-03 | valid loss: 3.818077e-03 
      	| train loss (relative): 8.174452e-02 | valid loss (relative): 7.771071e-02 
Epoch 27 use: 370.05 second.

epoch 28 starting......
Epoch:  28 | train loss: 3.802606e-03 | valid loss: 3.701335e-03 
      	| train loss (relative): 7.834617e-02 | valid loss (relative): 7.563849e-02 
Epoch 28 use: 360.18 second.

epoch 29 starting......
Epoch:  29 | train loss: 3.682424e-03 | valid loss: 3.577572e-03 
      	| train loss (relative): 7.566935e-02 | valid loss (relative): 7.329910e-02 
Epoch 29 use: 382.35 second.

epoch 30 starting......
Epoch:  30 | train loss: 3.577682e-03 | valid loss: 3.471112e-03 
      	| train loss (relative): 7.338487e-02 | valid loss (relative): 7.104957e-02 
Epoch 30 use: 437.23 second.

epoch 31 starting......
Epoch:  31 | train loss: 3.491973e-03 | valid loss: 3.460581e-03 
      	| train loss (relative): 7.149479e-02 | valid loss (relative): 7.018238e-02 
Epoch 31 use: 462.31 second.

epoch 32 starting......
Epoch:  32 | train loss: 3.429178e-03 | valid loss: 3.354610e-03 
      	| train loss (relative): 7.008001e-02 | valid loss (relative): 6.815039e-02 
Epoch 32 use: 484.54 second.

epoch 33 starting......
Epoch:  33 | train loss: 3.365652e-03 | valid loss: 3.337156e-03 
      	| train loss (relative): 6.870467e-02 | valid loss (relative): 6.759644e-02 
Epoch 33 use: 603.10 second.

epoch 34 starting......
Epoch:  34 | train loss: 3.321710e-03 | valid loss: 3.240526e-03 
      	| train loss (relative): 6.773618e-02 | valid loss (relative): 6.605792e-02 
Epoch 34 use: 385.52 second.

epoch 35 starting......
Epoch:  35 | train loss: 3.261362e-03 | valid loss: 3.225127e-03 
      	| train loss (relative): 6.643573e-02 | valid loss (relative): 6.568979e-02 
Epoch 35 use: 360.33 second.

epoch 36 starting......
Epoch:  36 | train loss: 3.235380e-03 | valid loss: 3.186229e-03 
      	| train loss (relative): 6.582917e-02 | valid loss (relative): 6.534196e-02 
Epoch 36 use: 360.92 second.

epoch 37 starting......
Epoch:  37 | train loss: 3.211900e-03 | valid loss: 3.171984e-03 
      	| train loss (relative): 6.533708e-02 | valid loss (relative): 6.494505e-02 
Epoch 37 use: 381.18 second.

epoch 38 starting......
Epoch:  38 | train loss: 3.190449e-03 | valid loss: 3.120447e-03 
      	| train loss (relative): 6.488021e-02 | valid loss (relative): 6.253006e-02 
Epoch 38 use: 364.79 second.

epoch 39 starting......
Epoch:  39 | train loss: 3.136722e-03 | valid loss: 3.102337e-03 
      	| train loss (relative): 6.366505e-02 | valid loss (relative): 6.344312e-02 
Epoch 39 use: 335.56 second.

epoch 40 starting......
Epoch:  40 | train loss: 3.105998e-03 | valid loss: 3.055115e-03 
      	| train loss (relative): 6.302438e-02 | valid loss (relative): 6.235154e-02 
Epoch 40 use: 337.15 second.

epoch 41 starting......
Epoch:  41 | train loss: 3.086850e-03 | valid loss: 3.064911e-03 
      	| train loss (relative): 6.261767e-02 | valid loss (relative): 6.153391e-02 
Epoch 41 use: 341.88 second.

epoch 42 starting......
Epoch:  42 | train loss: 3.071867e-03 | valid loss: 3.025486e-03 
      	| train loss (relative): 6.228172e-02 | valid loss (relative): 6.119468e-02 
Epoch 42 use: 333.86 second.

epoch 43 starting......
Epoch:  43 | train loss: 3.047535e-03 | valid loss: 3.004242e-03 
      	| train loss (relative): 6.175213e-02 | valid loss (relative): 6.090914e-02 
Epoch 43 use: 355.19 second.

epoch 44 starting......
Epoch:  44 | train loss: 3.023050e-03 | valid loss: 2.989960e-03 
      	| train loss (relative): 6.123194e-02 | valid loss (relative): 6.002485e-02 
Epoch 44 use: 376.30 second.

epoch 45 starting......
Epoch:  45 | train loss: 3.018540e-03 | valid loss: 2.969864e-03 
      	| train loss (relative): 6.112666e-02 | valid loss (relative): 5.965110e-02 
Epoch 45 use: 352.79 second.

epoch 46 starting......
Epoch:  46 | train loss: 2.991159e-03 | valid loss: 2.976332e-03 
      	| train loss (relative): 6.053983e-02 | valid loss (relative): 5.908956e-02 
Epoch 46 use: 337.46 second.

epoch 47 starting......
Epoch:  47 | train loss: 2.981239e-03 | valid loss: 2.943988e-03 
      	| train loss (relative): 6.032133e-02 | valid loss (relative): 5.937278e-02 
Epoch 47 use: 332.69 second.

epoch 48 starting......
Epoch:  48 | train loss: 2.949005e-03 | valid loss: 2.919813e-03 
      	| train loss (relative): 5.964477e-02 | valid loss (relative): 5.879496e-02 
Epoch 48 use: 357.19 second.

epoch 49 starting......
Epoch:  49 | train loss: 2.930722e-03 | valid loss: 2.888326e-03 
      	| train loss (relative): 5.923620e-02 | valid loss (relative): 5.849471e-02 
Epoch 49 use: 346.42 second.

epoch 50 starting......
Epoch:  50 | train loss: 2.917505e-03 | valid loss: 2.900743e-03 
      	| train loss (relative): 5.894055e-02 | valid loss (relative): 5.785158e-02 
Epoch 50 use: 339.64 second.

epoch 51 starting......
Epoch:  51 | train loss: 2.918960e-03 | valid loss: 2.875214e-03 
      	| train loss (relative): 5.898588e-02 | valid loss (relative): 5.764888e-02 
Epoch 51 use: 353.39 second.

epoch 52 starting......
Epoch:  52 | train loss: 2.893711e-03 | valid loss: 2.883545e-03 
      	| train loss (relative): 5.843431e-02 | valid loss (relative): 5.773871e-02 
Epoch 52 use: 329.24 second.

epoch 53 starting......
Epoch:  53 | train loss: 2.881201e-03 | valid loss: 2.842872e-03 
      	| train loss (relative): 5.816363e-02 | valid loss (relative): 5.693648e-02 
Epoch 53 use: 350.34 second.

epoch 54 starting......
Epoch:  54 | train loss: 2.864885e-03 | valid loss: 2.830381e-03 
      	| train loss (relative): 5.781880e-02 | valid loss (relative): 5.713789e-02 
Epoch 54 use: 343.97 second.

epoch 55 starting......
Epoch:  55 | train loss: 2.845602e-03 | valid loss: 2.801441e-03 
      	| train loss (relative): 5.742058e-02 | valid loss (relative): 5.611669e-02 
Epoch 55 use: 393.37 second.

epoch 56 starting......
Epoch:  56 | train loss: 2.827928e-03 | valid loss: 2.796629e-03 
      	| train loss (relative): 5.703438e-02 | valid loss (relative): 5.603331e-02 
Epoch 56 use: 367.64 second.

epoch 57 starting......
Epoch:  57 | train loss: 2.829408e-03 | valid loss: 2.796926e-03 
      	| train loss (relative): 5.705883e-02 | valid loss (relative): 5.608254e-02 
Epoch 57 use: 336.07 second.

epoch 58 starting......
Epoch:  58 | train loss: 2.820862e-03 | valid loss: 2.775725e-03 
      	| train loss (relative): 5.688095e-02 | valid loss (relative): 5.634011e-02 
Epoch 58 use: 345.08 second.

epoch 59 starting......
Epoch:  59 | train loss: 2.807809e-03 | valid loss: 2.781052e-03 
      	| train loss (relative): 5.661516e-02 | valid loss (relative): 5.582070e-02 
Epoch 59 use: 353.62 second.

epoch 60 starting......
Epoch:  60 | train loss: 2.803809e-03 | valid loss: 2.766432e-03 
      	| train loss (relative): 5.651377e-02 | valid loss (relative): 5.532528e-02 
Epoch 60 use: 348.35 second.

epoch 61 starting......
Epoch:  61 | train loss: 2.780917e-03 | valid loss: 2.727741e-03 
      	| train loss (relative): 5.602147e-02 | valid loss (relative): 5.493198e-02 
Epoch 61 use: 343.53 second.

epoch 62 starting......
Epoch:  62 | train loss: 2.762607e-03 | valid loss: 2.714730e-03 
      	| train loss (relative): 5.563939e-02 | valid loss (relative): 5.463959e-02 
Epoch 62 use: 333.29 second.

epoch 63 starting......
Epoch:  63 | train loss: 2.754031e-03 | valid loss: 2.699276e-03 
      	| train loss (relative): 5.546056e-02 | valid loss (relative): 5.427923e-02 
Epoch 63 use: 333.40 second.

epoch 64 starting......
Epoch:  64 | train loss: 2.741995e-03 | valid loss: 2.704083e-03 
      	| train loss (relative): 5.520267e-02 | valid loss (relative): 5.417236e-02 
Epoch 64 use: 357.59 second.

epoch 65 starting......
Epoch:  65 | train loss: 2.741863e-03 | valid loss: 2.701541e-03 
      	| train loss (relative): 5.519788e-02 | valid loss (relative): 5.376864e-02 
Epoch 65 use: 352.17 second.

epoch 66 starting......
Epoch:  66 | train loss: 2.731578e-03 | valid loss: 2.686781e-03 
      	| train loss (relative): 5.497786e-02 | valid loss (relative): 5.357320e-02 
Epoch 66 use: 331.61 second.

epoch 67 starting......
Epoch:  67 | train loss: 2.724521e-03 | valid loss: 2.709640e-03 
      	| train loss (relative): 5.482971e-02 | valid loss (relative): 5.415616e-02 
Epoch 67 use: 325.45 second.

epoch 68 starting......
Epoch:  68 | train loss: 2.717646e-03 | valid loss: 2.710326e-03 
      	| train loss (relative): 5.468255e-02 | valid loss (relative): 5.358246e-02 
Epoch 68 use: 335.27 second.

epoch 69 starting......
Epoch:  69 | train loss: 2.710679e-03 | valid loss: 2.653560e-03 
      	| train loss (relative): 5.452539e-02 | valid loss (relative): 5.304339e-02 
Epoch 69 use: 329.82 second.

epoch 70 starting......
Epoch:  70 | train loss: 2.685579e-03 | valid loss: 2.640013e-03 
      	| train loss (relative): 5.401549e-02 | valid loss (relative): 5.250949e-02 
Epoch 70 use: 335.30 second.

epoch 71 starting......
Epoch:  71 | train loss: 2.680607e-03 | valid loss: 2.648708e-03 
      	| train loss (relative): 5.390853e-02 | valid loss (relative): 5.274337e-02 
Epoch 71 use: 321.94 second.

epoch 72 starting......
Epoch:  72 | train loss: 2.676513e-03 | valid loss: 2.629104e-03 
      	| train loss (relative): 5.381103e-02 | valid loss (relative): 5.287898e-02 
Epoch 72 use: 338.20 second.

epoch 73 starting......
Epoch:  73 | train loss: 2.661923e-03 | valid loss: 2.614439e-03 
      	| train loss (relative): 5.349915e-02 | valid loss (relative): 5.249538e-02 
Epoch 73 use: 330.62 second.

epoch 74 starting......
Epoch:  74 | train loss: 2.651785e-03 | valid loss: 2.606763e-03 
      	| train loss (relative): 5.329046e-02 | valid loss (relative): 5.229226e-02 
Epoch 74 use: 326.16 second.

epoch 75 starting......
Epoch:  75 | train loss: 2.639372e-03 | valid loss: 2.607950e-03 
      	| train loss (relative): 5.302072e-02 | valid loss (relative): 5.244268e-02 
Epoch 75 use: 345.46 second.

epoch 76 starting......
Epoch:  76 | train loss: 2.635482e-03 | valid loss: 2.588395e-03 
      	| train loss (relative): 5.293986e-02 | valid loss (relative): 5.183105e-02 
Epoch 76 use: 338.38 second.

epoch 77 starting......
Epoch:  77 | train loss: 2.629077e-03 | valid loss: 2.595525e-03 
      	| train loss (relative): 5.281144e-02 | valid loss (relative): 5.175088e-02 
Epoch 77 use: 323.30 second.

epoch 78 starting......
Epoch:  78 | train loss: 2.627453e-03 | valid loss: 2.582545e-03 
      	| train loss (relative): 5.275628e-02 | valid loss (relative): 5.160828e-02 
Epoch 78 use: 348.61 second.

epoch 79 starting......
Epoch:  79 | train loss: 2.632603e-03 | valid loss: 2.579990e-03 
      	| train loss (relative): 5.286848e-02 | valid loss (relative): 5.104607e-02 
Epoch 79 use: 339.38 second.

epoch 80 starting......
Epoch:  80 | train loss: 2.605543e-03 | valid loss: 2.570632e-03 
      	| train loss (relative): 5.231059e-02 | valid loss (relative): 5.184329e-02 
Epoch 80 use: 319.14 second.

epoch 81 starting......
Epoch:  81 | train loss: 2.590714e-03 | valid loss: 2.544211e-03 
      	| train loss (relative): 5.200459e-02 | valid loss (relative): 5.045502e-02 
Epoch 81 use: 330.44 second.

epoch 82 starting......
Epoch:  82 | train loss: 2.583167e-03 | valid loss: 2.542519e-03 
      	| train loss (relative): 5.183873e-02 | valid loss (relative): 5.074183e-02 
Epoch 82 use: 319.57 second.

epoch 83 starting......
Epoch:  83 | train loss: 2.578078e-03 | valid loss: 2.545572e-03 
      	| train loss (relative): 5.173978e-02 | valid loss (relative): 5.071333e-02 
Epoch 83 use: 311.30 second.

epoch 84 starting......
Epoch:  84 | train loss: 2.573956e-03 | valid loss: 2.536082e-03 
      	| train loss (relative): 5.163461e-02 | valid loss (relative): 5.103698e-02 
Epoch 84 use: 311.42 second.

epoch 85 starting......
Epoch:  85 | train loss: 2.566600e-03 | valid loss: 2.522643e-03 
      	| train loss (relative): 5.149488e-02 | valid loss (relative): 4.967131e-02 
Epoch 85 use: 327.59 second.

epoch 86 starting......
Epoch:  86 | train loss: 2.554973e-03 | valid loss: 2.522770e-03 
      	| train loss (relative): 5.124897e-02 | valid loss (relative): 5.014372e-02 
Epoch 86 use: 324.61 second.

epoch 87 starting......
Epoch:  87 | train loss: 2.547067e-03 | valid loss: 2.505393e-03 
      	| train loss (relative): 5.109044e-02 | valid loss (relative): 5.032712e-02 
Epoch 87 use: 333.71 second.

epoch 88 starting......
Epoch:  88 | train loss: 2.535012e-03 | valid loss: 2.495309e-03 
      	| train loss (relative): 5.083833e-02 | valid loss (relative): 4.943543e-02 
Epoch 88 use: 330.02 second.

epoch 89 starting......
Epoch:  89 | train loss: 2.526124e-03 | valid loss: 2.483072e-03 
      	| train loss (relative): 5.064259e-02 | valid loss (relative): 4.988052e-02 
Epoch 89 use: 328.26 second.

epoch 90 starting......
Epoch:  90 | train loss: 2.525303e-03 | valid loss: 2.506498e-03 
      	| train loss (relative): 5.061916e-02 | valid loss (relative): 4.978877e-02 
Epoch 90 use: 336.64 second.

epoch 91 starting......
Epoch:  91 | train loss: 2.524201e-03 | valid loss: 2.498024e-03 
      	| train loss (relative): 5.058947e-02 | valid loss (relative): 4.981616e-02 
Epoch 91 use: 330.77 second.

epoch 92 starting......
Epoch:  92 | train loss: 2.510539e-03 | valid loss: 2.467972e-03 
      	| train loss (relative): 5.030524e-02 | valid loss (relative): 4.949752e-02 
Epoch 92 use: 335.70 second.

epoch 93 starting......
Epoch:  93 | train loss: 2.499570e-03 | valid loss: 2.455612e-03 
      	| train loss (relative): 5.008036e-02 | valid loss (relative): 4.894995e-02 
Epoch 93 use: 340.62 second.

epoch 94 starting......
Epoch:  94 | train loss: 2.484995e-03 | valid loss: 2.440343e-03 
      	| train loss (relative): 4.977629e-02 | valid loss (relative): 4.910284e-02 
Epoch 94 use: 337.64 second.

epoch 95 starting......
Epoch:  95 | train loss: 2.478488e-03 | valid loss: 2.449621e-03 
      	| train loss (relative): 4.964704e-02 | valid loss (relative): 4.891227e-02 
Epoch 95 use: 351.82 second.

epoch 96 starting......
Epoch:  96 | train loss: 2.475218e-03 | valid loss: 2.429263e-03 
      	| train loss (relative): 4.956977e-02 | valid loss (relative): 4.865577e-02 
Epoch 96 use: 348.17 second.

epoch 97 starting......
Epoch:  97 | train loss: 2.461712e-03 | valid loss: 2.430747e-03 
      	| train loss (relative): 4.928250e-02 | valid loss (relative): 4.871995e-02 
Epoch 97 use: 337.69 second.

epoch 98 starting......
Epoch:  98 | train loss: 2.459309e-03 | valid loss: 2.420113e-03 
      	| train loss (relative): 4.924610e-02 | valid loss (relative): 4.858440e-02 
Epoch 98 use: 352.59 second.

epoch 99 starting......
Epoch:  99 | train loss: 2.455051e-03 | valid loss: 2.463207e-03 
      	| train loss (relative): 4.915418e-02 | valid loss (relative): 4.807867e-02 
Epoch 99 use: 369.56 second.

test MSE Error: 2.542327e-03 | relative MSE Error: 5.003278e-02 
 Total time used for training: 10.69 hour.
MESLoss saved to  /rds/general/user/jy220/home/new_results/Variational_False_Changelr_False_MSELoss_Latent_256_nearest_neighbouring_True_SFC_nums_3_startlr_0.001_n_epoches_100.txt
relative MSELoss saved to  /rds/general/user/jy220/home/new_results/Variational_False_Changelr_False_reMSELoss_Latent_256_nearest_neighbouring_True_SFC_nums_3_startlr_0.001_n_epoches_100.txt
model saved to /rds/general/user/jy220/home/new_results/Variational_False_Changelr_False_Latent_256_Nearest_neighbouring_True_SFC_nums_3_startlr_0.001_n_epoches_100.pth
model_dict saved to /rds/general/user/jy220/home/new_results/Variational_False_Changelr_False_Latent_256_Nearest_neighbouring_True_SFC_nums_3_startlr_0.001_n_epoches_100_dict.pth
... Training slugflow data completed, Run finished Thu 12 Aug 03:13:59 BST 2021 ...
{'data_dir': '/rds/general/user/jy220/home/tensors/', 'data_type': 'tensors', 'vtu_fields': 'Component1::ComponentMassFractionPhase1, phase1::Velocity', 'variational': 'False', 'optimizer': 'Adamax', 'structured': 'False', 'changing_lr': 'False', 'self_concat': '2', 'dimension': '3', 'sfc_nums': '3', 'components': '4', 'nearest_neighbouring': 'True', 'dims_latent': '256', 'activation': 'Tanh', 'sfc_file': '/rds/general/user/jy220/home/SFC-CAE-Ready-to-use/sfcs.pt', 'inv_sfc_file': '/rds/general/user/jy220/home/SFC-CAE-Ready-to-use/inv_sfcs.pt', 'coords_file': '/rds/general/user/jy220/home/SFC-CAE-Ready-to-use/coords.pt', 'cells_file': '/rds/general/user/jy220/home/SFC-CAE-Ready-to-use/cells.npy', 'state_load': '/rds/general/user/jy220/home/new_results/Variational_False_Changelr_False_Latent_256_Nearest_neighbouring_True_SFC_nums_3_startlr_0.001_n_epoches_100_dict.pth', 'batch_size': '16', 'lr': '0.001', 'n_epoches': '100', 'seed': '15', 'visualize': 'False', 'reconstructed_path': 'None', 'reconstruct_start_index': '0', 'reconstruct_end_index': '50', 'save_path': '/rds/general/user/jy220/home/new_results/'}
[[ 2.50825269e-01 -1.67256990e-02 -1.22268730e-03]
 [ 2.38611959e-01 -5.50627777e-03 -5.06451913e-03]
 [ 2.39454874e-01 -1.59563257e-02  3.96778323e-03]
 ...
 [ 9.11361096e+00 -2.21908381e-02  2.22384902e-03]
 [ 9.11847310e+00 -2.84346931e-02 -2.34839590e-04]
 [ 9.11039661e+00 -2.51498573e-02 -8.70661044e-03]]
{'tetra': array([[      0,       1,       2,       3],
       [      4,       5,       6,       7],
       [      8,       9,      10,      11],
       ...,
       [1342744, 1342745, 1342746, 1342747],
       [1342748, 1342749, 1342750, 1342751],
       [1342752, 1342753, 1342754, 1342755]])}
vtu fields:  ['Component1::ComponentMassFractionPhase1', 'phase1::Velocity'] 
 structured  False 
 activation  Tanh() 
 self concat  2 
 sfc_nums  3 

dims_latent  256 
 components  4 
 nearest_neighbouring  True 

visualize  False 
 sample number  1706 

reading sfc nums......
[array([  41684,   41685,   41674, ..., 1235560, 1235564, 1235558]), array([954289, 954290, 954291, ..., 420685, 420687, 420688]), array([  40156,   40155,   40158, ..., 1123478, 1123475, 1123467])]
reading inverse sfc nums......
[array([   8146,    8145,    8144, ..., 1274444, 1274445, 1273166]), array([547280, 547283, 593037, ..., 933933, 933932, 864488]), array([ 66437,  66439, 122512, ..., 459416, 415130, 459418])]
Computing min and max......

tk:  tensor([0.7581, 0.0418, 0.1840, 0.1464], dtype=torch.float64) 

tb:  tensor([-0.3816, -0.3618, -0.0308,  0.1446], dtype=torch.float64) 

length of train set: 1505 

length of valid set: 100 

length of test set: 101 

torch device num: 4 

Let's use 4 GPUs!
epoch 100 starting......
Epoch:  100 | train loss: 2.866227e-03 | valid loss: 2.620512e-03 
      	| train loss (relative): 5.785002e-02 | valid loss (relative): 5.268653e-02 
Epoch 100 use: 404.84 second.

epoch 101 starting......
Epoch:  101 | train loss: 2.441198e-03 | valid loss: 2.589408e-03 
      	| train loss (relative): 4.887002e-02 | valid loss (relative): 5.200570e-02 
Epoch 101 use: 397.05 second.

epoch 102 starting......
Epoch:  102 | train loss: 2.416502e-03 | valid loss: 2.577427e-03 
      	| train loss (relative): 4.836576e-02 | valid loss (relative): 5.166797e-02 
Epoch 102 use: 363.42 second.

epoch 103 starting......
Epoch:  103 | train loss: 2.401170e-03 | valid loss: 2.562992e-03 
      	| train loss (relative): 4.803734e-02 | valid loss (relative): 5.134683e-02 
Epoch 103 use: 395.46 second.

epoch 104 starting......
Epoch:  104 | train loss: 2.387975e-03 | valid loss: 2.553702e-03 
      	| train loss (relative): 4.774993e-02 | valid loss (relative): 5.121576e-02 
Epoch 104 use: 399.75 second.

epoch 105 starting......
Epoch:  105 | train loss: 2.378590e-03 | valid loss: 2.551185e-03 
      	| train loss (relative): 4.755838e-02 | valid loss (relative): 5.111706e-02 
Epoch 105 use: 362.06 second.

epoch 106 starting......
Epoch:  106 | train loss: 2.373065e-03 | valid loss: 2.546932e-03 
      	| train loss (relative): 4.744529e-02 | valid loss (relative): 5.101946e-02 
Epoch 106 use: 393.88 second.

epoch 107 starting......
Epoch:  107 | train loss: 2.368714e-03 | valid loss: 2.537370e-03 
      	| train loss (relative): 4.733945e-02 | valid loss (relative): 5.090420e-02 
Epoch 107 use: 401.93 second.

epoch 108 starting......
Epoch:  108 | train loss: 2.360955e-03 | valid loss: 2.532430e-03 
      	| train loss (relative): 4.718296e-02 | valid loss (relative): 5.068485e-02 
Epoch 108 use: 458.31 second.

epoch 109 starting......
Epoch:  109 | train loss: 2.355411e-03 | valid loss: 2.528973e-03 
      	| train loss (relative): 4.706486e-02 | valid loss (relative): 5.063541e-02 
Epoch 109 use: 387.60 second.

epoch 110 starting......
Epoch:  110 | train loss: 2.351654e-03 | valid loss: 2.529151e-03 
      	| train loss (relative): 4.698566e-02 | valid loss (relative): 5.061863e-02 
Epoch 110 use: 376.01 second.

epoch 111 starting......
Epoch:  111 | train loss: 2.347375e-03 | valid loss: 2.521814e-03 
      	| train loss (relative): 4.689549e-02 | valid loss (relative): 5.060301e-02 
Epoch 111 use: 402.93 second.

epoch 112 starting......
Epoch:  112 | train loss: 2.342847e-03 | valid loss: 2.523156e-03 
      	| train loss (relative): 4.680880e-02 | valid loss (relative): 5.063250e-02 
Epoch 112 use: 373.47 second.

epoch 113 starting......
Epoch:  113 | train loss: 2.343829e-03 | valid loss: 2.530308e-03 
      	| train loss (relative): 4.683209e-02 | valid loss (relative): 5.054351e-02 
Epoch 113 use: 392.14 second.

epoch 114 starting......
Epoch:  114 | train loss: 2.339339e-03 | valid loss: 2.532650e-03 
      	| train loss (relative): 4.672340e-02 | valid loss (relative): 5.094329e-02 
Epoch 114 use: 393.28 second.

epoch 115 starting......
Epoch:  115 | train loss: 2.343203e-03 | valid loss: 2.521253e-03 
      	| train loss (relative): 4.680873e-02 | valid loss (relative): 5.070649e-02 
Epoch 115 use: 358.28 second.

epoch 116 starting......
Epoch:  116 | train loss: 2.337610e-03 | valid loss: 2.520456e-03 
      	| train loss (relative): 4.668294e-02 | valid loss (relative): 5.038229e-02 
Epoch 116 use: 346.04 second.

epoch 117 starting......
Epoch:  117 | train loss: 2.331578e-03 | valid loss: 2.507524e-03 
      	| train loss (relative): 4.656577e-02 | valid loss (relative): 4.994367e-02 
Epoch 117 use: 356.00 second.

epoch 118 starting......
Epoch:  118 | train loss: 2.324824e-03 | valid loss: 2.510200e-03 
      	| train loss (relative): 4.642425e-02 | valid loss (relative): 4.989645e-02 
Epoch 118 use: 330.94 second.

epoch 119 starting......
Epoch:  119 | train loss: 2.324906e-03 | valid loss: 2.514024e-03 
      	| train loss (relative): 4.642338e-02 | valid loss (relative): 5.049452e-02 
Epoch 119 use: 391.45 second.

epoch 120 starting......
Epoch:  120 | train loss: 2.318161e-03 | valid loss: 2.493913e-03 
      	| train loss (relative): 4.628270e-02 | valid loss (relative): 4.991803e-02 
Epoch 120 use: 346.88 second.

epoch 121 starting......
Epoch:  121 | train loss: 2.305347e-03 | valid loss: 2.495684e-03 
      	| train loss (relative): 4.601093e-02 | valid loss (relative): 5.062703e-02 
Epoch 121 use: 353.57 second.

epoch 122 starting......
Epoch:  122 | train loss: 2.314840e-03 | valid loss: 2.525301e-03 
      	| train loss (relative): 4.621471e-02 | valid loss (relative): 4.967503e-02 
Epoch 122 use: 359.30 second.

epoch 123 starting......
Epoch:  123 | train loss: 2.318085e-03 | valid loss: 2.487101e-03 
      	| train loss (relative): 4.626430e-02 | valid loss (relative): 4.981492e-02 
Epoch 123 use: 351.54 second.

epoch 124 starting......
Epoch:  124 | train loss: 2.297824e-03 | valid loss: 2.483121e-03 
      	| train loss (relative): 4.586020e-02 | valid loss (relative): 4.917613e-02 
Epoch 124 use: 361.96 second.

epoch 125 starting......
Epoch:  125 | train loss: 2.300782e-03 | valid loss: 2.484672e-03 
      	| train loss (relative): 4.590553e-02 | valid loss (relative): 4.967611e-02 
Epoch 125 use: 335.70 second.

epoch 126 starting......
Epoch:  126 | train loss: 2.300151e-03 | valid loss: 2.492858e-03 
      	| train loss (relative): 4.589060e-02 | valid loss (relative): 4.925771e-02 
Epoch 126 use: 342.00 second.

epoch 127 starting......
Epoch:  127 | train loss: 2.315409e-03 | valid loss: 2.459827e-03 
      	| train loss (relative): 4.616474e-02 | valid loss (relative): 4.911724e-02 
Epoch 127 use: 339.27 second.

epoch 128 starting......
Epoch:  128 | train loss: 2.270230e-03 | valid loss: 2.449783e-03 
      	| train loss (relative): 4.528568e-02 | valid loss (relative): 4.908060e-02 
Epoch 128 use: 342.43 second.

epoch 129 starting......
Epoch:  129 | train loss: 2.262053e-03 | valid loss: 2.439966e-03 
      	| train loss (relative): 4.511258e-02 | valid loss (relative): 4.861161e-02 
Epoch 129 use: 335.29 second.

epoch 130 starting......
Epoch:  130 | train loss: 2.254917e-03 | valid loss: 2.435892e-03 
      	| train loss (relative): 4.497104e-02 | valid loss (relative): 4.856548e-02 
Epoch 130 use: 376.57 second.

epoch 131 starting......
Epoch:  131 | train loss: 2.256132e-03 | valid loss: 2.456955e-03 
      	| train loss (relative): 4.499015e-02 | valid loss (relative): 4.914730e-02 
Epoch 131 use: 381.43 second.

epoch 132 starting......
Epoch:  132 | train loss: 2.266982e-03 | valid loss: 2.444209e-03 
      	| train loss (relative): 4.520476e-02 | valid loss (relative): 4.884761e-02 
Epoch 132 use: 337.45 second.

epoch 133 starting......
Epoch:  133 | train loss: 2.249852e-03 | valid loss: 2.437385e-03 
      	| train loss (relative): 4.486012e-02 | valid loss (relative): 4.877492e-02 
Epoch 133 use: 406.67 second.

epoch 134 starting......
Epoch:  134 | train loss: 2.248161e-03 | valid loss: 2.426059e-03 
      	| train loss (relative): 4.482274e-02 | valid loss (relative): 4.849467e-02 
Epoch 134 use: 421.31 second.

epoch 135 starting......
Epoch:  135 | train loss: 2.245412e-03 | valid loss: 2.426171e-03 
      	| train loss (relative): 4.476197e-02 | valid loss (relative): 4.847882e-02 
Epoch 135 use: 351.10 second.

epoch 136 starting......
Epoch:  136 | train loss: 2.240621e-03 | valid loss: 2.428727e-03 
      	| train loss (relative): 4.466513e-02 | valid loss (relative): 4.859256e-02 
Epoch 136 use: 371.98 second.

epoch 137 starting......
Epoch:  137 | train loss: 2.245436e-03 | valid loss: 2.438465e-03 
      	| train loss (relative): 4.476580e-02 | valid loss (relative): 4.919422e-02 
Epoch 137 use: 355.13 second.

epoch 138 starting......
Epoch:  138 | train loss: 2.244457e-03 | valid loss: 2.421363e-03 
      	| train loss (relative): 4.474452e-02 | valid loss (relative): 4.853625e-02 
Epoch 138 use: 410.91 second.

epoch 139 starting......
Epoch:  139 | train loss: 2.235076e-03 | valid loss: 2.436257e-03 
      	| train loss (relative): 4.453620e-02 | valid loss (relative): 4.879516e-02 
Epoch 139 use: 350.60 second.

epoch 140 starting......
Epoch:  140 | train loss: 2.234340e-03 | valid loss: 2.425596e-03 
      	| train loss (relative): 4.453427e-02 | valid loss (relative): 4.850591e-02 
Epoch 140 use: 431.10 second.

epoch 141 starting......
Epoch:  141 | train loss: 2.228649e-03 | valid loss: 2.398402e-03 
      	| train loss (relative): 4.441518e-02 | valid loss (relative): 4.790986e-02 
Epoch 141 use: 346.09 second.

epoch 142 starting......
Epoch:  142 | train loss: 2.215835e-03 | valid loss: 2.398600e-03 
      	| train loss (relative): 4.415377e-02 | valid loss (relative): 4.798660e-02 
Epoch 142 use: 343.13 second.

epoch 143 starting......
Epoch:  143 | train loss: 2.212781e-03 | valid loss: 2.404355e-03 
      	| train loss (relative): 4.408889e-02 | valid loss (relative): 4.793119e-02 
Epoch 143 use: 383.09 second.

epoch 144 starting......
Epoch:  144 | train loss: 2.215817e-03 | valid loss: 2.416141e-03 
      	| train loss (relative): 4.413352e-02 | valid loss (relative): 4.879923e-02 
Epoch 144 use: 376.57 second.

epoch 145 starting......
Epoch:  145 | train loss: 2.214952e-03 | valid loss: 2.394641e-03 
      	| train loss (relative): 4.412095e-02 | valid loss (relative): 4.815182e-02 
Epoch 145 use: 380.71 second.

epoch 146 starting......
Epoch:  146 | train loss: 2.206673e-03 | valid loss: 2.394596e-03 
      	| train loss (relative): 4.395194e-02 | valid loss (relative): 4.762268e-02 
Epoch 146 use: 382.44 second.

epoch 147 starting......
Epoch:  147 | train loss: 2.209140e-03 | valid loss: 2.389438e-03 
      	| train loss (relative): 4.399450e-02 | valid loss (relative): 4.741468e-02 
Epoch 147 use: 370.42 second.

epoch 148 starting......
Epoch:  148 | train loss: 2.218279e-03 | valid loss: 2.396324e-03 
      	| train loss (relative): 4.416213e-02 | valid loss (relative): 4.798330e-02 
Epoch 148 use: 495.03 second.

epoch 149 starting......
Epoch:  149 | train loss: 2.195509e-03 | valid loss: 2.385374e-03 
      	| train loss (relative): 4.372314e-02 | valid loss (relative): 4.773149e-02 
Epoch 149 use: 689.96 second.

epoch 150 starting......
Epoch:  150 | train loss: 2.194726e-03 | valid loss: 2.394550e-03 
      	| train loss (relative): 4.369554e-02 | valid loss (relative): 4.769399e-02 
Epoch 150 use: 401.08 second.

epoch 151 starting......
Epoch:  151 | train loss: 2.197560e-03 | valid loss: 2.383782e-03 
      	| train loss (relative): 4.376035e-02 | valid loss (relative): 4.715699e-02 
Epoch 151 use: 436.88 second.

epoch 152 starting......
Epoch:  152 | train loss: 2.181217e-03 | valid loss: 2.358103e-03 
      	| train loss (relative): 4.343086e-02 | valid loss (relative): 4.712315e-02 
Epoch 152 use: 396.85 second.

epoch 153 starting......
Epoch:  153 | train loss: 2.179349e-03 | valid loss: 2.357956e-03 
      	| train loss (relative): 4.338253e-02 | valid loss (relative): 4.736361e-02 
Epoch 153 use: 558.88 second.

epoch 154 starting......
Epoch:  154 | train loss: 2.182187e-03 | valid loss: 2.365477e-03 
      	| train loss (relative): 4.343402e-02 | valid loss (relative): 4.688809e-02 
Epoch 154 use: 926.23 second.

epoch 155 starting......
Epoch:  155 | train loss: 2.177859e-03 | valid loss: 2.367881e-03 
      	| train loss (relative): 4.335460e-02 | valid loss (relative): 4.664023e-02 
Epoch 155 use: 1212.02 second.

epoch 156 starting......
Epoch:  156 | train loss: 2.172519e-03 | valid loss: 2.352700e-03 
      	| train loss (relative): 4.323369e-02 | valid loss (relative): 4.699213e-02 
Epoch 156 use: 1303.31 second.

epoch 157 starting......
Epoch:  157 | train loss: 2.173441e-03 | valid loss: 2.371814e-03 
      	| train loss (relative): 4.325522e-02 | valid loss (relative): 4.715055e-02 
Epoch 157 use: 825.17 second.

epoch 158 starting......
Epoch:  158 | train loss: 2.170063e-03 | valid loss: 2.380115e-03 
      	| train loss (relative): 4.317735e-02 | valid loss (relative): 4.806090e-02 
Epoch 158 use: 866.76 second.

epoch 159 starting......
Epoch:  159 | train loss: 2.180114e-03 | valid loss: 2.350966e-03 
      	| train loss (relative): 4.338875e-02 | valid loss (relative): 4.666128e-02 
Epoch 159 use: 962.42 second.

epoch 160 starting......
Epoch:  160 | train loss: 2.162210e-03 | valid loss: 2.345759e-03 
      	| train loss (relative): 4.301867e-02 | valid loss (relative): 4.667865e-02 
Epoch 160 use: 770.87 second.

epoch 161 starting......
Epoch:  161 | train loss: 2.152676e-03 | valid loss: 2.358049e-03 
      	| train loss (relative): 4.282442e-02 | valid loss (relative): 4.765814e-02 
Epoch 161 use: 592.08 second.

epoch 162 starting......
Epoch:  162 | train loss: 2.168159e-03 | valid loss: 2.331872e-03 
      	| train loss (relative): 4.315024e-02 | valid loss (relative): 4.690191e-02 
Epoch 162 use: 372.21 second.

epoch 163 starting......
Epoch:  163 | train loss: 2.145218e-03 | valid loss: 2.329564e-03 
      	| train loss (relative): 4.268060e-02 | valid loss (relative): 4.641285e-02 
Epoch 163 use: 351.31 second.

epoch 164 starting......
Epoch:  164 | train loss: 2.147482e-03 | valid loss: 2.331033e-03 
      	| train loss (relative): 4.271593e-02 | valid loss (relative): 4.658452e-02 
Epoch 164 use: 369.81 second.

epoch 165 starting......
Epoch:  165 | train loss: 2.141814e-03 | valid loss: 2.333977e-03 
      	| train loss (relative): 4.259416e-02 | valid loss (relative): 4.642193e-02 
Epoch 165 use: 386.22 second.

epoch 166 starting......
Epoch:  166 | train loss: 2.142212e-03 | valid loss: 2.334446e-03 
      	| train loss (relative): 4.260368e-02 | valid loss (relative): 4.681879e-02 
Epoch 166 use: 412.86 second.

epoch 167 starting......
Epoch:  167 | train loss: 2.144379e-03 | valid loss: 2.352952e-03 
      	| train loss (relative): 4.264582e-02 | valid loss (relative): 4.650598e-02 
Epoch 167 use: 342.39 second.

epoch 168 starting......
Epoch:  168 | train loss: 2.137702e-03 | valid loss: 2.314925e-03 
      	| train loss (relative): 4.250780e-02 | valid loss (relative): 4.624915e-02 
Epoch 168 use: 351.73 second.

epoch 169 starting......
Epoch:  169 | train loss: 2.129931e-03 | valid loss: 2.311883e-03 
      	| train loss (relative): 4.235210e-02 | valid loss (relative): 4.600481e-02 
Epoch 169 use: 391.42 second.

epoch 170 starting......
Epoch:  170 | train loss: 2.128375e-03 | valid loss: 2.324648e-03 
      	| train loss (relative): 4.232278e-02 | valid loss (relative): 4.626329e-02 
Epoch 170 use: 346.57 second.

epoch 171 starting......
Epoch:  171 | train loss: 2.136804e-03 | valid loss: 2.329063e-03 
      	| train loss (relative): 4.248957e-02 | valid loss (relative): 4.615685e-02 
Epoch 171 use: 325.33 second.

epoch 172 starting......
Epoch:  172 | train loss: 2.129289e-03 | valid loss: 2.311585e-03 
      	| train loss (relative): 4.233016e-02 | valid loss (relative): 4.627489e-02 
Epoch 172 use: 332.16 second.

epoch 173 starting......
Epoch:  173 | train loss: 2.121439e-03 | valid loss: 2.315659e-03 
      	| train loss (relative): 4.217472e-02 | valid loss (relative): 4.648611e-02 
Epoch 173 use: 346.53 second.

epoch 174 starting......
Epoch:  174 | train loss: 2.122564e-03 | valid loss: 2.300909e-03 
      	| train loss (relative): 4.219674e-02 | valid loss (relative): 4.599115e-02 
Epoch 174 use: 413.01 second.

epoch 175 starting......
Epoch:  175 | train loss: 2.120245e-03 | valid loss: 2.293237e-03 
      	| train loss (relative): 4.214960e-02 | valid loss (relative): 4.562169e-02 
Epoch 175 use: 441.38 second.

epoch 176 starting......
Epoch:  176 | train loss: 2.111875e-03 | valid loss: 2.323160e-03 
      	| train loss (relative): 4.197351e-02 | valid loss (relative): 4.617634e-02 
Epoch 176 use: 370.85 second.

epoch 177 starting......
Epoch:  177 | train loss: 2.119106e-03 | valid loss: 2.305864e-03 
      	| train loss (relative): 4.212417e-02 | valid loss (relative): 4.599498e-02 
Epoch 177 use: 348.23 second.

epoch 178 starting......
Epoch:  178 | train loss: 2.117191e-03 | valid loss: 2.320652e-03 
      	| train loss (relative): 4.208388e-02 | valid loss (relative): 4.657215e-02 
Epoch 178 use: 347.15 second.

epoch 179 starting......
Epoch:  179 | train loss: 2.112518e-03 | valid loss: 2.302084e-03 
      	| train loss (relative): 4.198785e-02 | valid loss (relative): 4.612572e-02 
Epoch 179 use: 352.50 second.

epoch 180 starting......
Epoch:  180 | train loss: 2.102040e-03 | valid loss: 2.283840e-03 
      	| train loss (relative): 4.177827e-02 | valid loss (relative): 4.543601e-02 
Epoch 180 use: 451.71 second.

epoch 181 starting......
Epoch:  181 | train loss: 2.098574e-03 | valid loss: 2.283475e-03 
      	| train loss (relative): 4.170081e-02 | valid loss (relative): 4.515749e-02 
Epoch 181 use: 482.03 second.

epoch 182 starting......
Epoch:  182 | train loss: 2.099237e-03 | valid loss: 2.281422e-03 
      	| train loss (relative): 4.171193e-02 | valid loss (relative): 4.562922e-02 
Epoch 182 use: 434.38 second.

epoch 183 starting......
Epoch:  183 | train loss: 2.104087e-03 | valid loss: 2.315759e-03 
      	| train loss (relative): 4.181079e-02 | valid loss (relative): 4.558217e-02 
Epoch 183 use: 425.74 second.

epoch 184 starting......
Epoch:  184 | train loss: 2.101583e-03 | valid loss: 2.280154e-03 
      	| train loss (relative): 4.175375e-02 | valid loss (relative): 4.520585e-02 
Epoch 184 use: 368.41 second.

epoch 185 starting......
Epoch:  185 | train loss: 2.096232e-03 | valid loss: 2.293990e-03 
      	| train loss (relative): 4.165036e-02 | valid loss (relative): 4.564413e-02 
Epoch 185 use: 372.60 second.

epoch 186 starting......
Epoch:  186 | train loss: 2.092912e-03 | valid loss: 2.319448e-03 
      	| train loss (relative): 4.157927e-02 | valid loss (relative): 4.664464e-02 
Epoch 186 use: 401.16 second.

epoch 187 starting......
Epoch:  187 | train loss: 2.098890e-03 | valid loss: 2.263164e-03 
      	| train loss (relative): 4.170796e-02 | valid loss (relative): 4.505592e-02 
Epoch 187 use: 424.05 second.

epoch 188 starting......
Epoch:  188 | train loss: 2.079501e-03 | valid loss: 2.266235e-03 
      	| train loss (relative): 4.130743e-02 | valid loss (relative): 4.500728e-02 
Epoch 188 use: 393.48 second.

epoch 189 starting......
Epoch:  189 | train loss: 2.082726e-03 | valid loss: 2.286492e-03 
      	| train loss (relative): 4.137235e-02 | valid loss (relative): 4.555224e-02 
Epoch 189 use: 604.18 second.

epoch 190 starting......
Epoch:  190 | train loss: 2.086348e-03 | valid loss: 2.259369e-03 
      	| train loss (relative): 4.144162e-02 | valid loss (relative): 4.512316e-02 
Epoch 190 use: 547.51 second.

epoch 191 starting......
Epoch:  191 | train loss: 2.072064e-03 | valid loss: 2.259443e-03 
      	| train loss (relative): 4.115358e-02 | valid loss (relative): 4.514722e-02 
Epoch 191 use: 607.49 second.

epoch 192 starting......
Epoch:  192 | train loss: 2.078281e-03 | valid loss: 2.251619e-03 
      	| train loss (relative): 4.127353e-02 | valid loss (relative): 4.450347e-02 
Epoch 192 use: 385.22 second.

epoch 193 starting......
Epoch:  193 | train loss: 2.069615e-03 | valid loss: 2.252882e-03 
      	| train loss (relative): 4.109479e-02 | valid loss (relative): 4.450143e-02 
Epoch 193 use: 405.99 second.

epoch 194 starting......
Epoch:  194 | train loss: 2.074352e-03 | valid loss: 2.277711e-03 
      	| train loss (relative): 4.119189e-02 | valid loss (relative): 4.529706e-02 
Epoch 194 use: 584.35 second.

epoch 195 starting......
Epoch:  195 | train loss: 2.071484e-03 | valid loss: 2.255394e-03 
      	| train loss (relative): 4.113694e-02 | valid loss (relative): 4.449312e-02 
Epoch 195 use: 489.60 second.

epoch 196 starting......
Epoch:  196 | train loss: 2.068398e-03 | valid loss: 2.244656e-03 
      	| train loss (relative): 4.106447e-02 | valid loss (relative): 4.479247e-02 
Epoch 196 use: 370.93 second.

epoch 197 starting......
Epoch:  197 | train loss: 2.059748e-03 | valid loss: 2.242469e-03 
      	| train loss (relative): 4.089819e-02 | valid loss (relative): 4.423840e-02 
Epoch 197 use: 374.76 second.

epoch 198 starting......
Epoch:  198 | train loss: 2.053332e-03 | valid loss: 2.258032e-03 
      	| train loss (relative): 4.075630e-02 | valid loss (relative): 4.458778e-02 
Epoch 198 use: 364.12 second.

epoch 199 starting......
Epoch:  199 | train loss: 2.057217e-03 | valid loss: 2.237041e-03 
      	| train loss (relative): 4.084010e-02 | valid loss (relative): 4.457385e-02 
Epoch 199 use: 425.76 second.

test MSE Error: 2.187785e-03 | relative MSE Error: 4.351339e-02 
 Total time used for training: 12.20 hour.
MESLoss saved to  /rds/general/user/jy220/home/new_results/Variational_False_Changelr_False_MSELoss_Latent_256_nearest_neighbouring_True_SFC_nums_3_startlr_0.001_n_epoches_200.txt
relative MSELoss saved to  /rds/general/user/jy220/home/new_results/Variational_False_Changelr_False_reMSELoss_Latent_256_nearest_neighbouring_True_SFC_nums_3_startlr_0.001_n_epoches_200.txt
model saved to /rds/general/user/jy220/home/new_results/Variational_False_Changelr_False_Latent_256_Nearest_neighbouring_True_SFC_nums_3_startlr_0.001_n_epoches_200.pth
model_dict saved to /rds/general/user/jy220/home/new_results/Variational_False_Changelr_False_Latent_256_Nearest_neighbouring_True_SFC_nums_3_startlr_0.001_n_epoches_200_dict.pth
... Training slugflow data completed, Run finished Thu 12 Aug 20:34:18 BST 2021 ...
{'data_dir': '/rds/general/user/jy220/home/tensors/', 'data_type': 'tensors', 'vtu_fields': 'Component1::ComponentMassFractionPhase1, phase1::Velocity', 'variational': 'False', 'optimizer': 'Adamax', 'structured': 'False', 'changing_lr': 'False', 'self_concat': '2', 'dimension': '3', 'sfc_nums': '3', 'components': '4', 'nearest_neighbouring': 'True', 'dims_latent': '256', 'activation': 'Tanh', 'sfc_file': '/rds/general/user/jy220/home/SFC-CAE-Ready-to-use/sfcs.pt', 'inv_sfc_file': '/rds/general/user/jy220/home/SFC-CAE-Ready-to-use/inv_sfcs.pt', 'coords_file': '/rds/general/user/jy220/home/SFC-CAE-Ready-to-use/coords.pt', 'cells_file': '/rds/general/user/jy220/home/SFC-CAE-Ready-to-use/cells.npy', 'state_load': '/rds/general/user/jy220/home/new_results/Variational_False_Changelr_False_Latent_256_Nearest_neighbouring_True_SFC_nums_3_startlr_0.001_n_epoches_200_dict.pth', 'batch_size': '16', 'lr': '0.001', 'n_epoches': '100', 'seed': '15', 'visualize': 'False', 'reconstructed_path': 'None', 'reconstruct_start_index': '0', 'reconstruct_end_index': '50', 'save_path': '/rds/general/user/jy220/home/new_results/'}
[[ 2.50825269e-01 -1.67256990e-02 -1.22268730e-03]
 [ 2.38611959e-01 -5.50627777e-03 -5.06451913e-03]
 [ 2.39454874e-01 -1.59563257e-02  3.96778323e-03]
 ...
 [ 9.11361096e+00 -2.21908381e-02  2.22384902e-03]
 [ 9.11847310e+00 -2.84346931e-02 -2.34839590e-04]
 [ 9.11039661e+00 -2.51498573e-02 -8.70661044e-03]]
{'tetra': array([[      0,       1,       2,       3],
       [      4,       5,       6,       7],
       [      8,       9,      10,      11],
       ...,
       [1342744, 1342745, 1342746, 1342747],
       [1342748, 1342749, 1342750, 1342751],
       [1342752, 1342753, 1342754, 1342755]])}
vtu fields:  ['Component1::ComponentMassFractionPhase1', 'phase1::Velocity'] 
 structured  False 
 activation  Tanh() 
 self concat  2 
 sfc_nums  3 

dims_latent  256 
 components  4 
 nearest_neighbouring  True 

visualize  False 
 sample number  1706 

reading sfc nums......
[array([  41684,   41685,   41674, ..., 1235560, 1235564, 1235558]), array([954289, 954290, 954291, ..., 420685, 420687, 420688]), array([  40156,   40155,   40158, ..., 1123478, 1123475, 1123467])]
reading inverse sfc nums......
[array([   8146,    8145,    8144, ..., 1274444, 1274445, 1273166]), array([547280, 547283, 593037, ..., 933933, 933932, 864488]), array([ 66437,  66439, 122512, ..., 459416, 415130, 459418])]
Computing min and max......

tk:  tensor([0.7581, 0.0418, 0.1840, 0.1464], dtype=torch.float64) 

tb:  tensor([-0.3816, -0.3618, -0.0308,  0.1446], dtype=torch.float64) 

length of train set: 1505 

length of valid set: 100 

length of test set: 101 

torch device num: 4 

Let's use 4 GPUs!
epoch 200 starting......
Epoch:  200 | train loss: 2.477342e-03 | valid loss: 2.026927e-03 
      	| train loss (relative): 4.911692e-02 | valid loss (relative): 4.000228e-02 
Epoch 200 use: 516.29 second.

epoch 201 starting......
Epoch:  201 | train loss: 2.089619e-03 | valid loss: 1.999689e-03 
      	| train loss (relative): 4.152414e-02 | valid loss (relative): 3.950579e-02 
Epoch 201 use: 549.96 second.

epoch 202 starting......
Epoch:  202 | train loss: 2.070036e-03 | valid loss: 1.993281e-03 
      	| train loss (relative): 4.111312e-02 | valid loss (relative): 3.940385e-02 
Epoch 202 use: 472.83 second.

epoch 203 starting......
Epoch:  203 | train loss: 2.062150e-03 | valid loss: 1.987819e-03 
      	| train loss (relative): 4.095112e-02 | valid loss (relative): 3.923805e-02 
Epoch 203 use: 521.87 second.

epoch 204 starting......
Epoch:  204 | train loss: 2.056579e-03 | valid loss: 1.986071e-03 
      	| train loss (relative): 4.083308e-02 | valid loss (relative): 3.914597e-02 
Epoch 204 use: 505.63 second.

epoch 205 starting......
Epoch:  205 | train loss: 2.052689e-03 | valid loss: 1.984142e-03 
      	| train loss (relative): 4.075923e-02 | valid loss (relative): 3.914585e-02 
Epoch 205 use: 674.25 second.

epoch 206 starting......
Epoch:  206 | train loss: 2.049369e-03 | valid loss: 1.981883e-03 
      	| train loss (relative): 4.068488e-02 | valid loss (relative): 3.912395e-02 
Epoch 206 use: 446.42 second.

epoch 207 starting......
Epoch:  207 | train loss: 2.047237e-03 | valid loss: 1.980331e-03 
      	| train loss (relative): 4.063822e-02 | valid loss (relative): 3.909802e-02 
Epoch 207 use: 487.87 second.

epoch 208 starting......
Epoch:  208 | train loss: 2.045002e-03 | valid loss: 1.979081e-03 
      	| train loss (relative): 4.059879e-02 | valid loss (relative): 3.906839e-02 
Epoch 208 use: 471.15 second.

epoch 209 starting......
Epoch:  209 | train loss: 2.043537e-03 | valid loss: 1.978644e-03 
      	| train loss (relative): 4.056245e-02 | valid loss (relative): 3.904096e-02 
Epoch 209 use: 419.13 second.

epoch 210 starting......
Epoch:  210 | train loss: 2.041625e-03 | valid loss: 1.981410e-03 
      	| train loss (relative): 4.052713e-02 | valid loss (relative): 3.905066e-02 
Epoch 210 use: 433.72 second.

epoch 211 starting......
Epoch:  211 | train loss: 2.041477e-03 | valid loss: 1.980428e-03 
      	| train loss (relative): 4.052201e-02 | valid loss (relative): 3.915217e-02 
Epoch 211 use: 470.16 second.

epoch 212 starting......
Epoch:  212 | train loss: 2.041252e-03 | valid loss: 1.981455e-03 
      	| train loss (relative): 4.051493e-02 | valid loss (relative): 3.908519e-02 
Epoch 212 use: 434.66 second.

epoch 213 starting......
Epoch:  213 | train loss: 2.045936e-03 | valid loss: 1.994188e-03 
      	| train loss (relative): 4.062115e-02 | valid loss (relative): 3.912681e-02 
Epoch 213 use: 443.82 second.

epoch 214 starting......
Epoch:  214 | train loss: 2.046213e-03 | valid loss: 1.986230e-03 
      	| train loss (relative): 4.060886e-02 | valid loss (relative): 3.925707e-02 
Epoch 214 use: 433.09 second.

epoch 215 starting......
Epoch:  215 | train loss: 2.046100e-03 | valid loss: 1.989156e-03 
      	| train loss (relative): 4.061183e-02 | valid loss (relative): 3.929425e-02 
Epoch 215 use: 464.30 second.

epoch 216 starting......
Epoch:  216 | train loss: 2.041363e-03 | valid loss: 1.990500e-03 
      	| train loss (relative): 4.052220e-02 | valid loss (relative): 3.940719e-02 
Epoch 216 use: 440.58 second.

epoch 217 starting......
Epoch:  217 | train loss: 2.048403e-03 | valid loss: 2.005960e-03 
      	| train loss (relative): 4.065352e-02 | valid loss (relative): 3.997082e-02 
Epoch 217 use: 438.52 second.

epoch 218 starting......
Epoch:  218 | train loss: 2.043845e-03 | valid loss: 1.983103e-03 
      	| train loss (relative): 4.056881e-02 | valid loss (relative): 3.916911e-02 
Epoch 218 use: 468.55 second.

epoch 219 starting......
Epoch:  219 | train loss: 2.035160e-03 | valid loss: 1.986269e-03 
      	| train loss (relative): 4.038446e-02 | valid loss (relative): 3.926679e-02 
Epoch 219 use: 445.92 second.

epoch 220 starting......
Epoch:  220 | train loss: 2.034561e-03 | valid loss: 1.982084e-03 
      	| train loss (relative): 4.036851e-02 | valid loss (relative): 3.929101e-02 
Epoch 220 use: 424.52 second.

epoch 221 starting......
Epoch:  221 | train loss: 2.038296e-03 | valid loss: 1.998487e-03 
      	| train loss (relative): 4.044208e-02 | valid loss (relative): 3.935022e-02 
Epoch 221 use: 452.07 second.

epoch 222 starting......
Epoch:  222 | train loss: 2.037765e-03 | valid loss: 1.990990e-03 
      	| train loss (relative): 4.043788e-02 | valid loss (relative): 3.909247e-02 
Epoch 222 use: 458.99 second.

epoch 223 starting......
Epoch:  223 | train loss: 2.038336e-03 | valid loss: 2.030192e-03 
      	| train loss (relative): 4.044259e-02 | valid loss (relative): 3.940599e-02 
Epoch 223 use: 425.86 second.

epoch 224 starting......
Epoch:  224 | train loss: 2.045416e-03 | valid loss: 1.982030e-03 
      	| train loss (relative): 4.057943e-02 | valid loss (relative): 3.900556e-02 
Epoch 224 use: 435.36 second.

epoch 225 starting......
Epoch:  225 | train loss: 2.030451e-03 | valid loss: 1.996303e-03 
      	| train loss (relative): 4.027962e-02 | valid loss (relative): 3.970520e-02 
Epoch 225 use: 453.22 second.

epoch 226 starting......
Epoch:  226 | train loss: 2.031387e-03 | valid loss: 1.977538e-03 
      	| train loss (relative): 4.030427e-02 | valid loss (relative): 3.908357e-02 
Epoch 226 use: 438.34 second.

epoch 227 starting......
Epoch:  227 | train loss: 2.033741e-03 | valid loss: 1.987160e-03 
      	| train loss (relative): 4.034702e-02 | valid loss (relative): 3.893758e-02 
Epoch 227 use: 451.20 second.

epoch 228 starting......
Epoch:  228 | train loss: 2.031288e-03 | valid loss: 1.995659e-03 
      	| train loss (relative): 4.029487e-02 | valid loss (relative): 3.983831e-02 
Epoch 228 use: 448.48 second.

epoch 229 starting......
Epoch:  229 | train loss: 2.035223e-03 | valid loss: 1.980720e-03 
      	| train loss (relative): 4.037444e-02 | valid loss (relative): 3.912215e-02 
Epoch 229 use: 429.41 second.

epoch 230 starting......
Epoch:  230 | train loss: 2.024905e-03 | valid loss: 1.967035e-03 
      	| train loss (relative): 4.016410e-02 | valid loss (relative): 3.866740e-02 
Epoch 230 use: 452.17 second.

epoch 231 starting......
Epoch:  231 | train loss: 2.019889e-03 | valid loss: 1.989526e-03 
      	| train loss (relative): 4.006135e-02 | valid loss (relative): 3.966347e-02 
Epoch 231 use: 443.09 second.

epoch 232 starting......
Epoch:  232 | train loss: 2.028039e-03 | valid loss: 1.976349e-03 
      	| train loss (relative): 4.022738e-02 | valid loss (relative): 3.904945e-02 
Epoch 232 use: 495.08 second.

epoch 233 starting......
Epoch:  233 | train loss: 2.026525e-03 | valid loss: 1.983377e-03 
      	| train loss (relative): 4.019106e-02 | valid loss (relative): 3.900415e-02 
Epoch 233 use: 432.21 second.

epoch 234 starting......
Epoch:  234 | train loss: 2.017542e-03 | valid loss: 1.966172e-03 
      	| train loss (relative): 4.001430e-02 | valid loss (relative): 3.879326e-02 
Epoch 234 use: 432.12 second.

epoch 235 starting......
Epoch:  235 | train loss: 2.016857e-03 | valid loss: 1.985358e-03 
      	| train loss (relative): 4.000194e-02 | valid loss (relative): 3.902416e-02 
Epoch 235 use: 457.80 second.

epoch 236 starting......
Epoch:  236 | train loss: 2.024039e-03 | valid loss: 1.976304e-03 
      	| train loss (relative): 4.014282e-02 | valid loss (relative): 3.860602e-02 
Epoch 236 use: 439.47 second.

epoch 237 starting......
Epoch:  237 | train loss: 2.017265e-03 | valid loss: 1.967854e-03 
      	| train loss (relative): 3.999868e-02 | valid loss (relative): 3.862477e-02 
Epoch 237 use: 496.25 second.

epoch 238 starting......
Epoch:  238 | train loss: 2.010450e-03 | valid loss: 1.960796e-03 
      	| train loss (relative): 3.985960e-02 | valid loss (relative): 3.874752e-02 
Epoch 238 use: 446.85 second.

epoch 239 starting......
Epoch:  239 | train loss: 2.004929e-03 | valid loss: 1.962164e-03 
      	| train loss (relative): 3.975566e-02 | valid loss (relative): 3.862397e-02 
Epoch 239 use: 441.88 second.

epoch 240 starting......
Epoch:  240 | train loss: 2.005752e-03 | valid loss: 1.978893e-03 
      	| train loss (relative): 3.976807e-02 | valid loss (relative): 3.864270e-02 
Epoch 240 use: 431.41 second.

epoch 241 starting......
Epoch:  241 | train loss: 2.013192e-03 | valid loss: 1.964487e-03 
      	| train loss (relative): 3.991596e-02 | valid loss (relative): 3.875553e-02 
Epoch 241 use: 448.03 second.

epoch 242 starting......
Epoch:  242 | train loss: 2.007526e-03 | valid loss: 1.976311e-03 
      	| train loss (relative): 3.979307e-02 | valid loss (relative): 3.912249e-02 
Epoch 242 use: 459.21 second.

epoch 243 starting......
Epoch:  243 | train loss: 2.004187e-03 | valid loss: 1.952305e-03 
      	| train loss (relative): 3.973171e-02 | valid loss (relative): 3.842940e-02 
Epoch 243 use: 470.01 second.

epoch 244 starting......
Epoch:  244 | train loss: 1.995567e-03 | valid loss: 1.973951e-03 
      	| train loss (relative): 3.955678e-02 | valid loss (relative): 3.860266e-02 
Epoch 244 use: 418.38 second.

epoch 245 starting......
Epoch:  245 | train loss: 2.005799e-03 | valid loss: 1.967580e-03 
      	| train loss (relative): 3.975730e-02 | valid loss (relative): 3.858861e-02 
Epoch 245 use: 435.68 second.

epoch 246 starting......
Epoch:  246 | train loss: 1.995668e-03 | valid loss: 1.953739e-03 
      	| train loss (relative): 3.956334e-02 | valid loss (relative): 3.824528e-02 
Epoch 246 use: 470.32 second.

epoch 247 starting......
Epoch:  247 | train loss: 1.993998e-03 | valid loss: 1.961396e-03 
      	| train loss (relative): 3.952806e-02 | valid loss (relative): 3.857123e-02 
Epoch 247 use: 432.43 second.

epoch 248 starting......
Epoch:  248 | train loss: 1.994361e-03 | valid loss: 1.955301e-03 
      	| train loss (relative): 3.953663e-02 | valid loss (relative): 3.859226e-02 
Epoch 248 use: 437.88 second.

epoch 249 starting......
Epoch:  249 | train loss: 1.997135e-03 | valid loss: 1.945980e-03 
      	| train loss (relative): 3.958901e-02 | valid loss (relative): 3.841720e-02 
Epoch 249 use: 434.83 second.

epoch 250 starting......
Epoch:  250 | train loss: 1.984117e-03 | valid loss: 1.943544e-03 
      	| train loss (relative): 3.932503e-02 | valid loss (relative): 3.799577e-02 
Epoch 250 use: 440.10 second.

epoch 251 starting......
Epoch:  251 | train loss: 1.993699e-03 | valid loss: 1.952544e-03 
      	| train loss (relative): 3.951108e-02 | valid loss (relative): 3.836682e-02 
Epoch 251 use: 426.21 second.

epoch 252 starting......
Epoch:  252 | train loss: 1.983704e-03 | valid loss: 1.951780e-03 
      	| train loss (relative): 3.931129e-02 | valid loss (relative): 3.810148e-02 
Epoch 252 use: 472.92 second.

epoch 253 starting......
Epoch:  253 | train loss: 1.978672e-03 | valid loss: 1.932587e-03 
      	| train loss (relative): 3.920456e-02 | valid loss (relative): 3.801969e-02 
Epoch 253 use: 473.31 second.

epoch 254 starting......
Epoch:  254 | train loss: 1.971197e-03 | valid loss: 1.933701e-03 
      	| train loss (relative): 3.905669e-02 | valid loss (relative): 3.805063e-02 
Epoch 254 use: 423.42 second.

epoch 255 starting......
Epoch:  255 | train loss: 1.974876e-03 | valid loss: 1.936020e-03 
      	| train loss (relative): 3.912358e-02 | valid loss (relative): 3.777726e-02 
Epoch 255 use: 463.79 second.

epoch 256 starting......
Epoch:  256 | train loss: 1.971898e-03 | valid loss: 1.964744e-03 
      	| train loss (relative): 3.907241e-02 | valid loss (relative): 3.932406e-02 
Epoch 256 use: 425.88 second.

epoch 257 starting......
Epoch:  257 | train loss: 1.982629e-03 | valid loss: 1.973781e-03 
      	| train loss (relative): 3.928585e-02 | valid loss (relative): 3.827903e-02 
Epoch 257 use: 458.92 second.

epoch 258 starting......
Epoch:  258 | train loss: 1.998383e-03 | valid loss: 1.925046e-03 
      	| train loss (relative): 3.958330e-02 | valid loss (relative): 3.799088e-02 
Epoch 258 use: 417.92 second.

epoch 259 starting......
Epoch:  259 | train loss: 1.963260e-03 | valid loss: 1.919100e-03 
      	| train loss (relative): 3.889462e-02 | valid loss (relative): 3.791932e-02 
Epoch 259 use: 445.18 second.

epoch 260 starting......
Epoch:  260 | train loss: 1.960168e-03 | valid loss: 1.924083e-03 
      	| train loss (relative): 3.883313e-02 | valid loss (relative): 3.802670e-02 
Epoch 260 use: 434.91 second.

epoch 261 starting......
Epoch:  261 | train loss: 1.962362e-03 | valid loss: 1.918337e-03 
      	| train loss (relative): 3.887840e-02 | valid loss (relative): 3.762610e-02 
Epoch 261 use: 484.93 second.

epoch 262 starting......
Epoch:  262 | train loss: 1.963647e-03 | valid loss: 1.922867e-03 
      	| train loss (relative): 3.889301e-02 | valid loss (relative): 3.774063e-02 
Epoch 262 use: 500.73 second.

epoch 263 starting......
Epoch:  263 | train loss: 1.961655e-03 | valid loss: 1.923727e-03 
      	| train loss (relative): 3.885254e-02 | valid loss (relative): 3.804781e-02 
Epoch 263 use: 435.23 second.

epoch 264 starting......
Epoch:  264 | train loss: 1.962324e-03 | valid loss: 1.926635e-03 
      	| train loss (relative): 3.886728e-02 | valid loss (relative): 3.776805e-02 
Epoch 264 use: 468.55 second.

epoch 265 starting......
Epoch:  265 | train loss: 1.959806e-03 | valid loss: 1.929653e-03 
      	| train loss (relative): 3.881589e-02 | valid loss (relative): 3.808516e-02 
Epoch 265 use: 439.14 second.

epoch 266 starting......
Epoch:  266 | train loss: 1.962317e-03 | valid loss: 1.922815e-03 
      	| train loss (relative): 3.886513e-02 | valid loss (relative): 3.782345e-02 
Epoch 266 use: 443.00 second.

epoch 267 starting......
Epoch:  267 | train loss: 1.957270e-03 | valid loss: 1.921264e-03 
      	| train loss (relative): 3.875976e-02 | valid loss (relative): 3.789328e-02 
Epoch 267 use: 475.65 second.

epoch 268 starting......
Epoch:  268 | train loss: 1.958863e-03 | valid loss: 1.935631e-03 
      	| train loss (relative): 3.879776e-02 | valid loss (relative): 3.782259e-02 
Epoch 268 use: 495.03 second.

epoch 269 starting......
Epoch:  269 | train loss: 1.959990e-03 | valid loss: 1.926451e-03 
      	| train loss (relative): 3.881289e-02 | valid loss (relative): 3.789961e-02 
Epoch 269 use: 431.26 second.

epoch 270 starting......
Epoch:  270 | train loss: 1.955412e-03 | valid loss: 1.924756e-03 
      	| train loss (relative): 3.872433e-02 | valid loss (relative): 3.820482e-02 
Epoch 270 use: 472.57 second.

epoch 271 starting......
Epoch:  271 | train loss: 1.953989e-03 | valid loss: 1.911138e-03 
      	| train loss (relative): 3.869876e-02 | valid loss (relative): 3.765831e-02 
Epoch 271 use: 435.91 second.

epoch 272 starting......
Epoch:  272 | train loss: 1.945683e-03 | valid loss: 1.915279e-03 
      	| train loss (relative): 3.852870e-02 | valid loss (relative): 3.763500e-02 
Epoch 272 use: 437.78 second.

epoch 273 starting......
Epoch:  273 | train loss: 1.950495e-03 | valid loss: 1.919218e-03 
      	| train loss (relative): 3.862207e-02 | valid loss (relative): 3.789885e-02 
Epoch 273 use: 434.19 second.

epoch 274 starting......
Epoch:  274 | train loss: 1.950632e-03 | valid loss: 1.913461e-03 
      	| train loss (relative): 3.862190e-02 | valid loss (relative): 3.783214e-02 
Epoch 274 use: 430.92 second.

epoch 275 starting......
Epoch:  275 | train loss: 1.952607e-03 | valid loss: 1.941322e-03 
      	| train loss (relative): 3.866098e-02 | valid loss (relative): 3.822569e-02 
Epoch 275 use: 446.84 second.

epoch 276 starting......
Epoch:  276 | train loss: 1.950115e-03 | valid loss: 1.906464e-03 
      	| train loss (relative): 3.860586e-02 | valid loss (relative): 3.737994e-02 
Epoch 276 use: 436.18 second.

epoch 277 starting......
Epoch:  277 | train loss: 1.938859e-03 | valid loss: 1.914509e-03 
      	| train loss (relative): 3.837713e-02 | valid loss (relative): 3.764003e-02 
Epoch 277 use: 438.31 second.

epoch 278 starting......
Epoch:  278 | train loss: 1.950014e-03 | valid loss: 1.901437e-03 
      	| train loss (relative): 3.861095e-02 | valid loss (relative): 3.740936e-02 
Epoch 278 use: 429.25 second.

epoch 279 starting......
Epoch:  279 | train loss: 1.936302e-03 | valid loss: 1.894359e-03 
      	| train loss (relative): 3.833187e-02 | valid loss (relative): 3.727746e-02 
Epoch 279 use: 429.06 second.

epoch 280 starting......
Epoch:  280 | train loss: 1.930120e-03 | valid loss: 1.907734e-03 
      	| train loss (relative): 3.820199e-02 | valid loss (relative): 3.798730e-02 
Epoch 280 use: 449.52 second.

epoch 281 starting......
Epoch:  281 | train loss: 1.931937e-03 | valid loss: 1.895004e-03 
      	| train loss (relative): 3.824012e-02 | valid loss (relative): 3.751791e-02 
Epoch 281 use: 429.06 second.

epoch 282 starting......
Epoch:  282 | train loss: 1.933020e-03 | valid loss: 1.913714e-03 
      	| train loss (relative): 3.825644e-02 | valid loss (relative): 3.764020e-02 
Epoch 282 use: 452.59 second.

epoch 283 starting......
Epoch:  283 | train loss: 1.933357e-03 | valid loss: 1.900269e-03 
      	| train loss (relative): 3.826654e-02 | valid loss (relative): 3.728087e-02 
Epoch 283 use: 437.28 second.

epoch 284 starting......
Epoch:  284 | train loss: 1.935106e-03 | valid loss: 1.924573e-03 
      	| train loss (relative): 3.829787e-02 | valid loss (relative): 3.792857e-02 
Epoch 284 use: 460.57 second.

epoch 285 starting......
Epoch:  285 | train loss: 1.934517e-03 | valid loss: 1.892764e-03 
      	| train loss (relative): 3.828744e-02 | valid loss (relative): 3.734244e-02 
Epoch 285 use: 434.30 second.

epoch 286 starting......
Epoch:  286 | train loss: 1.926156e-03 | valid loss: 1.891345e-03 
      	| train loss (relative): 3.811345e-02 | valid loss (relative): 3.709565e-02 
Epoch 286 use: 453.07 second.

epoch 287 starting......
Epoch:  287 | train loss: 1.924703e-03 | valid loss: 1.906660e-03 
      	| train loss (relative): 3.809170e-02 | valid loss (relative): 3.761795e-02 
Epoch 287 use: 455.67 second.

epoch 288 starting......
Epoch:  288 | train loss: 1.938068e-03 | valid loss: 1.934204e-03 
      	| train loss (relative): 3.835670e-02 | valid loss (relative): 3.784792e-02 
Epoch 288 use: 455.46 second.

epoch 289 starting......
Epoch:  289 | train loss: 1.933012e-03 | valid loss: 1.886956e-03 
      	| train loss (relative): 3.825477e-02 | valid loss (relative): 3.707368e-02 
Epoch 289 use: 480.40 second.

epoch 290 starting......
Epoch:  290 | train loss: 1.919833e-03 | valid loss: 1.904075e-03 
      	| train loss (relative): 3.799142e-02 | valid loss (relative): 3.780139e-02 
Epoch 290 use: 436.29 second.

epoch 291 starting......
Epoch:  291 | train loss: 1.927533e-03 | valid loss: 1.884802e-03 
      	| train loss (relative): 3.814745e-02 | valid loss (relative): 3.724754e-02 
Epoch 291 use: 466.52 second.

epoch 292 starting......
Epoch:  292 | train loss: 1.918804e-03 | valid loss: 1.889175e-03 
      	| train loss (relative): 3.797088e-02 | valid loss (relative): 3.717264e-02 
Epoch 292 use: 497.55 second.

epoch 293 starting......
Epoch:  293 | train loss: 1.923641e-03 | valid loss: 1.918539e-03 
      	| train loss (relative): 3.806250e-02 | valid loss (relative): 3.820138e-02 
Epoch 293 use: 446.99 second.

epoch 294 starting......
Epoch:  294 | train loss: 1.925646e-03 | valid loss: 1.880149e-03 
      	| train loss (relative): 3.810009e-02 | valid loss (relative): 3.699327e-02 
Epoch 294 use: 450.40 second.

epoch 295 starting......
Epoch:  295 | train loss: 1.912803e-03 | valid loss: 1.886525e-03 
      	| train loss (relative): 3.784535e-02 | valid loss (relative): 3.710495e-02 
Epoch 295 use: 481.48 second.

epoch 296 starting......
Epoch:  296 | train loss: 1.909262e-03 | valid loss: 1.869447e-03 
      	| train loss (relative): 3.777560e-02 | valid loss (relative): 3.691812e-02 
Epoch 296 use: 482.72 second.

epoch 297 starting......
Epoch:  297 | train loss: 1.904116e-03 | valid loss: 1.872441e-03 
      	| train loss (relative): 3.766774e-02 | valid loss (relative): 3.683821e-02 
Epoch 297 use: 442.00 second.

epoch 298 starting......
Epoch:  298 | train loss: 1.908135e-03 | valid loss: 1.869258e-03 
      	| train loss (relative): 3.774826e-02 | valid loss (relative): 3.687887e-02 
Epoch 298 use: 455.54 second.

epoch 299 starting......
Epoch:  299 | train loss: 1.902779e-03 | valid loss: 1.870436e-03 
      	| train loss (relative): 3.764013e-02 | valid loss (relative): 3.676407e-02 
Epoch 299 use: 449.14 second.

test MSE Error: 1.933229e-03 | relative MSE Error: 3.817054e-02 
 Total time used for training: 12.64 hour.
MESLoss saved to  /rds/general/user/jy220/home/new_results/Variational_False_Changelr_False_MSELoss_Latent_256_nearest_neighbouring_True_SFC_nums_3_startlr_0.001_n_epoches_300.txt
relative MSELoss saved to  /rds/general/user/jy220/home/new_results/Variational_False_Changelr_False_reMSELoss_Latent_256_nearest_neighbouring_True_SFC_nums_3_startlr_0.001_n_epoches_300.txt
model saved to /rds/general/user/jy220/home/new_results/Variational_False_Changelr_False_Latent_256_Nearest_neighbouring_True_SFC_nums_3_startlr_0.001_n_epoches_300.pth
model_dict saved to /rds/general/user/jy220/home/new_results/Variational_False_Changelr_False_Latent_256_Nearest_neighbouring_True_SFC_nums_3_startlr_0.001_n_epoches_300_dict.pth
... Training slugflow data completed, Run finished Fri 13 Aug 11:35:39 BST 2021 ...
{'data_dir': '/rds/general/user/jy220/home/tensors/', 'data_type': 'tensors', 'vtu_fields': 'Component1::ComponentMassFractionPhase1, phase1::Velocity', 'variational': 'False', 'optimizer': 'Adamax', 'structured': 'False', 'changing_lr': 'False', 'self_concat': '2', 'dimension': '3', 'sfc_nums': '3', 'components': '4', 'nearest_neighbouring': 'True', 'dims_latent': '256', 'activation': 'Tanh', 'sfc_file': '/rds/general/user/jy220/home/SFC-CAE-Ready-to-use/sfcs.pt', 'inv_sfc_file': '/rds/general/user/jy220/home/SFC-CAE-Ready-to-use/inv_sfcs.pt', 'coords_file': '/rds/general/user/jy220/home/SFC-CAE-Ready-to-use/coords.pt', 'cells_file': '/rds/general/user/jy220/home/SFC-CAE-Ready-to-use/cells.npy', 'state_load': '/rds/general/user/jy220/home/new_results/Variational_False_Changelr_False_Latent_256_Nearest_neighbouring_True_SFC_nums_3_startlr_0.001_n_epoches_300_dict.pth', 'batch_size': '16', 'lr': '0.001', 'n_epoches': '150', 'seed': '17', 'visualize': 'False', 'reconstructed_path': 'None', 'reconstruct_start_index': '0', 'reconstruct_end_index': '50', 'save_path': '/rds/general/user/jy220/home/new_results/'}
[[ 2.50825269e-01 -1.67256990e-02 -1.22268730e-03]
 [ 2.38611959e-01 -5.50627777e-03 -5.06451913e-03]
 [ 2.39454874e-01 -1.59563257e-02  3.96778323e-03]
 ...
 [ 9.11361096e+00 -2.21908381e-02  2.22384902e-03]
 [ 9.11847310e+00 -2.84346931e-02 -2.34839590e-04]
 [ 9.11039661e+00 -2.51498573e-02 -8.70661044e-03]]
{'tetra': array([[      0,       1,       2,       3],
       [      4,       5,       6,       7],
       [      8,       9,      10,      11],
       ...,
       [1342744, 1342745, 1342746, 1342747],
       [1342748, 1342749, 1342750, 1342751],
       [1342752, 1342753, 1342754, 1342755]])}
vtu fields:  ['Component1::ComponentMassFractionPhase1', 'phase1::Velocity'] 
 structured  False 
 activation  Tanh() 
 self concat  2 
 sfc_nums  3 

dims_latent  256 
 components  4 
 nearest_neighbouring  True 

visualize  False 
 sample number  1706 

reading sfc nums......
[array([  41684,   41685,   41674, ..., 1235560, 1235564, 1235558]), array([954289, 954290, 954291, ..., 420685, 420687, 420688]), array([  40156,   40155,   40158, ..., 1123478, 1123475, 1123467])]
reading inverse sfc nums......
[array([   8146,    8145,    8144, ..., 1274444, 1274445, 1273166]), array([547280, 547283, 593037, ..., 933933, 933932, 864488]), array([ 66437,  66439, 122512, ..., 459416, 415130, 459418])]
Computing min and max......

tk:  tensor([0.7581, 0.0418, 0.1840, 0.1464], dtype=torch.float64) 

tb:  tensor([-0.3816, -0.3618, -0.0308,  0.1446], dtype=torch.float64) 

length of train set: 1505 

length of valid set: 100 

length of test set: 101 

torch device num: 4 

Let's use 4 GPUs!
epoch 300 starting......
Epoch:  300 | train loss: 2.245782e-03 | valid loss: 1.927923e-03 
      	| train loss (relative): 4.435267e-02 | valid loss (relative): 3.792942e-02 
Epoch 300 use: 620.03 second.

epoch 301 starting......
Epoch:  301 | train loss: 1.916770e-03 | valid loss: 1.903137e-03 
      	| train loss (relative): 3.793878e-02 | valid loss (relative): 3.744324e-02 
Epoch 301 use: 443.92 second.

epoch 302 starting......
Epoch:  302 | train loss: 1.902005e-03 | valid loss: 1.896866e-03 
      	| train loss (relative): 3.764005e-02 | valid loss (relative): 3.734411e-02 
Epoch 302 use: 415.91 second.

epoch 303 starting......
Epoch:  303 | train loss: 1.893690e-03 | valid loss: 1.892686e-03 
      	| train loss (relative): 3.746705e-02 | valid loss (relative): 3.725249e-02 
Epoch 303 use: 439.47 second.

epoch 304 starting......
Epoch:  304 | train loss: 1.889160e-03 | valid loss: 1.891887e-03 
      	| train loss (relative): 3.736992e-02 | valid loss (relative): 3.720588e-02 
Epoch 304 use: 509.47 second.

epoch 305 starting......
Epoch:  305 | train loss: 1.887997e-03 | valid loss: 1.890734e-03 
      	| train loss (relative): 3.734378e-02 | valid loss (relative): 3.716186e-02 
Epoch 305 use: 479.51 second.

epoch 306 starting......
Epoch:  306 | train loss: 1.884929e-03 | valid loss: 1.891253e-03 
      	| train loss (relative): 3.728328e-02 | valid loss (relative): 3.724664e-02 
Epoch 306 use: 439.75 second.

epoch 307 starting......
Epoch:  307 | train loss: 1.886068e-03 | valid loss: 1.893785e-03 
      	| train loss (relative): 3.730425e-02 | valid loss (relative): 3.732444e-02 
Epoch 307 use: 426.81 second.

epoch 308 starting......
Epoch:  308 | train loss: 1.890082e-03 | valid loss: 1.892253e-03 
      	| train loss (relative): 3.738390e-02 | valid loss (relative): 3.722011e-02 
Epoch 308 use: 425.69 second.

epoch 309 starting......
Epoch:  309 | train loss: 1.885152e-03 | valid loss: 1.892095e-03 
      	| train loss (relative): 3.727791e-02 | valid loss (relative): 3.726029e-02 
Epoch 309 use: 443.80 second.

epoch 310 starting......
Epoch:  310 | train loss: 1.883478e-03 | valid loss: 1.889493e-03 
      	| train loss (relative): 3.724765e-02 | valid loss (relative): 3.721750e-02 
Epoch 310 use: 437.85 second.

epoch 311 starting......
Epoch:  311 | train loss: 1.883296e-03 | valid loss: 1.893527e-03 
      	| train loss (relative): 3.724147e-02 | valid loss (relative): 3.723373e-02 
Epoch 311 use: 448.37 second.

epoch 312 starting......
Epoch:  312 | train loss: 1.887575e-03 | valid loss: 1.894330e-03 
      	| train loss (relative): 3.732481e-02 | valid loss (relative): 3.735154e-02 
Epoch 312 use: 435.87 second.

epoch 313 starting......
Epoch:  313 | train loss: 1.885284e-03 | valid loss: 1.893146e-03 
      	| train loss (relative): 3.728101e-02 | valid loss (relative): 3.716110e-02 
Epoch 313 use: 430.07 second.

epoch 314 starting......
Epoch:  314 | train loss: 1.885679e-03 | valid loss: 1.893721e-03 
      	| train loss (relative): 3.728634e-02 | valid loss (relative): 3.725544e-02 
Epoch 314 use: 409.72 second.

epoch 315 starting......
Epoch:  315 | train loss: 1.883340e-03 | valid loss: 1.891692e-03 
      	| train loss (relative): 3.724407e-02 | valid loss (relative): 3.715795e-02 
Epoch 315 use: 401.95 second.

epoch 316 starting......
Epoch:  316 | train loss: 1.884552e-03 | valid loss: 1.897210e-03 
      	| train loss (relative): 3.726242e-02 | valid loss (relative): 3.745111e-02 
Epoch 316 use: 412.63 second.

epoch 317 starting......
Epoch:  317 | train loss: 1.883571e-03 | valid loss: 1.889601e-03 
      	| train loss (relative): 3.725263e-02 | valid loss (relative): 3.713672e-02 
Epoch 317 use: 380.65 second.

epoch 318 starting......
Epoch:  318 | train loss: 1.878948e-03 | valid loss: 1.891458e-03 
      	| train loss (relative): 3.715028e-02 | valid loss (relative): 3.707603e-02 
Epoch 318 use: 423.48 second.

epoch 319 starting......
Epoch:  319 | train loss: 1.875810e-03 | valid loss: 1.893844e-03 
      	| train loss (relative): 3.707956e-02 | valid loss (relative): 3.716744e-02 
Epoch 319 use: 476.44 second.

epoch 320 starting......
Epoch:  320 | train loss: 1.877314e-03 | valid loss: 1.894511e-03 
      	| train loss (relative): 3.711394e-02 | valid loss (relative): 3.720378e-02 
Epoch 320 use: 408.19 second.

epoch 321 starting......
Epoch:  321 | train loss: 1.881710e-03 | valid loss: 1.899048e-03 
      	| train loss (relative): 3.720316e-02 | valid loss (relative): 3.736219e-02 
Epoch 321 use: 395.03 second.

epoch 322 starting......
Epoch:  322 | train loss: 1.878936e-03 | valid loss: 1.905804e-03 
      	| train loss (relative): 3.715444e-02 | valid loss (relative): 3.716301e-02 
Epoch 322 use: 365.13 second.

epoch 323 starting......
Epoch:  323 | train loss: 1.882669e-03 | valid loss: 1.900621e-03 
      	| train loss (relative): 3.721619e-02 | valid loss (relative): 3.735564e-02 
Epoch 323 use: 346.45 second.

epoch 324 starting......
Epoch:  324 | train loss: 1.880151e-03 | valid loss: 1.905522e-03 
      	| train loss (relative): 3.717114e-02 | valid loss (relative): 3.774431e-02 
Epoch 324 use: 355.55 second.

epoch 325 starting......
Epoch:  325 | train loss: 1.879630e-03 | valid loss: 1.898291e-03 
      	| train loss (relative): 3.716067e-02 | valid loss (relative): 3.753173e-02 
Epoch 325 use: 349.92 second.

epoch 326 starting......
Epoch:  326 | train loss: 1.875360e-03 | valid loss: 1.892799e-03 
      	| train loss (relative): 3.707706e-02 | valid loss (relative): 3.753673e-02 
Epoch 326 use: 347.43 second.

epoch 327 starting......
Epoch:  327 | train loss: 1.875006e-03 | valid loss: 1.897828e-03 
      	| train loss (relative): 3.706586e-02 | valid loss (relative): 3.726871e-02 
Epoch 327 use: 363.08 second.

epoch 328 starting......
Epoch:  328 | train loss: 1.877607e-03 | valid loss: 1.919217e-03 
      	| train loss (relative): 3.711554e-02 | valid loss (relative): 3.751745e-02 
Epoch 328 use: 366.22 second.

epoch 329 starting......
Epoch:  329 | train loss: 1.883431e-03 | valid loss: 1.890427e-03 
      	| train loss (relative): 3.723025e-02 | valid loss (relative): 3.725645e-02 
Epoch 329 use: 344.92 second.

epoch 330 starting......
Epoch:  330 | train loss: 1.871948e-03 | valid loss: 1.898570e-03 
      	| train loss (relative): 3.700646e-02 | valid loss (relative): 3.744961e-02 
Epoch 330 use: 352.35 second.

epoch 331 starting......
Epoch:  331 | train loss: 1.869796e-03 | valid loss: 1.892369e-03 
      	| train loss (relative): 3.695237e-02 | valid loss (relative): 3.719484e-02 
Epoch 331 use: 392.43 second.

epoch 332 starting......
Epoch:  332 | train loss: 1.872264e-03 | valid loss: 1.896134e-03 
      	| train loss (relative): 3.701727e-02 | valid loss (relative): 3.698063e-02 
Epoch 332 use: 344.60 second.

epoch 333 starting......
Epoch:  333 | train loss: 1.875030e-03 | valid loss: 1.912712e-03 
      	| train loss (relative): 3.705680e-02 | valid loss (relative): 3.784039e-02 
Epoch 333 use: 361.79 second.

epoch 334 starting......
Epoch:  334 | train loss: 1.872659e-03 | valid loss: 1.887147e-03 
      	| train loss (relative): 3.701344e-02 | valid loss (relative): 3.703957e-02 
Epoch 334 use: 351.50 second.

epoch 335 starting......
Epoch:  335 | train loss: 1.868782e-03 | valid loss: 1.889463e-03 
      	| train loss (relative): 3.693480e-02 | valid loss (relative): 3.707360e-02 
Epoch 335 use: 393.97 second.

epoch 336 starting......
Epoch:  336 | train loss: 1.869023e-03 | valid loss: 1.896378e-03 
      	| train loss (relative): 3.693089e-02 | valid loss (relative): 3.745404e-02 
Epoch 336 use: 360.66 second.

epoch 337 starting......
Epoch:  337 | train loss: 1.865274e-03 | valid loss: 1.881893e-03 
      	| train loss (relative): 3.685998e-02 | valid loss (relative): 3.693910e-02 
Epoch 337 use: 354.83 second.

epoch 338 starting......
Epoch:  338 | train loss: 1.866509e-03 | valid loss: 1.895047e-03 
      	| train loss (relative): 3.688399e-02 | valid loss (relative): 3.702211e-02 
Epoch 338 use: 343.15 second.

epoch 339 starting......
Epoch:  339 | train loss: 1.867957e-03 | valid loss: 1.899467e-03 
      	| train loss (relative): 3.691435e-02 | valid loss (relative): 3.722708e-02 
Epoch 339 use: 401.20 second.

epoch 340 starting......
Epoch:  340 | train loss: 1.865495e-03 | valid loss: 1.895090e-03 
      	| train loss (relative): 3.686330e-02 | valid loss (relative): 3.689710e-02 
Epoch 340 use: 350.69 second.

epoch 341 starting......
Epoch:  341 | train loss: 1.862666e-03 | valid loss: 1.874087e-03 
      	| train loss (relative): 3.680244e-02 | valid loss (relative): 3.683000e-02 
Epoch 341 use: 348.23 second.

epoch 342 starting......
Epoch:  342 | train loss: 1.855724e-03 | valid loss: 1.888032e-03 
      	| train loss (relative): 3.666628e-02 | valid loss (relative): 3.726763e-02 
Epoch 342 use: 340.24 second.

epoch 343 starting......
Epoch:  343 | train loss: 1.861261e-03 | valid loss: 1.919723e-03 
      	| train loss (relative): 3.677849e-02 | valid loss (relative): 3.704844e-02 
Epoch 343 use: 340.68 second.

epoch 344 starting......
Epoch:  344 | train loss: 1.854950e-03 | valid loss: 1.867939e-03 
      	| train loss (relative): 3.664725e-02 | valid loss (relative): 3.644948e-02 
Epoch 344 use: 354.06 second.

epoch 345 starting......
Epoch:  345 | train loss: 1.845747e-03 | valid loss: 1.864964e-03 
      	| train loss (relative): 3.646249e-02 | valid loss (relative): 3.666685e-02 
Epoch 345 use: 364.09 second.

epoch 346 starting......
Epoch:  346 | train loss: 1.842579e-03 | valid loss: 1.865083e-03 
      	| train loss (relative): 3.640316e-02 | valid loss (relative): 3.651764e-02 
Epoch 346 use: 339.14 second.

epoch 347 starting......
Epoch:  347 | train loss: 1.844706e-03 | valid loss: 1.878584e-03 
      	| train loss (relative): 3.643541e-02 | valid loss (relative): 3.717455e-02 
Epoch 347 use: 350.35 second.

epoch 348 starting......
Epoch:  348 | train loss: 1.852357e-03 | valid loss: 1.891584e-03 
      	| train loss (relative): 3.659551e-02 | valid loss (relative): 3.728916e-02 
Epoch 348 use: 348.57 second.

epoch 349 starting......
Epoch:  349 | train loss: 1.855131e-03 | valid loss: 1.869518e-03 
      	| train loss (relative): 3.665410e-02 | valid loss (relative): 3.677147e-02 
Epoch 349 use: 349.95 second.

epoch 350 starting......
Epoch:  350 | train loss: 1.840579e-03 | valid loss: 1.861157e-03 
      	| train loss (relative): 3.635727e-02 | valid loss (relative): 3.643562e-02 
Epoch 350 use: 342.63 second.

epoch 351 starting......
Epoch:  351 | train loss: 1.842368e-03 | valid loss: 1.873496e-03 
      	| train loss (relative): 3.639032e-02 | valid loss (relative): 3.706979e-02 
Epoch 351 use: 355.24 second.

epoch 352 starting......
Epoch:  352 | train loss: 1.845420e-03 | valid loss: 1.862781e-03 
      	| train loss (relative): 3.645285e-02 | valid loss (relative): 3.661210e-02 
Epoch 352 use: 337.45 second.

epoch 353 starting......
Epoch:  353 | train loss: 1.842950e-03 | valid loss: 1.873226e-03 
      	| train loss (relative): 3.640163e-02 | valid loss (relative): 3.716789e-02 
Epoch 353 use: 353.51 second.

epoch 354 starting......
Epoch:  354 | train loss: 1.840696e-03 | valid loss: 1.872191e-03 
      	| train loss (relative): 3.635851e-02 | valid loss (relative): 3.667061e-02 
Epoch 354 use: 352.27 second.

epoch 355 starting......
Epoch:  355 | train loss: 1.844329e-03 | valid loss: 1.870840e-03 
      	| train loss (relative): 3.642282e-02 | valid loss (relative): 3.696298e-02 
Epoch 355 use: 350.15 second.

epoch 356 starting......
Epoch:  356 | train loss: 1.846550e-03 | valid loss: 1.874601e-03 
      	| train loss (relative): 3.647121e-02 | valid loss (relative): 3.705017e-02 
Epoch 356 use: 342.38 second.

epoch 357 starting......
Epoch:  357 | train loss: 1.838732e-03 | valid loss: 1.874193e-03 
      	| train loss (relative): 3.631589e-02 | valid loss (relative): 3.645994e-02 
Epoch 357 use: 359.44 second.

epoch 358 starting......
Epoch:  358 | train loss: 1.843590e-03 | valid loss: 1.867842e-03 
      	| train loss (relative): 3.641282e-02 | valid loss (relative): 3.663039e-02 
Epoch 358 use: 354.38 second.

epoch 359 starting......
Epoch:  359 | train loss: 1.837227e-03 | valid loss: 1.853536e-03 
      	| train loss (relative): 3.627756e-02 | valid loss (relative): 3.628433e-02 
Epoch 359 use: 346.29 second.

epoch 360 starting......
Epoch:  360 | train loss: 1.827761e-03 | valid loss: 1.885645e-03 
      	| train loss (relative): 3.609146e-02 | valid loss (relative): 3.670739e-02 
Epoch 360 use: 349.42 second.

epoch 361 starting......
Epoch:  361 | train loss: 1.837156e-03 | valid loss: 1.850559e-03 
      	| train loss (relative): 3.627264e-02 | valid loss (relative): 3.616610e-02 
Epoch 361 use: 358.71 second.

epoch 362 starting......
Epoch:  362 | train loss: 1.826286e-03 | valid loss: 1.854757e-03 
      	| train loss (relative): 3.606293e-02 | valid loss (relative): 3.640071e-02 
Epoch 362 use: 343.31 second.

epoch 363 starting......
Epoch:  363 | train loss: 1.828294e-03 | valid loss: 1.857787e-03 
      	| train loss (relative): 3.609871e-02 | valid loss (relative): 3.647083e-02 
Epoch 363 use: 355.24 second.

epoch 364 starting......
Epoch:  364 | train loss: 1.828479e-03 | valid loss: 1.856604e-03 
      	| train loss (relative): 3.610454e-02 | valid loss (relative): 3.622283e-02 
Epoch 364 use: 345.78 second.

epoch 365 starting......
Epoch:  365 | train loss: 1.826450e-03 | valid loss: 1.861135e-03 
      	| train loss (relative): 3.607012e-02 | valid loss (relative): 3.665925e-02 
Epoch 365 use: 367.11 second.

epoch 366 starting......
Epoch:  366 | train loss: 1.829140e-03 | valid loss: 1.861554e-03 
      	| train loss (relative): 3.611648e-02 | valid loss (relative): 3.671850e-02 
Epoch 366 use: 355.60 second.

epoch 367 starting......
Epoch:  367 | train loss: 1.830921e-03 | valid loss: 1.854178e-03 
      	| train loss (relative): 3.615767e-02 | valid loss (relative): 3.646987e-02 
Epoch 367 use: 341.82 second.

epoch 368 starting......
Epoch:  368 | train loss: 1.829868e-03 | valid loss: 1.855999e-03 
      	| train loss (relative): 3.612946e-02 | valid loss (relative): 3.654034e-02 
Epoch 368 use: 365.66 second.

epoch 369 starting......
Epoch:  369 | train loss: 1.826401e-03 | valid loss: 1.859240e-03 
      	| train loss (relative): 3.605999e-02 | valid loss (relative): 3.662398e-02 
Epoch 369 use: 349.74 second.

epoch 370 starting......
Epoch:  370 | train loss: 1.830908e-03 | valid loss: 1.861419e-03 
      	| train loss (relative): 3.614361e-02 | valid loss (relative): 3.642497e-02 
Epoch 370 use: 347.80 second.

epoch 371 starting......
Epoch:  371 | train loss: 1.827437e-03 | valid loss: 1.848910e-03 
      	| train loss (relative): 3.608504e-02 | valid loss (relative): 3.622956e-02 
Epoch 371 use: 353.35 second.

epoch 372 starting......
Epoch:  372 | train loss: 1.822961e-03 | valid loss: 1.849937e-03 
      	| train loss (relative): 3.598902e-02 | valid loss (relative): 3.599707e-02 
Epoch 372 use: 345.50 second.

epoch 373 starting......
Epoch:  373 | train loss: 1.821246e-03 | valid loss: 1.851828e-03 
      	| train loss (relative): 3.594971e-02 | valid loss (relative): 3.619430e-02 
Epoch 373 use: 351.44 second.

epoch 374 starting......
Epoch:  374 | train loss: 1.818979e-03 | valid loss: 1.846689e-03 
      	| train loss (relative): 3.590488e-02 | valid loss (relative): 3.654468e-02 
Epoch 374 use: 356.12 second.

epoch 375 starting......
Epoch:  375 | train loss: 1.818248e-03 | valid loss: 1.848535e-03 
      	| train loss (relative): 3.589482e-02 | valid loss (relative): 3.616854e-02 
Epoch 375 use: 338.23 second.

epoch 376 starting......
Epoch:  376 | train loss: 1.826230e-03 | valid loss: 1.861612e-03 
      	| train loss (relative): 3.605182e-02 | valid loss (relative): 3.669222e-02 
Epoch 376 use: 344.81 second.

epoch 377 starting......
Epoch:  377 | train loss: 1.819595e-03 | valid loss: 1.844912e-03 
      	| train loss (relative): 3.591363e-02 | valid loss (relative): 3.636692e-02 
Epoch 377 use: 371.31 second.

epoch 378 starting......
Epoch:  378 | train loss: 1.815318e-03 | valid loss: 1.844415e-03 
      	| train loss (relative): 3.583214e-02 | valid loss (relative): 3.596929e-02 
Epoch 378 use: 348.60 second.

epoch 379 starting......
Epoch:  379 | train loss: 1.815876e-03 | valid loss: 1.853515e-03 
      	| train loss (relative): 3.584871e-02 | valid loss (relative): 3.624735e-02 
Epoch 379 use: 345.50 second.

epoch 380 starting......
Epoch:  380 | train loss: 1.816111e-03 | valid loss: 1.846788e-03 
      	| train loss (relative): 3.584385e-02 | valid loss (relative): 3.654912e-02 
Epoch 380 use: 361.90 second.

epoch 381 starting......
Epoch:  381 | train loss: 1.814577e-03 | valid loss: 1.850235e-03 
      	| train loss (relative): 3.582071e-02 | valid loss (relative): 3.629653e-02 
Epoch 381 use: 378.67 second.

epoch 382 starting......
Epoch:  382 | train loss: 1.811197e-03 | valid loss: 1.840706e-03 
      	| train loss (relative): 3.574356e-02 | valid loss (relative): 3.650045e-02 
Epoch 382 use: 358.08 second.

epoch 383 starting......
Epoch:  383 | train loss: 1.810984e-03 | valid loss: 1.838088e-03 
      	| train loss (relative): 3.574622e-02 | valid loss (relative): 3.633674e-02 
Epoch 383 use: 361.56 second.

epoch 384 starting......
Epoch:  384 | train loss: 1.806407e-03 | valid loss: 1.841094e-03 
      	| train loss (relative): 3.565060e-02 | valid loss (relative): 3.640819e-02 
Epoch 384 use: 368.27 second.

epoch 385 starting......
Epoch:  385 | train loss: 1.805378e-03 | valid loss: 1.840772e-03 
      	| train loss (relative): 3.563196e-02 | valid loss (relative): 3.617246e-02 
Epoch 385 use: 366.21 second.

epoch 386 starting......
Epoch:  386 | train loss: 1.809674e-03 | valid loss: 1.834528e-03 
      	| train loss (relative): 3.571156e-02 | valid loss (relative): 3.605349e-02 
Epoch 386 use: 387.24 second.

epoch 387 starting......
Epoch:  387 | train loss: 1.804029e-03 | valid loss: 1.836530e-03 
      	| train loss (relative): 3.560146e-02 | valid loss (relative): 3.595929e-02 
Epoch 387 use: 386.49 second.

epoch 388 starting......
Epoch:  388 | train loss: 1.804030e-03 | valid loss: 1.839381e-03 
      	| train loss (relative): 3.560258e-02 | valid loss (relative): 3.587248e-02 
Epoch 388 use: 381.75 second.

epoch 389 starting......
Epoch:  389 | train loss: 1.809520e-03 | valid loss: 1.866083e-03 
      	| train loss (relative): 3.571036e-02 | valid loss (relative): 3.692415e-02 
Epoch 389 use: 370.48 second.

epoch 390 starting......
Epoch:  390 | train loss: 1.809292e-03 | valid loss: 1.838435e-03 
      	| train loss (relative): 3.570993e-02 | valid loss (relative): 3.603986e-02 
Epoch 390 use: 374.60 second.

epoch 391 starting......
Epoch:  391 | train loss: 1.803917e-03 | valid loss: 1.866883e-03 
      	| train loss (relative): 3.560012e-02 | valid loss (relative): 3.622557e-02 
Epoch 391 use: 373.33 second.

epoch 392 starting......
Epoch:  392 | train loss: 1.808042e-03 | valid loss: 1.829928e-03 
      	| train loss (relative): 3.567396e-02 | valid loss (relative): 3.586584e-02 
Epoch 392 use: 359.06 second.

epoch 393 starting......
Epoch:  393 | train loss: 1.796286e-03 | valid loss: 1.838611e-03 
      	| train loss (relative): 3.545057e-02 | valid loss (relative): 3.605125e-02 
Epoch 393 use: 360.34 second.

epoch 394 starting......
Epoch:  394 | train loss: 1.800448e-03 | valid loss: 1.824997e-03 
      	| train loss (relative): 3.552314e-02 | valid loss (relative): 3.580946e-02 
Epoch 394 use: 359.53 second.

epoch 395 starting......
Epoch:  395 | train loss: 1.791897e-03 | valid loss: 1.824904e-03 
      	| train loss (relative): 3.535882e-02 | valid loss (relative): 3.605628e-02 
Epoch 395 use: 356.39 second.

epoch 396 starting......
Epoch:  396 | train loss: 1.792292e-03 | valid loss: 1.820832e-03 
      	| train loss (relative): 3.536367e-02 | valid loss (relative): 3.581581e-02 
Epoch 396 use: 355.26 second.

epoch 397 starting......
Epoch:  397 | train loss: 1.793444e-03 | valid loss: 1.839938e-03 
      	| train loss (relative): 3.538839e-02 | valid loss (relative): 3.603375e-02 
Epoch 397 use: 340.36 second.

epoch 398 starting......
Epoch:  398 | train loss: 1.794252e-03 | valid loss: 1.817187e-03 
      	| train loss (relative): 3.539510e-02 | valid loss (relative): 3.563204e-02 
Epoch 398 use: 360.74 second.

epoch 399 starting......
Epoch:  399 | train loss: 1.791678e-03 | valid loss: 1.829687e-03 
      	| train loss (relative): 3.534412e-02 | valid loss (relative): 3.570002e-02 
Epoch 399 use: 342.03 second.

epoch 400 starting......
Epoch:  400 | train loss: 1.793952e-03 | valid loss: 1.832410e-03 
      	| train loss (relative): 3.538932e-02 | valid loss (relative): 3.602599e-02 
Epoch 400 use: 361.85 second.

epoch 401 starting......
Epoch:  401 | train loss: 1.794594e-03 | valid loss: 1.831502e-03 
      	| train loss (relative): 3.540628e-02 | valid loss (relative): 3.600178e-02 
Epoch 401 use: 344.18 second.

epoch 402 starting......
Epoch:  402 | train loss: 1.790472e-03 | valid loss: 1.829151e-03 
      	| train loss (relative): 3.532550e-02 | valid loss (relative): 3.567502e-02 
Epoch 402 use: 355.43 second.

epoch 403 starting......
Epoch:  403 | train loss: 1.788648e-03 | valid loss: 1.842025e-03 
      	| train loss (relative): 3.528759e-02 | valid loss (relative): 3.629380e-02 
Epoch 403 use: 352.96 second.

epoch 404 starting......
Epoch:  404 | train loss: 1.792356e-03 | valid loss: 1.815852e-03 
      	| train loss (relative): 3.535865e-02 | valid loss (relative): 3.562575e-02 
Epoch 404 use: 359.09 second.

epoch 405 starting......
Epoch:  405 | train loss: 1.787566e-03 | valid loss: 1.835551e-03 
      	| train loss (relative): 3.526056e-02 | valid loss (relative): 3.568782e-02 
Epoch 405 use: 373.77 second.

epoch 406 starting......
Epoch:  406 | train loss: 1.789889e-03 | valid loss: 1.834247e-03 
      	| train loss (relative): 3.530586e-02 | valid loss (relative): 3.621896e-02 
Epoch 406 use: 366.82 second.

epoch 407 starting......
Epoch:  407 | train loss: 1.787332e-03 | valid loss: 1.817153e-03 
      	| train loss (relative): 3.526050e-02 | valid loss (relative): 3.563806e-02 
Epoch 407 use: 377.54 second.

epoch 408 starting......
Epoch:  408 | train loss: 1.786694e-03 | valid loss: 1.822043e-03 
      	| train loss (relative): 3.524556e-02 | valid loss (relative): 3.560277e-02 
Epoch 408 use: 378.33 second.

epoch 409 starting......
Epoch:  409 | train loss: 1.787729e-03 | valid loss: 1.832256e-03 
      	| train loss (relative): 3.525997e-02 | valid loss (relative): 3.597018e-02 
Epoch 409 use: 376.78 second.

epoch 410 starting......
Epoch:  410 | train loss: 1.784069e-03 | valid loss: 1.809194e-03 
      	| train loss (relative): 3.519019e-02 | valid loss (relative): 3.547672e-02 
Epoch 410 use: 374.76 second.

epoch 411 starting......
Epoch:  411 | train loss: 1.776964e-03 | valid loss: 1.812472e-03 
      	| train loss (relative): 3.505113e-02 | valid loss (relative): 3.559527e-02 
Epoch 411 use: 397.21 second.

epoch 412 starting......
Epoch:  412 | train loss: 1.778543e-03 | valid loss: 1.827487e-03 
      	| train loss (relative): 3.508604e-02 | valid loss (relative): 3.594097e-02 
Epoch 412 use: 373.56 second.

epoch 413 starting......
Epoch:  413 | train loss: 1.785694e-03 | valid loss: 1.819381e-03 
      	| train loss (relative): 3.522133e-02 | valid loss (relative): 3.555948e-02 
Epoch 413 use: 368.19 second.

epoch 414 starting......
Epoch:  414 | train loss: 1.774672e-03 | valid loss: 1.803711e-03 
      	| train loss (relative): 3.500330e-02 | valid loss (relative): 3.562069e-02 
Epoch 414 use: 372.14 second.

epoch 415 starting......
Epoch:  415 | train loss: 1.769847e-03 | valid loss: 1.803856e-03 
      	| train loss (relative): 3.490635e-02 | valid loss (relative): 3.554423e-02 
Epoch 415 use: 367.71 second.

epoch 416 starting......
Epoch:  416 | train loss: 1.772351e-03 | valid loss: 1.810118e-03 
      	| train loss (relative): 3.495152e-02 | valid loss (relative): 3.569035e-02 
Epoch 416 use: 384.44 second.

epoch 417 starting......
Epoch:  417 | train loss: 1.774769e-03 | valid loss: 1.806140e-03 
      	| train loss (relative): 3.499737e-02 | valid loss (relative): 3.542041e-02 
Epoch 417 use: 380.28 second.

epoch 418 starting......
Epoch:  418 | train loss: 1.772688e-03 | valid loss: 1.818488e-03 
      	| train loss (relative): 3.495447e-02 | valid loss (relative): 3.523665e-02 
Epoch 418 use: 395.05 second.

epoch 419 starting......
Epoch:  419 | train loss: 1.773883e-03 | valid loss: 1.821614e-03 
      	| train loss (relative): 3.497972e-02 | valid loss (relative): 3.547557e-02 
Epoch 419 use: 398.70 second.

epoch 420 starting......
Epoch:  420 | train loss: 1.776880e-03 | valid loss: 1.811341e-03 
      	| train loss (relative): 3.504235e-02 | valid loss (relative): 3.550889e-02 
Epoch 420 use: 361.47 second.

epoch 421 starting......
Epoch:  421 | train loss: 1.768743e-03 | valid loss: 1.807091e-03 
      	| train loss (relative): 3.487812e-02 | valid loss (relative): 3.557873e-02 
Epoch 421 use: 379.09 second.

epoch 422 starting......
Epoch:  422 | train loss: 1.766300e-03 | valid loss: 1.797291e-03 
      	| train loss (relative): 3.483637e-02 | valid loss (relative): 3.520709e-02 
Epoch 422 use: 364.07 second.

epoch 423 starting......
Epoch:  423 | train loss: 1.764353e-03 | valid loss: 1.798293e-03 
      	| train loss (relative): 3.479068e-02 | valid loss (relative): 3.522645e-02 
Epoch 423 use: 351.06 second.

epoch 424 starting......
Epoch:  424 | train loss: 1.767623e-03 | valid loss: 1.796643e-03 
      	| train loss (relative): 3.485573e-02 | valid loss (relative): 3.523155e-02 
Epoch 424 use: 371.96 second.

epoch 425 starting......
Epoch:  425 | train loss: 1.761886e-03 | valid loss: 1.796588e-03 
      	| train loss (relative): 3.473928e-02 | valid loss (relative): 3.511592e-02 
Epoch 425 use: 358.79 second.

epoch 426 starting......
Epoch:  426 | train loss: 1.765566e-03 | valid loss: 1.796500e-03 
      	| train loss (relative): 3.481244e-02 | valid loss (relative): 3.533469e-02 
Epoch 426 use: 360.95 second.

epoch 427 starting......
Epoch:  427 | train loss: 1.767618e-03 | valid loss: 1.803798e-03 
      	| train loss (relative): 3.485409e-02 | valid loss (relative): 3.534025e-02 
Epoch 427 use: 363.48 second.

epoch 428 starting......
Epoch:  428 | train loss: 1.765102e-03 | valid loss: 1.803990e-03 
      	| train loss (relative): 3.480446e-02 | valid loss (relative): 3.534585e-02 
Epoch 428 use: 360.81 second.

epoch 429 starting......
Epoch:  429 | train loss: 1.763277e-03 | valid loss: 1.806493e-03 
      	| train loss (relative): 3.477186e-02 | valid loss (relative): 3.539515e-02 
Epoch 429 use: 374.36 second.

epoch 430 starting......
Epoch:  430 | train loss: 1.763982e-03 | valid loss: 1.807878e-03 
      	| train loss (relative): 3.478116e-02 | valid loss (relative): 3.538201e-02 
Epoch 430 use: 358.76 second.

epoch 431 starting......
Epoch:  431 | train loss: 1.765123e-03 | valid loss: 1.802102e-03 
      	| train loss (relative): 3.480438e-02 | valid loss (relative): 3.524696e-02 
Epoch 431 use: 358.64 second.

epoch 432 starting......
Epoch:  432 | train loss: 1.760047e-03 | valid loss: 1.797703e-03 
      	| train loss (relative): 3.469858e-02 | valid loss (relative): 3.548153e-02 
Epoch 432 use: 356.01 second.

epoch 433 starting......
Epoch:  433 | train loss: 1.761757e-03 | valid loss: 1.805305e-03 
      	| train loss (relative): 3.473469e-02 | valid loss (relative): 3.552675e-02 
Epoch 433 use: 352.07 second.

epoch 434 starting......
Epoch:  434 | train loss: 1.762415e-03 | valid loss: 1.797995e-03 
      	| train loss (relative): 3.474972e-02 | valid loss (relative): 3.514007e-02 
Epoch 434 use: 357.48 second.

epoch 435 starting......
Epoch:  435 | train loss: 1.764280e-03 | valid loss: 1.809299e-03 
      	| train loss (relative): 3.478397e-02 | valid loss (relative): 3.561246e-02 
Epoch 435 use: 357.27 second.

epoch 436 starting......
Epoch:  436 | train loss: 1.764899e-03 | valid loss: 1.798311e-03 
      	| train loss (relative): 3.479720e-02 | valid loss (relative): 3.542399e-02 
Epoch 436 use: 364.96 second.

epoch 437 starting......
Epoch:  437 | train loss: 1.764050e-03 | valid loss: 1.786971e-03 
      	| train loss (relative): 3.478287e-02 | valid loss (relative): 3.503611e-02 
Epoch 437 use: 356.67 second.

epoch 438 starting......
Epoch:  438 | train loss: 1.748399e-03 | valid loss: 1.780284e-03 
      	| train loss (relative): 3.446497e-02 | valid loss (relative): 3.487083e-02 
Epoch 438 use: 349.90 second.

epoch 439 starting......
Epoch:  439 | train loss: 1.745449e-03 | valid loss: 1.781228e-03 
      	| train loss (relative): 3.440972e-02 | valid loss (relative): 3.496349e-02 
Epoch 439 use: 352.64 second.

epoch 440 starting......
Epoch:  440 | train loss: 1.748941e-03 | valid loss: 1.799653e-03 
      	| train loss (relative): 3.447039e-02 | valid loss (relative): 3.527868e-02 
Epoch 440 use: 350.53 second.

epoch 441 starting......
Epoch:  441 | train loss: 1.750452e-03 | valid loss: 1.785952e-03 
      	| train loss (relative): 3.450442e-02 | valid loss (relative): 3.481597e-02 
Epoch 441 use: 369.68 second.

epoch 442 starting......
Epoch:  442 | train loss: 1.748662e-03 | valid loss: 1.782077e-03 
      	| train loss (relative): 3.446549e-02 | valid loss (relative): 3.510116e-02 
Epoch 442 use: 343.91 second.

epoch 443 starting......
Epoch:  443 | train loss: 1.745389e-03 | valid loss: 1.789782e-03 
      	| train loss (relative): 3.440053e-02 | valid loss (relative): 3.523763e-02 
Epoch 443 use: 348.53 second.

epoch 444 starting......
Epoch:  444 | train loss: 1.749185e-03 | valid loss: 1.784482e-03 
      	| train loss (relative): 3.447984e-02 | valid loss (relative): 3.504051e-02 
Epoch 444 use: 364.25 second.

epoch 445 starting......
Epoch:  445 | train loss: 1.746904e-03 | valid loss: 1.786874e-03 
      	| train loss (relative): 3.443541e-02 | valid loss (relative): 3.499692e-02 
Epoch 445 use: 335.38 second.

epoch 446 starting......
Epoch:  446 | train loss: 1.748609e-03 | valid loss: 1.802065e-03 
      	| train loss (relative): 3.446379e-02 | valid loss (relative): 3.568526e-02 
Epoch 446 use: 360.25 second.

epoch 447 starting......
Epoch:  447 | train loss: 1.750446e-03 | valid loss: 1.779374e-03 
      	| train loss (relative): 3.449813e-02 | valid loss (relative): 3.467184e-02 
Epoch 447 use: 360.84 second.

epoch 448 starting......
Epoch:  448 | train loss: 1.742626e-03 | valid loss: 1.781968e-03 
      	| train loss (relative): 3.435362e-02 | valid loss (relative): 3.494671e-02 
Epoch 448 use: 364.92 second.

epoch 449 starting......
Epoch:  449 | train loss: 1.743793e-03 | valid loss: 1.776701e-03 
      	| train loss (relative): 3.436687e-02 | valid loss (relative): 3.494832e-02 
Epoch 449 use: 367.35 second.

test MSE Error: 1.757111e-03 | relative MSE Error: 3.459682e-02 
 Total time used for training: 15.49 hour.
MESLoss saved to  /rds/general/user/jy220/home/new_results/Variational_False_Changelr_False_MSELoss_Latent_256_nearest_neighbouring_True_SFC_nums_3_startlr_0.001_n_epoches_450.txt
relative MSELoss saved to  /rds/general/user/jy220/home/new_results/Variational_False_Changelr_False_reMSELoss_Latent_256_nearest_neighbouring_True_SFC_nums_3_startlr_0.001_n_epoches_450.txt
model saved to /rds/general/user/jy220/home/new_results/Variational_False_Changelr_False_Latent_256_Nearest_neighbouring_True_SFC_nums_3_startlr_0.001_n_epoches_450.pth
model_dict saved to /rds/general/user/jy220/home/new_results/Variational_False_Changelr_False_Latent_256_Nearest_neighbouring_True_SFC_nums_3_startlr_0.001_n_epoches_450_dict.pth
... Training slugflow data completed, Run finished Sat 14 Aug 04:52:20 BST 2021 ...
{'data_dir': '/rds/general/user/jy220/home/tensors/', 'data_type': 'tensors', 'mode': 'train', 'vtu_fields': 'Component1::ComponentMassFractionPhase1, phase1::Velocity', 'variational': 'False', 'optimizer': 'Adamax', 'structured': 'False', 'changing_lr': 'False', 'self_concat': '2', 'dimension': '3', 'sfc_nums': '3', 'components': '4', 'nearest_neighbouring': 'True', 'dims_latent': '256', 'activation': 'Tanh', 'tk_file': '/rds/general/user/jy220/home/slugflow_tk.pt', 'tb_file': '/rds/general/user/jy220/home/slugflow_tb.pt', 'sfc_file': '/rds/general/user/jy220/home/SFC-CAE-Ready-to-use/sfcs.pt', 'inv_sfc_file': '/rds/general/user/jy220/home/SFC-CAE-Ready-to-use/inv_sfcs.pt', 'coords_file': '/rds/general/user/jy220/home/SFC-CAE-Ready-to-use/coords.pt', 'cells_file': '/rds/general/user/jy220/home/SFC-CAE-Ready-to-use/cells.npy', 'state_load': '/rds/general/user/jy220/home/new_results/Variational_False_Changelr_False_Latent_256_Nearest_neighbouring_True_SFC_nums_3_startlr_0.001_n_epoches_450_dict.pth', 'batch_size': '16', 'lr': '0.001', 'n_epoches': '150', 'seed': '17', 'visualize': 'False', 'reconstructed_path': 'None', 'reconstruct_start_index': '0', 'reconstruct_end_index': '50', 'save_path': '/rds/general/user/jy220/home/new_results/'}
[[ 2.50825269e-01 -1.67256990e-02 -1.22268730e-03]
 [ 2.38611959e-01 -5.50627777e-03 -5.06451913e-03]
 [ 2.39454874e-01 -1.59563257e-02  3.96778323e-03]
 ...
 [ 9.11361096e+00 -2.21908381e-02  2.22384902e-03]
 [ 9.11847310e+00 -2.84346931e-02 -2.34839590e-04]
 [ 9.11039661e+00 -2.51498573e-02 -8.70661044e-03]]
{'tetra': array([[      0,       1,       2,       3],
       [      4,       5,       6,       7],
       [      8,       9,      10,      11],
       ...,
       [1342744, 1342745, 1342746, 1342747],
       [1342748, 1342749, 1342750, 1342751],
       [1342752, 1342753, 1342754, 1342755]])}
vtu fields:  ['Component1::ComponentMassFractionPhase1', 'phase1::Velocity'] 
 structured  False 
 activation  Tanh() 
 self concat  2 
 sfc_nums  3 

dims_latent  256 
 components  4 
 nearest_neighbouring  True 

visualize  False 
 sample number  1706 

reading sfc nums......
[array([  41684,   41685,   41674, ..., 1235560, 1235564, 1235558]), array([954289, 954290, 954291, ..., 420685, 420687, 420688]), array([  40156,   40155,   40158, ..., 1123478, 1123475, 1123467])]
reading inverse sfc nums......
[array([   8146,    8145,    8144, ..., 1274444, 1274445, 1273166]), array([547280, 547283, 593037, ..., 933933, 933932, 864488]), array([ 66437,  66439, 122512, ..., 459416, 415130, 459418])]
tk:  tensor([0.7581, 0.0418, 0.1840, 0.1464], dtype=torch.float64) 

tb:  tensor([-0.3816, -0.3618, -0.0308,  0.1446], dtype=torch.float64) 

length of train set: 1505 

length of valid set: 100 

length of test set: 101 

torch device num: 4 

Let's use 4 GPUs!
epoch 450 starting......
Epoch:  450 | train loss: 2.092305e-03 | valid loss: 1.814088e-03 
      	| train loss (relative): 4.080021e-02 | valid loss (relative): 3.590390e-02 
Epoch 450 use: 420.82 second.

epoch 451 starting......
Epoch:  451 | train loss: 1.769445e-03 | valid loss: 1.780284e-03 
      	| train loss (relative): 3.488076e-02 | valid loss (relative): 3.516435e-02 
Epoch 451 use: 398.18 second.

epoch 452 starting......
Epoch:  452 | train loss: 1.745657e-03 | valid loss: 1.765588e-03 
      	| train loss (relative): 3.439261e-02 | valid loss (relative): 3.489178e-02 
Epoch 452 use: 392.71 second.

epoch 453 starting......
Epoch:  453 | train loss: 1.735504e-03 | valid loss: 1.760308e-03 
      	| train loss (relative): 3.418456e-02 | valid loss (relative): 3.475726e-02 
Epoch 453 use: 385.72 second.

epoch 454 starting......
Epoch:  454 | train loss: 1.730800e-03 | valid loss: 1.758746e-03 
      	| train loss (relative): 3.409144e-02 | valid loss (relative): 3.481125e-02 
Epoch 454 use: 378.67 second.

epoch 455 starting......
Epoch:  455 | train loss: 1.728099e-03 | valid loss: 1.758690e-03 
      	| train loss (relative): 3.403207e-02 | valid loss (relative): 3.476870e-02 
Epoch 455 use: 374.50 second.

epoch 456 starting......
Epoch:  456 | train loss: 1.727036e-03 | valid loss: 1.758950e-03 
      	| train loss (relative): 3.401445e-02 | valid loss (relative): 3.473799e-02 
Epoch 456 use: 389.34 second.

epoch 457 starting......
Epoch:  457 | train loss: 1.725929e-03 | valid loss: 1.760161e-03 
      	| train loss (relative): 3.398326e-02 | valid loss (relative): 3.471972e-02 
Epoch 457 use: 571.33 second.

epoch 458 starting......
Epoch:  458 | train loss: 1.726320e-03 | valid loss: 1.758454e-03 
      	| train loss (relative): 3.399728e-02 | valid loss (relative): 3.477382e-02 
Epoch 458 use: 403.64 second.

epoch 459 starting......
Epoch:  459 | train loss: 1.726962e-03 | valid loss: 1.766372e-03 
      	| train loss (relative): 3.401135e-02 | valid loss (relative): 3.493259e-02 
Epoch 459 use: 381.47 second.

epoch 460 starting......
Epoch:  460 | train loss: 1.729824e-03 | valid loss: 1.766365e-03 
      	| train loss (relative): 3.406351e-02 | valid loss (relative): 3.486934e-02 
Epoch 460 use: 391.28 second.

epoch 461 starting......
Epoch:  461 | train loss: 1.728296e-03 | valid loss: 1.769692e-03 
      	| train loss (relative): 3.403663e-02 | valid loss (relative): 3.498390e-02 
Epoch 461 use: 394.10 second.

epoch 462 starting......
Epoch:  462 | train loss: 1.727730e-03 | valid loss: 1.766899e-03 
      	| train loss (relative): 3.402467e-02 | valid loss (relative): 3.481969e-02 
Epoch 462 use: 387.94 second.

epoch 463 starting......
Epoch:  463 | train loss: 1.727355e-03 | valid loss: 1.772351e-03 
      	| train loss (relative): 3.401287e-02 | valid loss (relative): 3.521769e-02 
Epoch 463 use: 384.63 second.

epoch 464 starting......
Epoch:  464 | train loss: 1.727957e-03 | valid loss: 1.767629e-03 
      	| train loss (relative): 3.402760e-02 | valid loss (relative): 3.496752e-02 
Epoch 464 use: 400.17 second.

epoch 465 starting......
Epoch:  465 | train loss: 1.727099e-03 | valid loss: 1.772065e-03 
      	| train loss (relative): 3.401165e-02 | valid loss (relative): 3.503982e-02 
Epoch 465 use: 413.05 second.

epoch 466 starting......
Epoch:  466 | train loss: 1.732690e-03 | valid loss: 1.775346e-03 
      	| train loss (relative): 3.411592e-02 | valid loss (relative): 3.518495e-02 
Epoch 466 use: 400.23 second.

epoch 467 starting......
Epoch:  467 | train loss: 1.729845e-03 | valid loss: 1.770637e-03 
      	| train loss (relative): 3.406198e-02 | valid loss (relative): 3.496629e-02 
Epoch 467 use: 434.92 second.

epoch 468 starting......
Epoch:  468 | train loss: 1.726645e-03 | valid loss: 1.769273e-03 
      	| train loss (relative): 3.399644e-02 | valid loss (relative): 3.508586e-02 
Epoch 468 use: 404.60 second.

epoch 469 starting......
Epoch:  469 | train loss: 1.724304e-03 | valid loss: 1.767825e-03 
      	| train loss (relative): 3.395117e-02 | valid loss (relative): 3.488308e-02 
Epoch 469 use: 422.17 second.

epoch 470 starting......
Epoch:  470 | train loss: 1.723439e-03 | valid loss: 1.769000e-03 
      	| train loss (relative): 3.392767e-02 | valid loss (relative): 3.503592e-02 
Epoch 470 use: 418.74 second.

epoch 471 starting......
Epoch:  471 | train loss: 1.724097e-03 | valid loss: 1.765847e-03 
      	| train loss (relative): 3.394059e-02 | valid loss (relative): 3.487496e-02 
Epoch 471 use: 394.30 second.

epoch 472 starting......
Epoch:  472 | train loss: 1.721622e-03 | valid loss: 1.766488e-03 
      	| train loss (relative): 3.389392e-02 | valid loss (relative): 3.488623e-02 
Epoch 472 use: 418.62 second.

epoch 473 starting......
Epoch:  473 | train loss: 1.723813e-03 | valid loss: 1.774975e-03 
      	| train loss (relative): 3.393426e-02 | valid loss (relative): 3.503633e-02 
Epoch 473 use: 379.11 second.

epoch 474 starting......
Epoch:  474 | train loss: 1.725696e-03 | valid loss: 1.765406e-03 
      	| train loss (relative): 3.397913e-02 | valid loss (relative): 3.494240e-02 
Epoch 474 use: 409.68 second.

epoch 475 starting......
Epoch:  475 | train loss: 1.721780e-03 | valid loss: 1.772156e-03 
      	| train loss (relative): 3.389598e-02 | valid loss (relative): 3.475928e-02 
Epoch 475 use: 388.90 second.

epoch 476 starting......
Epoch:  476 | train loss: 1.724133e-03 | valid loss: 1.771313e-03 
      	| train loss (relative): 3.393441e-02 | valid loss (relative): 3.508857e-02 
Epoch 476 use: 371.60 second.

epoch 477 starting......
Epoch:  477 | train loss: 1.722261e-03 | valid loss: 1.767641e-03 
      	| train loss (relative): 3.390489e-02 | valid loss (relative): 3.480335e-02 
Epoch 477 use: 373.92 second.

epoch 478 starting......
Epoch:  478 | train loss: 1.720164e-03 | valid loss: 1.769150e-03 
      	| train loss (relative): 3.386271e-02 | valid loss (relative): 3.489503e-02 
Epoch 478 use: 357.21 second.

epoch 479 starting......
Epoch:  479 | train loss: 1.721077e-03 | valid loss: 1.766845e-03 
      	| train loss (relative): 3.387730e-02 | valid loss (relative): 3.511260e-02 
Epoch 479 use: 372.03 second.

epoch 480 starting......
Epoch:  480 | train loss: 1.715598e-03 | valid loss: 1.761217e-03 
      	| train loss (relative): 3.377330e-02 | valid loss (relative): 3.484216e-02 
Epoch 480 use: 375.56 second.

epoch 481 starting......
Epoch:  481 | train loss: 1.712297e-03 | valid loss: 1.761792e-03 
      	| train loss (relative): 3.370361e-02 | valid loss (relative): 3.472730e-02 
Epoch 481 use: 362.88 second.

epoch 482 starting......
Epoch:  482 | train loss: 1.714127e-03 | valid loss: 1.777984e-03 
      	| train loss (relative): 3.374071e-02 | valid loss (relative): 3.505461e-02 
Epoch 482 use: 516.09 second.

epoch 483 starting......
Epoch:  483 | train loss: 1.720962e-03 | valid loss: 1.768718e-03 
      	| train loss (relative): 3.387222e-02 | valid loss (relative): 3.467416e-02 
Epoch 483 use: 414.93 second.

epoch 484 starting......
Epoch:  484 | train loss: 1.711956e-03 | valid loss: 1.766286e-03 
      	| train loss (relative): 3.369555e-02 | valid loss (relative): 3.503667e-02 
Epoch 484 use: 394.32 second.

epoch 485 starting......
Epoch:  485 | train loss: 1.712354e-03 | valid loss: 1.767552e-03 
      	| train loss (relative): 3.369949e-02 | valid loss (relative): 3.479659e-02 
Epoch 485 use: 382.31 second.

epoch 486 starting......
Epoch:  486 | train loss: 1.714788e-03 | valid loss: 1.765450e-03 
      	| train loss (relative): 3.374892e-02 | valid loss (relative): 3.482506e-02 
Epoch 486 use: 398.97 second.

epoch 487 starting......
Epoch:  487 | train loss: 1.715251e-03 | valid loss: 1.761795e-03 
      	| train loss (relative): 3.375392e-02 | valid loss (relative): 3.476470e-02 
Epoch 487 use: 399.61 second.

epoch 488 starting......
Epoch:  488 | train loss: 1.712710e-03 | valid loss: 1.771885e-03 
      	| train loss (relative): 3.370394e-02 | valid loss (relative): 3.496421e-02 
Epoch 488 use: 386.82 second.

epoch 489 starting......
Epoch:  489 | train loss: 1.713513e-03 | valid loss: 1.764839e-03 
      	| train loss (relative): 3.372244e-02 | valid loss (relative): 3.465280e-02 
Epoch 489 use: 367.19 second.

epoch 490 starting......
Epoch:  490 | train loss: 1.714252e-03 | valid loss: 1.774555e-03 
      	| train loss (relative): 3.373857e-02 | valid loss (relative): 3.520892e-02 
Epoch 490 use: 386.12 second.

epoch 491 starting......
Epoch:  491 | train loss: 1.717056e-03 | valid loss: 1.765124e-03 
      	| train loss (relative): 3.379110e-02 | valid loss (relative): 3.479465e-02 
Epoch 491 use: 388.57 second.

epoch 492 starting......
Epoch:  492 | train loss: 1.710181e-03 | valid loss: 1.756389e-03 
      	| train loss (relative): 3.365124e-02 | valid loss (relative): 3.485642e-02 
Epoch 492 use: 397.25 second.

epoch 493 starting......
Epoch:  493 | train loss: 1.708700e-03 | valid loss: 1.785246e-03 
      	| train loss (relative): 3.362990e-02 | valid loss (relative): 3.500140e-02 
Epoch 493 use: 397.60 second.

epoch 494 starting......
Epoch:  494 | train loss: 1.714244e-03 | valid loss: 1.765267e-03 
      	| train loss (relative): 3.373505e-02 | valid loss (relative): 3.484475e-02 
Epoch 494 use: 382.09 second.

epoch 495 starting......
Epoch:  495 | train loss: 1.711823e-03 | valid loss: 1.768077e-03 
      	| train loss (relative): 3.369205e-02 | valid loss (relative): 3.464743e-02 
Epoch 495 use: 387.65 second.

epoch 496 starting......
Epoch:  496 | train loss: 1.708692e-03 | valid loss: 1.751796e-03 
      	| train loss (relative): 3.362414e-02 | valid loss (relative): 3.452054e-02 
Epoch 496 use: 383.84 second.

epoch 497 starting......
Epoch:  497 | train loss: 1.702411e-03 | valid loss: 1.751218e-03 
      	| train loss (relative): 3.349523e-02 | valid loss (relative): 3.458363e-02 
Epoch 497 use: 378.23 second.

epoch 498 starting......
Epoch:  498 | train loss: 1.698658e-03 | valid loss: 1.762250e-03 
      	| train loss (relative): 3.342581e-02 | valid loss (relative): 3.453749e-02 
Epoch 498 use: 378.62 second.

epoch 499 starting......
Epoch:  499 | train loss: 1.705355e-03 | valid loss: 1.757584e-03 
      	| train loss (relative): 3.355425e-02 | valid loss (relative): 3.489698e-02 
Epoch 499 use: 388.19 second.

epoch 500 starting......
Epoch:  500 | train loss: 1.702840e-03 | valid loss: 1.755976e-03 
      	| train loss (relative): 3.350946e-02 | valid loss (relative): 3.469781e-02 
Epoch 500 use: 364.75 second.

epoch 501 starting......
Epoch:  501 | train loss: 1.701582e-03 | valid loss: 1.751487e-03 
      	| train loss (relative): 3.347841e-02 | valid loss (relative): 3.445100e-02 
Epoch 501 use: 385.96 second.

epoch 502 starting......
Epoch:  502 | train loss: 1.701534e-03 | valid loss: 1.759781e-03 
      	| train loss (relative): 3.348120e-02 | valid loss (relative): 3.460648e-02 
Epoch 502 use: 376.78 second.

epoch 503 starting......
Epoch:  503 | train loss: 1.706069e-03 | valid loss: 1.766512e-03 
      	| train loss (relative): 3.356382e-02 | valid loss (relative): 3.477765e-02 
Epoch 503 use: 364.34 second.

epoch 504 starting......
Epoch:  504 | train loss: 1.707038e-03 | valid loss: 1.759471e-03 
      	| train loss (relative): 3.359282e-02 | valid loss (relative): 3.456008e-02 
Epoch 504 use: 396.93 second.

epoch 505 starting......
Epoch:  505 | train loss: 1.701794e-03 | valid loss: 1.755248e-03 
      	| train loss (relative): 3.348310e-02 | valid loss (relative): 3.475997e-02 
Epoch 505 use: 388.03 second.

epoch 506 starting......
Epoch:  506 | train loss: 1.698415e-03 | valid loss: 1.757197e-03 
      	| train loss (relative): 3.341862e-02 | valid loss (relative): 3.486937e-02 
Epoch 506 use: 371.34 second.

epoch 507 starting......
Epoch:  507 | train loss: 1.700021e-03 | valid loss: 1.757395e-03 
      	| train loss (relative): 3.345447e-02 | valid loss (relative): 3.474430e-02 
Epoch 507 use: 382.11 second.

epoch 508 starting......
Epoch:  508 | train loss: 1.699090e-03 | valid loss: 1.767493e-03 
      	| train loss (relative): 3.342832e-02 | valid loss (relative): 3.521266e-02 
Epoch 508 use: 362.24 second.

epoch 509 starting......
Epoch:  509 | train loss: 1.698493e-03 | valid loss: 1.747877e-03 
      	| train loss (relative): 3.341813e-02 | valid loss (relative): 3.463485e-02 
Epoch 509 use: 386.10 second.

epoch 510 starting......
Epoch:  510 | train loss: 1.691028e-03 | valid loss: 1.753315e-03 
      	| train loss (relative): 3.326492e-02 | valid loss (relative): 3.448224e-02 
Epoch 510 use: 386.23 second.

epoch 511 starting......
Epoch:  511 | train loss: 1.693806e-03 | valid loss: 1.745616e-03 
      	| train loss (relative): 3.332103e-02 | valid loss (relative): 3.457085e-02 
Epoch 511 use: 384.35 second.

epoch 512 starting......
Epoch:  512 | train loss: 1.692300e-03 | valid loss: 1.747758e-03 
      	| train loss (relative): 3.328880e-02 | valid loss (relative): 3.431195e-02 
Epoch 512 use: 375.94 second.

epoch 513 starting......
Epoch:  513 | train loss: 1.689804e-03 | valid loss: 1.748716e-03 
      	| train loss (relative): 3.324151e-02 | valid loss (relative): 3.433422e-02 
Epoch 513 use: 387.65 second.

epoch 514 starting......
Epoch:  514 | train loss: 1.692530e-03 | valid loss: 1.746146e-03 
      	| train loss (relative): 3.329229e-02 | valid loss (relative): 3.442980e-02 
Epoch 514 use: 366.26 second.

epoch 515 starting......
Epoch:  515 | train loss: 1.690941e-03 | valid loss: 1.753394e-03 
      	| train loss (relative): 3.326231e-02 | valid loss (relative): 3.453272e-02 
Epoch 515 use: 383.35 second.

epoch 516 starting......
Epoch:  516 | train loss: 1.691992e-03 | valid loss: 1.747761e-03 
      	| train loss (relative): 3.328558e-02 | valid loss (relative): 3.467887e-02 
Epoch 516 use: 383.43 second.

epoch 517 starting......
Epoch:  517 | train loss: 1.687326e-03 | valid loss: 1.749205e-03 
      	| train loss (relative): 3.319156e-02 | valid loss (relative): 3.456706e-02 
Epoch 517 use: 387.44 second.

epoch 518 starting......
Epoch:  518 | train loss: 1.694080e-03 | valid loss: 1.746255e-03 
      	| train loss (relative): 3.332409e-02 | valid loss (relative): 3.442900e-02 
Epoch 518 use: 383.90 second.

epoch 519 starting......
Epoch:  519 | train loss: 1.687185e-03 | valid loss: 1.742175e-03 
      	| train loss (relative): 3.319161e-02 | valid loss (relative): 3.448370e-02 
Epoch 519 use: 366.84 second.

epoch 520 starting......
Epoch:  520 | train loss: 1.684714e-03 | valid loss: 1.760801e-03 
      	| train loss (relative): 3.313890e-02 | valid loss (relative): 3.480241e-02 
Epoch 520 use: 367.08 second.

epoch 521 starting......
Epoch:  521 | train loss: 1.691471e-03 | valid loss: 1.743692e-03 
      	| train loss (relative): 3.327170e-02 | valid loss (relative): 3.461711e-02 
Epoch 521 use: 390.86 second.

epoch 522 starting......
Epoch:  522 | train loss: 1.687387e-03 | valid loss: 1.741099e-03 
      	| train loss (relative): 3.319289e-02 | valid loss (relative): 3.423313e-02 
Epoch 522 use: 387.29 second.

epoch 523 starting......
Epoch:  523 | train loss: 1.685576e-03 | valid loss: 1.746280e-03 
      	| train loss (relative): 3.315244e-02 | valid loss (relative): 3.437455e-02 
Epoch 523 use: 378.49 second.

epoch 524 starting......
Epoch:  524 | train loss: 1.685695e-03 | valid loss: 1.745122e-03 
      	| train loss (relative): 3.316224e-02 | valid loss (relative): 3.448221e-02 
Epoch 524 use: 390.42 second.

epoch 525 starting......
Epoch:  525 | train loss: 1.686019e-03 | valid loss: 1.734138e-03 
      	| train loss (relative): 3.316336e-02 | valid loss (relative): 3.405230e-02 
Epoch 525 use: 371.25 second.

epoch 526 starting......
Epoch:  526 | train loss: 1.675328e-03 | valid loss: 1.726945e-03 
      	| train loss (relative): 3.294522e-02 | valid loss (relative): 3.399511e-02 
Epoch 526 use: 384.59 second.

epoch 527 starting......
Epoch:  527 | train loss: 1.673047e-03 | valid loss: 1.741096e-03 
      	| train loss (relative): 3.290360e-02 | valid loss (relative): 3.419891e-02 
Epoch 527 use: 405.48 second.

epoch 528 starting......
Epoch:  528 | train loss: 1.674863e-03 | valid loss: 1.730658e-03 
      	| train loss (relative): 3.294105e-02 | valid loss (relative): 3.417183e-02 
Epoch 528 use: 418.03 second.

epoch 529 starting......
Epoch:  529 | train loss: 1.678071e-03 | valid loss: 1.750774e-03 
      	| train loss (relative): 3.299635e-02 | valid loss (relative): 3.474805e-02 
Epoch 529 use: 368.61 second.

epoch 530 starting......
Epoch:  530 | train loss: 1.682510e-03 | valid loss: 1.735024e-03 
      	| train loss (relative): 3.309068e-02 | valid loss (relative): 3.408264e-02 
Epoch 530 use: 377.19 second.

epoch 531 starting......
Epoch:  531 | train loss: 1.674148e-03 | valid loss: 1.728877e-03 
      	| train loss (relative): 3.292410e-02 | valid loss (relative): 3.422130e-02 
Epoch 531 use: 377.55 second.

epoch 532 starting......
Epoch:  532 | train loss: 1.673601e-03 | valid loss: 1.732919e-03 
      	| train loss (relative): 3.291160e-02 | valid loss (relative): 3.428046e-02 
Epoch 532 use: 404.10 second.

epoch 533 starting......
Epoch:  533 | train loss: 1.672703e-03 | valid loss: 1.732006e-03 
      	| train loss (relative): 3.289390e-02 | valid loss (relative): 3.426225e-02 
Epoch 533 use: 367.13 second.

epoch 534 starting......
Epoch:  534 | train loss: 1.673648e-03 | valid loss: 1.735892e-03 
      	| train loss (relative): 3.291045e-02 | valid loss (relative): 3.419519e-02 
Epoch 534 use: 367.59 second.

epoch 535 starting......
Epoch:  535 | train loss: 1.674287e-03 | valid loss: 1.742137e-03 
      	| train loss (relative): 3.292337e-02 | valid loss (relative): 3.424617e-02 
Epoch 535 use: 382.98 second.

epoch 536 starting......
Epoch:  536 | train loss: 1.676978e-03 | valid loss: 1.731222e-03 
      	| train loss (relative): 3.298067e-02 | valid loss (relative): 3.413937e-02 
Epoch 536 use: 370.95 second.

epoch 537 starting......
Epoch:  537 | train loss: 1.670966e-03 | valid loss: 1.734766e-03 
      	| train loss (relative): 3.285807e-02 | valid loss (relative): 3.384140e-02 
Epoch 537 use: 362.07 second.

epoch 538 starting......
Epoch:  538 | train loss: 1.674506e-03 | valid loss: 1.746743e-03 
      	| train loss (relative): 3.292627e-02 | valid loss (relative): 3.419471e-02 
Epoch 538 use: 375.62 second.

epoch 539 starting......
Epoch:  539 | train loss: 1.677271e-03 | valid loss: 1.733619e-03 
      	| train loss (relative): 3.298530e-02 | valid loss (relative): 3.401774e-02 
Epoch 539 use: 376.14 second.

epoch 540 starting......
Epoch:  540 | train loss: 1.670301e-03 | valid loss: 1.734728e-03 
      	| train loss (relative): 3.284535e-02 | valid loss (relative): 3.422307e-02 
Epoch 540 use: 364.07 second.

epoch 541 starting......
Epoch:  541 | train loss: 1.673154e-03 | valid loss: 1.723822e-03 
      	| train loss (relative): 3.290668e-02 | valid loss (relative): 3.407930e-02 
Epoch 541 use: 373.18 second.

epoch 542 starting......
Epoch:  542 | train loss: 1.665616e-03 | valid loss: 1.730741e-03 
      	| train loss (relative): 3.275045e-02 | valid loss (relative): 3.429377e-02 
Epoch 542 use: 387.94 second.

epoch 543 starting......
Epoch:  543 | train loss: 1.665553e-03 | valid loss: 1.726334e-03 
      	| train loss (relative): 3.275109e-02 | valid loss (relative): 3.425011e-02 
Epoch 543 use: 400.68 second.

epoch 544 starting......
Epoch:  544 | train loss: 1.663556e-03 | valid loss: 1.720487e-03 
      	| train loss (relative): 3.270796e-02 | valid loss (relative): 3.397284e-02 
Epoch 544 use: 389.60 second.

epoch 545 starting......
Epoch:  545 | train loss: 1.665170e-03 | valid loss: 1.724071e-03 
      	| train loss (relative): 3.274034e-02 | valid loss (relative): 3.403354e-02 
Epoch 545 use: 395.39 second.

epoch 546 starting......
Epoch:  546 | train loss: 1.669232e-03 | valid loss: 1.725835e-03 
      	| train loss (relative): 3.282231e-02 | valid loss (relative): 3.396145e-02 
Epoch 546 use: 375.02 second.

epoch 547 starting......
Epoch:  547 | train loss: 1.666305e-03 | valid loss: 1.732595e-03 
      	| train loss (relative): 3.276284e-02 | valid loss (relative): 3.444206e-02 
Epoch 547 use: 400.16 second.

epoch 548 starting......
Epoch:  548 | train loss: 1.665775e-03 | valid loss: 1.726325e-03 
      	| train loss (relative): 3.275315e-02 | valid loss (relative): 3.371595e-02 
Epoch 548 use: 407.94 second.

epoch 549 starting......
Epoch:  549 | train loss: 1.663021e-03 | valid loss: 1.734277e-03 
      	| train loss (relative): 3.269108e-02 | valid loss (relative): 3.407045e-02 
Epoch 549 use: 417.01 second.

epoch 550 starting......
Epoch:  550 | train loss: 1.662349e-03 | valid loss: 1.720624e-03 
      	| train loss (relative): 3.267935e-02 | valid loss (relative): 3.388439e-02 
Epoch 550 use: 408.73 second.

epoch 551 starting......
Epoch:  551 | train loss: 1.665723e-03 | valid loss: 1.722759e-03 
      	| train loss (relative): 3.275036e-02 | valid loss (relative): 3.399119e-02 
Epoch 551 use: 399.02 second.

epoch 552 starting......
Epoch:  552 | train loss: 1.662921e-03 | valid loss: 1.731371e-03 
      	| train loss (relative): 3.269219e-02 | valid loss (relative): 3.429143e-02 
Epoch 552 use: 440.30 second.

epoch 553 starting......
Epoch:  553 | train loss: 1.662147e-03 | valid loss: 1.721635e-03 
      	| train loss (relative): 3.267737e-02 | valid loss (relative): 3.404053e-02 
Epoch 553 use: 409.17 second.

epoch 554 starting......
Epoch:  554 | train loss: 1.660639e-03 | valid loss: 1.726668e-03 
      	| train loss (relative): 3.264632e-02 | valid loss (relative): 3.405571e-02 
Epoch 554 use: 450.44 second.

epoch 555 starting......
Epoch:  555 | train loss: 1.657924e-03 | valid loss: 1.714160e-03 
      	| train loss (relative): 3.259553e-02 | valid loss (relative): 3.387556e-02 
Epoch 555 use: 441.52 second.

epoch 556 starting......
Epoch:  556 | train loss: 1.656336e-03 | valid loss: 1.722122e-03 
      	| train loss (relative): 3.255795e-02 | valid loss (relative): 3.420788e-02 
Epoch 556 use: 431.38 second.

epoch 557 starting......
Epoch:  557 | train loss: 1.660869e-03 | valid loss: 1.722308e-03 
      	| train loss (relative): 3.265161e-02 | valid loss (relative): 3.411109e-02 
Epoch 557 use: 468.59 second.

epoch 558 starting......
Epoch:  558 | train loss: 1.659848e-03 | valid loss: 1.722663e-03 
      	| train loss (relative): 3.262598e-02 | valid loss (relative): 3.407998e-02 
Epoch 558 use: 395.39 second.

epoch 559 starting......
Epoch:  559 | train loss: 1.659369e-03 | valid loss: 1.721907e-03 
      	| train loss (relative): 3.262150e-02 | valid loss (relative): 3.391623e-02 
Epoch 559 use: 453.49 second.

epoch 560 starting......
Epoch:  560 | train loss: 1.653523e-03 | valid loss: 1.724925e-03 
      	| train loss (relative): 3.250413e-02 | valid loss (relative): 3.358711e-02 
Epoch 560 use: 407.84 second.

epoch 561 starting......
Epoch:  561 | train loss: 1.664714e-03 | valid loss: 1.718204e-03 
      	| train loss (relative): 3.272223e-02 | valid loss (relative): 3.385333e-02 
Epoch 561 use: 442.32 second.

epoch 562 starting......
Epoch:  562 | train loss: 1.654335e-03 | valid loss: 1.714006e-03 
      	| train loss (relative): 3.251969e-02 | valid loss (relative): 3.390732e-02 
Epoch 562 use: 413.57 second.

epoch 563 starting......
Epoch:  563 | train loss: 1.653173e-03 | valid loss: 1.716357e-03 
      	| train loss (relative): 3.249968e-02 | valid loss (relative): 3.383163e-02 
Epoch 563 use: 432.61 second.

epoch 564 starting......
Epoch:  564 | train loss: 1.653343e-03 | valid loss: 1.717705e-03 
      	| train loss (relative): 3.250142e-02 | valid loss (relative): 3.411324e-02 
Epoch 564 use: 456.51 second.

epoch 565 starting......
Epoch:  565 | train loss: 1.650641e-03 | valid loss: 1.716658e-03 
      	| train loss (relative): 3.244532e-02 | valid loss (relative): 3.392002e-02 
Epoch 565 use: 419.27 second.

epoch 566 starting......
Epoch:  566 | train loss: 1.656125e-03 | valid loss: 1.721943e-03 
      	| train loss (relative): 3.255662e-02 | valid loss (relative): 3.408369e-02 
Epoch 566 use: 430.79 second.

epoch 567 starting......
Epoch:  567 | train loss: 1.652625e-03 | valid loss: 1.711351e-03 
      	| train loss (relative): 3.249098e-02 | valid loss (relative): 3.390363e-02 
Epoch 567 use: 435.69 second.

epoch 568 starting......
Epoch:  568 | train loss: 1.645604e-03 | valid loss: 1.705632e-03 
      	| train loss (relative): 3.234578e-02 | valid loss (relative): 3.369934e-02 
Epoch 568 use: 398.37 second.

epoch 569 starting......
Epoch:  569 | train loss: 1.649043e-03 | valid loss: 1.715390e-03 
      	| train loss (relative): 3.241328e-02 | valid loss (relative): 3.369535e-02 
Epoch 569 use: 441.14 second.

epoch 570 starting......
Epoch:  570 | train loss: 1.648388e-03 | valid loss: 1.712732e-03 
      	| train loss (relative): 3.240128e-02 | valid loss (relative): 3.376412e-02 
Epoch 570 use: 406.70 second.

epoch 571 starting......
Epoch:  571 | train loss: 1.645564e-03 | valid loss: 1.709504e-03 
      	| train loss (relative): 3.234201e-02 | valid loss (relative): 3.369555e-02 
Epoch 571 use: 452.19 second.

epoch 572 starting......
Epoch:  572 | train loss: 1.643751e-03 | valid loss: 1.710651e-03 
      	| train loss (relative): 3.230366e-02 | valid loss (relative): 3.376725e-02 
Epoch 572 use: 390.03 second.

epoch 573 starting......
Epoch:  573 | train loss: 1.643121e-03 | valid loss: 1.707280e-03 
      	| train loss (relative): 3.229540e-02 | valid loss (relative): 3.363841e-02 
Epoch 573 use: 463.67 second.

epoch 574 starting......
Epoch:  574 | train loss: 1.644447e-03 | valid loss: 1.711685e-03 
      	| train loss (relative): 3.231783e-02 | valid loss (relative): 3.351117e-02 
Epoch 574 use: 415.42 second.

epoch 575 starting......
Epoch:  575 | train loss: 1.648151e-03 | valid loss: 1.702725e-03 
      	| train loss (relative): 3.239119e-02 | valid loss (relative): 3.354942e-02 
Epoch 575 use: 453.47 second.

epoch 576 starting......
Epoch:  576 | train loss: 1.643430e-03 | valid loss: 1.704870e-03 
      	| train loss (relative): 3.229616e-02 | valid loss (relative): 3.384384e-02 
Epoch 576 use: 401.27 second.

epoch 577 starting......
Epoch:  577 | train loss: 1.645382e-03 | valid loss: 1.728135e-03 
      	| train loss (relative): 3.234076e-02 | valid loss (relative): 3.400056e-02 
Epoch 577 use: 438.94 second.

epoch 578 starting......
Epoch:  578 | train loss: 1.649030e-03 | valid loss: 1.702789e-03 
      	| train loss (relative): 3.240950e-02 | valid loss (relative): 3.359955e-02 
Epoch 578 use: 427.25 second.

epoch 579 starting......
Epoch:  579 | train loss: 1.642806e-03 | valid loss: 1.709814e-03 
      	| train loss (relative): 3.228792e-02 | valid loss (relative): 3.363741e-02 
Epoch 579 use: 422.76 second.

epoch 580 starting......
Epoch:  580 | train loss: 1.642822e-03 | valid loss: 1.701778e-03 
      	| train loss (relative): 3.228386e-02 | valid loss (relative): 3.361976e-02 
Epoch 580 use: 409.75 second.

epoch 581 starting......
Epoch:  581 | train loss: 1.643023e-03 | valid loss: 1.713746e-03 
      	| train loss (relative): 3.229107e-02 | valid loss (relative): 3.347939e-02 
Epoch 581 use: 407.57 second.

epoch 582 starting......
Epoch:  582 | train loss: 1.647358e-03 | valid loss: 1.711088e-03 
      	| train loss (relative): 3.237224e-02 | valid loss (relative): 3.395667e-02 
Epoch 582 use: 425.31 second.

epoch 583 starting......
Epoch:  583 | train loss: 1.644634e-03 | valid loss: 1.699105e-03 
      	| train loss (relative): 3.232306e-02 | valid loss (relative): 3.358680e-02 
Epoch 583 use: 414.41 second.

epoch 584 starting......
Epoch:  584 | train loss: 1.638859e-03 | valid loss: 1.703131e-03 
      	| train loss (relative): 3.220566e-02 | valid loss (relative): 3.376029e-02 
Epoch 584 use: 444.24 second.

epoch 585 starting......
Epoch:  585 | train loss: 1.638020e-03 | valid loss: 1.704642e-03 
      	| train loss (relative): 3.219028e-02 | valid loss (relative): 3.373598e-02 
Epoch 585 use: 414.61 second.

epoch 586 starting......
Epoch:  586 | train loss: 1.639659e-03 | valid loss: 1.705878e-03 
      	| train loss (relative): 3.221980e-02 | valid loss (relative): 3.363578e-02 
Epoch 586 use: 455.58 second.

epoch 587 starting......
Epoch:  587 | train loss: 1.644093e-03 | valid loss: 1.696646e-03 
      	| train loss (relative): 3.230393e-02 | valid loss (relative): 3.343815e-02 
Epoch 587 use: 402.65 second.

epoch 588 starting......
Epoch:  588 | train loss: 1.633778e-03 | valid loss: 1.699924e-03 
      	| train loss (relative): 3.210621e-02 | valid loss (relative): 3.361483e-02 
Epoch 588 use: 459.65 second.

epoch 589 starting......
Epoch:  589 | train loss: 1.633674e-03 | valid loss: 1.698017e-03 
      	| train loss (relative): 3.209640e-02 | valid loss (relative): 3.337221e-02 
Epoch 589 use: 411.54 second.

epoch 590 starting......
Epoch:  590 | train loss: 1.634232e-03 | valid loss: 1.700302e-03 
      	| train loss (relative): 3.211087e-02 | valid loss (relative): 3.342523e-02 
Epoch 590 use: 460.28 second.

epoch 591 starting......
Epoch:  591 | train loss: 1.633721e-03 | valid loss: 1.694330e-03 
      	| train loss (relative): 3.210600e-02 | valid loss (relative): 3.335393e-02 
Epoch 591 use: 427.75 second.

epoch 592 starting......
Epoch:  592 | train loss: 1.630715e-03 | valid loss: 1.699900e-03 
      	| train loss (relative): 3.204357e-02 | valid loss (relative): 3.359913e-02 
Epoch 592 use: 442.54 second.

epoch 593 starting......
Epoch:  593 | train loss: 1.635780e-03 | valid loss: 1.694384e-03 
      	| train loss (relative): 3.214026e-02 | valid loss (relative): 3.340023e-02 
Epoch 593 use: 450.73 second.

epoch 594 starting......
Epoch:  594 | train loss: 1.629669e-03 | valid loss: 1.690640e-03 
      	| train loss (relative): 3.202054e-02 | valid loss (relative): 3.337046e-02 
Epoch 594 use: 441.05 second.

epoch 595 starting......
Epoch:  595 | train loss: 1.631565e-03 | valid loss: 1.700052e-03 
      	| train loss (relative): 3.205498e-02 | valid loss (relative): 3.368964e-02 
Epoch 595 use: 448.93 second.

epoch 596 starting......
Epoch:  596 | train loss: 1.635408e-03 | valid loss: 1.701096e-03 
      	| train loss (relative): 3.213440e-02 | valid loss (relative): 3.332394e-02 
Epoch 596 use: 426.04 second.

epoch 597 starting......
Epoch:  597 | train loss: 1.631223e-03 | valid loss: 1.697368e-03 
      	| train loss (relative): 3.204710e-02 | valid loss (relative): 3.334440e-02 
Epoch 597 use: 442.43 second.

epoch 598 starting......
Epoch:  598 | train loss: 1.632653e-03 | valid loss: 1.712057e-03 
      	| train loss (relative): 3.207925e-02 | valid loss (relative): 3.412462e-02 
Epoch 598 use: 420.59 second.

epoch 599 starting......
Epoch:  599 | train loss: 1.631231e-03 | valid loss: 1.688687e-03 
      	| train loss (relative): 3.205953e-02 | valid loss (relative): 3.330302e-02 
Epoch 599 use: 440.90 second.

test MSE Error: 1.727035e-03 | relative MSE Error: 3.417970e-02 
 Total time used for training: 16.81 hour.
MESLoss saved to  /rds/general/user/jy220/home/new_results/Variational_False_Changelr_False_MSELoss_Latent_256_nearest_neighbouring_True_SFC_nums_3_startlr_0.001_n_epoches_600.txt
relative MSELoss saved to  /rds/general/user/jy220/home/new_results/Variational_False_Changelr_False_reMSELoss_Latent_256_nearest_neighbouring_True_SFC_nums_3_startlr_0.001_n_epoches_600.txt
model saved to /rds/general/user/jy220/home/new_results/Variational_False_Changelr_False_Latent_256_Nearest_neighbouring_True_SFC_nums_3_startlr_0.001_n_epoches_600.pth
model_dict saved to /rds/general/user/jy220/home/new_results/Variational_False_Changelr_False_Latent_256_Nearest_neighbouring_True_SFC_nums_3_startlr_0.001_n_epoches_600_dict.pth
... Training slugflow data completed, Run finished Sun 15 Aug 05:39:44 BST 2021 ...
{'data_dir': '/rds/general/user/jy220/home/tensors/', 'data_type': 'tensors', 'mode': 'train', 'vtu_fields': 'Component1::ComponentMassFractionPhase1, phase1::Velocity', 'variational': 'False', 'optimizer': 'Adamax', 'structured': 'False', 'changing_lr': 'False', 'self_concat': '2', 'dimension': '3', 'sfc_nums': '3', 'components': '4', 'nearest_neighbouring': 'True', 'dims_latent': '256', 'activation': 'Tanh', 'tk_file': '/rds/general/user/jy220/home/slugflow_tk.pt', 'tb_file': '/rds/general/user/jy220/home/slugflow_tb.pt', 'sfc_file': '/rds/general/user/jy220/home/SFC-CAE-Ready-to-use/sfcs.pt', 'inv_sfc_file': '/rds/general/user/jy220/home/SFC-CAE-Ready-to-use/inv_sfcs.pt', 'coords_file': '/rds/general/user/jy220/home/SFC-CAE-Ready-to-use/coords.pt', 'cells_file': '/rds/general/user/jy220/home/SFC-CAE-Ready-to-use/cells.npy', 'state_load': '/rds/general/user/jy220/home/new_results/Variational_False_Changelr_False_Latent_256_Nearest_neighbouring_True_SFC_nums_3_startlr_0.001_n_epoches_600_dict.pth', 'batch_size': '16', 'lr': '0.001', 'n_epoches': '100', 'seed': '17', 'visualize': 'False', 'reconstructed_path': 'None', 'reconstruct_start_index': '0', 'reconstruct_end_index': '50', 'save_path': '/rds/general/user/jy220/home/new_results/'}
[[ 2.50825269e-01 -1.67256990e-02 -1.22268730e-03]
 [ 2.38611959e-01 -5.50627777e-03 -5.06451913e-03]
 [ 2.39454874e-01 -1.59563257e-02  3.96778323e-03]
 ...
 [ 9.11361096e+00 -2.21908381e-02  2.22384902e-03]
 [ 9.11847310e+00 -2.84346931e-02 -2.34839590e-04]
 [ 9.11039661e+00 -2.51498573e-02 -8.70661044e-03]]
{'tetra': array([[      0,       1,       2,       3],
       [      4,       5,       6,       7],
       [      8,       9,      10,      11],
       ...,
       [1342744, 1342745, 1342746, 1342747],
       [1342748, 1342749, 1342750, 1342751],
       [1342752, 1342753, 1342754, 1342755]])}
vtu fields:  ['Component1::ComponentMassFractionPhase1', 'phase1::Velocity'] 
 structured  False 
 activation  Tanh() 
 self concat  2 
 sfc_nums  3 

dims_latent  256 
 components  4 
 nearest_neighbouring  True 

visualize  False 
 sample number  1706 

reading sfc nums......
[array([  41684,   41685,   41674, ..., 1235560, 1235564, 1235558]), array([954289, 954290, 954291, ..., 420685, 420687, 420688]), array([  40156,   40155,   40158, ..., 1123478, 1123475, 1123467])]
reading inverse sfc nums......
[array([   8146,    8145,    8144, ..., 1274444, 1274445, 1273166]), array([547280, 547283, 593037, ..., 933933, 933932, 864488]), array([ 66437,  66439, 122512, ..., 459416, 415130, 459418])]
tk:  tensor([0.7581, 0.0418, 0.1840, 0.1464], dtype=torch.float64) 

tb:  tensor([-0.3816, -0.3618, -0.0308,  0.1446], dtype=torch.float64) 

length of train set: 1505 

length of valid set: 100 

length of test set: 101 

torch device num: 4 

Let's use 4 GPUs!
epoch 600 starting......
Epoch:  600 | train loss: 1.895486e-03 | valid loss: 1.618867e-03 
      	| train loss (relative): 3.716265e-02 | valid loss (relative): 3.169344e-02 
Epoch 600 use: 524.24 second.

epoch 601 starting......
Epoch:  601 | train loss: 1.649940e-03 | valid loss: 1.594521e-03 
      	| train loss (relative): 3.245963e-02 | valid loss (relative): 3.119951e-02 
Epoch 601 use: 496.44 second.

epoch 602 starting......
Epoch:  602 | train loss: 1.634478e-03 | valid loss: 1.588824e-03 
      	| train loss (relative): 3.214937e-02 | valid loss (relative): 3.108611e-02 
Epoch 602 use: 497.97 second.

epoch 603 starting......
Epoch:  603 | train loss: 1.628814e-03 | valid loss: 1.585784e-03 
      	| train loss (relative): 3.203656e-02 | valid loss (relative): 3.099397e-02 
Epoch 603 use: 492.14 second.

epoch 604 starting......
Epoch:  604 | train loss: 1.626385e-03 | valid loss: 1.586111e-03 
      	| train loss (relative): 3.198193e-02 | valid loss (relative): 3.107739e-02 
Epoch 604 use: 496.98 second.

epoch 605 starting......
Epoch:  605 | train loss: 1.624787e-03 | valid loss: 1.586798e-03 
      	| train loss (relative): 3.194935e-02 | valid loss (relative): 3.106359e-02 
Epoch 605 use: 483.38 second.

epoch 606 starting......
Epoch:  606 | train loss: 1.625506e-03 | valid loss: 1.586085e-03 
      	| train loss (relative): 3.196475e-02 | valid loss (relative): 3.105236e-02 
Epoch 606 use: 504.42 second.

epoch 607 starting......
Epoch:  607 | train loss: 1.625832e-03 | valid loss: 1.590770e-03 
      	| train loss (relative): 3.196895e-02 | valid loss (relative): 3.105212e-02 
Epoch 607 use: 489.11 second.

epoch 608 starting......
Epoch:  608 | train loss: 1.628252e-03 | valid loss: 1.596922e-03 
      	| train loss (relative): 3.201486e-02 | valid loss (relative): 3.127354e-02 
Epoch 608 use: 487.23 second.

epoch 609 starting......
Epoch:  609 | train loss: 1.630305e-03 | valid loss: 1.591354e-03 
      	| train loss (relative): 3.206021e-02 | valid loss (relative): 3.111563e-02 
Epoch 609 use: 474.98 second.

epoch 610 starting......
Epoch:  610 | train loss: 1.629374e-03 | valid loss: 1.593335e-03 
      	| train loss (relative): 3.204166e-02 | valid loss (relative): 3.112061e-02 
Epoch 610 use: 493.90 second.

epoch 611 starting......
Epoch:  611 | train loss: 1.629722e-03 | valid loss: 1.593116e-03 
      	| train loss (relative): 3.204377e-02 | valid loss (relative): 3.112855e-02 
Epoch 611 use: 485.71 second.

epoch 612 starting......
Epoch:  612 | train loss: 1.627334e-03 | valid loss: 1.593685e-03 
      	| train loss (relative): 3.199315e-02 | valid loss (relative): 3.114745e-02 
Epoch 612 use: 486.36 second.

epoch 613 starting......
Epoch:  613 | train loss: 1.630783e-03 | valid loss: 1.596735e-03 
      	| train loss (relative): 3.206187e-02 | valid loss (relative): 3.125768e-02 
Epoch 613 use: 497.27 second.

epoch 614 starting......
Epoch:  614 | train loss: 1.629089e-03 | valid loss: 1.595384e-03 
      	| train loss (relative): 3.202967e-02 | valid loss (relative): 3.119804e-02 
Epoch 614 use: 478.90 second.

epoch 615 starting......
Epoch:  615 | train loss: 1.630555e-03 | valid loss: 1.594017e-03 
      	| train loss (relative): 3.205917e-02 | valid loss (relative): 3.117753e-02 
Epoch 615 use: 474.06 second.

epoch 616 starting......
Epoch:  616 | train loss: 1.628385e-03 | valid loss: 1.599180e-03 
      	| train loss (relative): 3.201609e-02 | valid loss (relative): 3.132567e-02 
Epoch 616 use: 467.63 second.

epoch 617 starting......
Epoch:  617 | train loss: 1.629923e-03 | valid loss: 1.597745e-03 
      	| train loss (relative): 3.204724e-02 | valid loss (relative): 3.112653e-02 
Epoch 617 use: 485.60 second.

epoch 618 starting......
Epoch:  618 | train loss: 1.625578e-03 | valid loss: 1.595240e-03 
      	| train loss (relative): 3.195369e-02 | valid loss (relative): 3.127434e-02 
Epoch 618 use: 471.94 second.

epoch 619 starting......
Epoch:  619 | train loss: 1.628121e-03 | valid loss: 1.604188e-03 
      	| train loss (relative): 3.200873e-02 | valid loss (relative): 3.132225e-02 
Epoch 619 use: 484.20 second.

epoch 620 starting......
Epoch:  620 | train loss: 1.630257e-03 | valid loss: 1.604226e-03 
      	| train loss (relative): 3.205122e-02 | valid loss (relative): 3.146261e-02 
Epoch 620 use: 483.53 second.

epoch 621 starting......
Epoch:  621 | train loss: 1.632450e-03 | valid loss: 1.593751e-03 
      	| train loss (relative): 3.209975e-02 | valid loss (relative): 3.120438e-02 
Epoch 621 use: 491.35 second.

epoch 622 starting......
Epoch:  622 | train loss: 1.624178e-03 | valid loss: 1.596411e-03 
      	| train loss (relative): 3.193223e-02 | valid loss (relative): 3.124138e-02 
Epoch 622 use: 477.59 second.

epoch 623 starting......
Epoch:  623 | train loss: 1.627225e-03 | valid loss: 1.607806e-03 
      	| train loss (relative): 3.198829e-02 | valid loss (relative): 3.166734e-02 
Epoch 623 use: 480.30 second.

epoch 624 starting......
Epoch:  624 | train loss: 1.629214e-03 | valid loss: 1.594146e-03 
      	| train loss (relative): 3.203004e-02 | valid loss (relative): 3.129494e-02 
Epoch 624 use: 493.20 second.

epoch 625 starting......
Epoch:  625 | train loss: 1.622878e-03 | valid loss: 1.590150e-03 
      	| train loss (relative): 3.190275e-02 | valid loss (relative): 3.117607e-02 
Epoch 625 use: 473.82 second.

epoch 626 starting......
Epoch:  626 | train loss: 1.623905e-03 | valid loss: 1.597286e-03 
      	| train loss (relative): 3.192898e-02 | valid loss (relative): 3.125120e-02 
Epoch 626 use: 476.35 second.

epoch 627 starting......
Epoch:  627 | train loss: 1.622209e-03 | valid loss: 1.592807e-03 
      	| train loss (relative): 3.189006e-02 | valid loss (relative): 3.114462e-02 
Epoch 627 use: 478.91 second.

epoch 628 starting......
Epoch:  628 | train loss: 1.621772e-03 | valid loss: 1.593748e-03 
      	| train loss (relative): 3.188028e-02 | valid loss (relative): 3.128283e-02 
Epoch 628 use: 491.46 second.

epoch 629 starting......
Epoch:  629 | train loss: 1.623022e-03 | valid loss: 1.601897e-03 
      	| train loss (relative): 3.190564e-02 | valid loss (relative): 3.149794e-02 
Epoch 629 use: 481.54 second.

epoch 630 starting......
Epoch:  630 | train loss: 1.622650e-03 | valid loss: 1.605942e-03 
      	| train loss (relative): 3.189721e-02 | valid loss (relative): 3.151678e-02 
Epoch 630 use: 481.91 second.

epoch 631 starting......
Epoch:  631 | train loss: 1.627130e-03 | valid loss: 1.595062e-03 
      	| train loss (relative): 3.198536e-02 | valid loss (relative): 3.127350e-02 
Epoch 631 use: 491.47 second.

epoch 632 starting......
Epoch:  632 | train loss: 1.619895e-03 | valid loss: 1.594671e-03 
      	| train loss (relative): 3.184003e-02 | valid loss (relative): 3.130350e-02 
Epoch 632 use: 487.51 second.

epoch 633 starting......
Epoch:  633 | train loss: 1.616626e-03 | valid loss: 1.589858e-03 
      	| train loss (relative): 3.177999e-02 | valid loss (relative): 3.089494e-02 
Epoch 633 use: 484.68 second.

epoch 634 starting......
Epoch:  634 | train loss: 1.614641e-03 | valid loss: 1.593251e-03 
      	| train loss (relative): 3.173393e-02 | valid loss (relative): 3.111480e-02 
Epoch 634 use: 481.27 second.

epoch 635 starting......
Epoch:  635 | train loss: 1.618922e-03 | valid loss: 1.596731e-03 
      	| train loss (relative): 3.182124e-02 | valid loss (relative): 3.111974e-02 
Epoch 635 use: 487.23 second.

epoch 636 starting......
Epoch:  636 | train loss: 1.620386e-03 | valid loss: 1.596002e-03 
      	| train loss (relative): 3.185269e-02 | valid loss (relative): 3.124941e-02 
Epoch 636 use: 489.68 second.

epoch 637 starting......
Epoch:  637 | train loss: 1.619439e-03 | valid loss: 1.601436e-03 
      	| train loss (relative): 3.183082e-02 | valid loss (relative): 3.113710e-02 
Epoch 637 use: 473.39 second.

epoch 638 starting......
Epoch:  638 | train loss: 1.620231e-03 | valid loss: 1.595243e-03 
      	| train loss (relative): 3.184247e-02 | valid loss (relative): 3.133852e-02 
Epoch 638 use: 482.03 second.

epoch 639 starting......
Epoch:  639 | train loss: 1.615206e-03 | valid loss: 1.595619e-03 
      	| train loss (relative): 3.174771e-02 | valid loss (relative): 3.130236e-02 
Epoch 639 use: 475.66 second.

epoch 640 starting......
Epoch:  640 | train loss: 1.615749e-03 | valid loss: 1.590940e-03 
      	| train loss (relative): 3.175810e-02 | valid loss (relative): 3.113618e-02 
Epoch 640 use: 480.43 second.

epoch 641 starting......
Epoch:  641 | train loss: 1.616225e-03 | valid loss: 1.594635e-03 
      	| train loss (relative): 3.176462e-02 | valid loss (relative): 3.111426e-02 
Epoch 641 use: 486.90 second.

epoch 642 starting......
Epoch:  642 | train loss: 1.616584e-03 | valid loss: 1.592937e-03 
      	| train loss (relative): 3.177568e-02 | valid loss (relative): 3.118773e-02 
Epoch 642 use: 477.43 second.

epoch 643 starting......
Epoch:  643 | train loss: 1.617893e-03 | valid loss: 1.593942e-03 
      	| train loss (relative): 3.179991e-02 | valid loss (relative): 3.114186e-02 
Epoch 643 use: 494.37 second.

epoch 644 starting......
Epoch:  644 | train loss: 1.614271e-03 | valid loss: 1.598049e-03 
      	| train loss (relative): 3.172426e-02 | valid loss (relative): 3.122335e-02 
Epoch 644 use: 477.16 second.

epoch 645 starting......
Epoch:  645 | train loss: 1.614518e-03 | valid loss: 1.587574e-03 
      	| train loss (relative): 3.173295e-02 | valid loss (relative): 3.113218e-02 
Epoch 645 use: 474.33 second.

epoch 646 starting......
Epoch:  646 | train loss: 1.613060e-03 | valid loss: 1.595509e-03 
      	| train loss (relative): 3.170585e-02 | valid loss (relative): 3.130158e-02 
Epoch 646 use: 478.81 second.

epoch 647 starting......
Epoch:  647 | train loss: 1.616076e-03 | valid loss: 1.595050e-03 
      	| train loss (relative): 3.176569e-02 | valid loss (relative): 3.112309e-02 
Epoch 647 use: 481.57 second.

epoch 648 starting......
Epoch:  648 | train loss: 1.614847e-03 | valid loss: 1.595154e-03 
      	| train loss (relative): 3.173836e-02 | valid loss (relative): 3.093415e-02 
Epoch 648 use: 472.16 second.

epoch 649 starting......
Epoch:  649 | train loss: 1.614817e-03 | valid loss: 1.593113e-03 
      	| train loss (relative): 3.173415e-02 | valid loss (relative): 3.119579e-02 
Epoch 649 use: 483.77 second.

epoch 650 starting......
Epoch:  650 | train loss: 1.612094e-03 | valid loss: 1.592172e-03 
      	| train loss (relative): 3.168274e-02 | valid loss (relative): 3.129765e-02 
Epoch 650 use: 491.41 second.

epoch 651 starting......
Epoch:  651 | train loss: 1.613297e-03 | valid loss: 1.597964e-03 
      	| train loss (relative): 3.170793e-02 | valid loss (relative): 3.148819e-02 
Epoch 651 use: 488.32 second.

epoch 652 starting......
Epoch:  652 | train loss: 1.614773e-03 | valid loss: 1.600278e-03 
      	| train loss (relative): 3.173936e-02 | valid loss (relative): 3.159817e-02 
Epoch 652 use: 474.06 second.

epoch 653 starting......
Epoch:  653 | train loss: 1.613914e-03 | valid loss: 1.590695e-03 
      	| train loss (relative): 3.172356e-02 | valid loss (relative): 3.109305e-02 
Epoch 653 use: 493.41 second.

epoch 654 starting......
Epoch:  654 | train loss: 1.610740e-03 | valid loss: 1.590467e-03 
      	| train loss (relative): 3.165236e-02 | valid loss (relative): 3.116803e-02 
Epoch 654 use: 478.55 second.

epoch 655 starting......
Epoch:  655 | train loss: 1.610526e-03 | valid loss: 1.597325e-03 
      	| train loss (relative): 3.165181e-02 | valid loss (relative): 3.145078e-02 
Epoch 655 use: 472.44 second.

epoch 656 starting......
Epoch:  656 | train loss: 1.610297e-03 | valid loss: 1.586462e-03 
      	| train loss (relative): 3.164617e-02 | valid loss (relative): 3.115307e-02 
Epoch 656 use: 491.29 second.

epoch 657 starting......
Epoch:  657 | train loss: 1.607368e-03 | valid loss: 1.588866e-03 
      	| train loss (relative): 3.158501e-02 | valid loss (relative): 3.114879e-02 
Epoch 657 use: 483.92 second.

epoch 658 starting......
Epoch:  658 | train loss: 1.609070e-03 | valid loss: 1.594142e-03 
      	| train loss (relative): 3.161954e-02 | valid loss (relative): 3.123792e-02 
Epoch 658 use: 499.24 second.

epoch 659 starting......
Epoch:  659 | train loss: 1.609936e-03 | valid loss: 1.582084e-03 
      	| train loss (relative): 3.163474e-02 | valid loss (relative): 3.100616e-02 
Epoch 659 use: 505.84 second.

epoch 660 starting......
Epoch:  660 | train loss: 1.602393e-03 | valid loss: 1.583224e-03 
      	| train loss (relative): 3.148789e-02 | valid loss (relative): 3.117647e-02 
Epoch 660 use: 485.57 second.

epoch 661 starting......
Epoch:  661 | train loss: 1.603570e-03 | valid loss: 1.584586e-03 
      	| train loss (relative): 3.151022e-02 | valid loss (relative): 3.077268e-02 
Epoch 661 use: 475.70 second.

epoch 662 starting......
Epoch:  662 | train loss: 1.606648e-03 | valid loss: 1.587592e-03 
      	| train loss (relative): 3.156513e-02 | valid loss (relative): 3.097661e-02 
Epoch 662 use: 475.84 second.

epoch 663 starting......
Epoch:  663 | train loss: 1.606261e-03 | valid loss: 1.579364e-03 
      	| train loss (relative): 3.156590e-02 | valid loss (relative): 3.093271e-02 
Epoch 663 use: 478.22 second.

epoch 664 starting......
Epoch:  664 | train loss: 1.602908e-03 | valid loss: 1.581569e-03 
      	| train loss (relative): 3.149454e-02 | valid loss (relative): 3.081104e-02 
Epoch 664 use: 481.83 second.

epoch 665 starting......
Epoch:  665 | train loss: 1.599143e-03 | valid loss: 1.585707e-03 
      	| train loss (relative): 3.141993e-02 | valid loss (relative): 3.092129e-02 
Epoch 665 use: 495.83 second.

epoch 666 starting......
Epoch:  666 | train loss: 1.599500e-03 | valid loss: 1.580469e-03 
      	| train loss (relative): 3.142728e-02 | valid loss (relative): 3.086228e-02 
Epoch 666 use: 487.64 second.

epoch 667 starting......
Epoch:  667 | train loss: 1.599716e-03 | valid loss: 1.578961e-03 
      	| train loss (relative): 3.143099e-02 | valid loss (relative): 3.067577e-02 
Epoch 667 use: 479.48 second.

epoch 668 starting......
Epoch:  668 | train loss: 1.602205e-03 | valid loss: 1.590370e-03 
      	| train loss (relative): 3.147912e-02 | valid loss (relative): 3.126243e-02 
Epoch 668 use: 493.61 second.

epoch 669 starting......
Epoch:  669 | train loss: 1.601917e-03 | valid loss: 1.581289e-03 
      	| train loss (relative): 3.148090e-02 | valid loss (relative): 3.097608e-02 
Epoch 669 use: 483.94 second.

epoch 670 starting......
Epoch:  670 | train loss: 1.598991e-03 | valid loss: 1.579535e-03 
      	| train loss (relative): 3.141583e-02 | valid loss (relative): 3.090308e-02 
Epoch 670 use: 476.09 second.

epoch 671 starting......
Epoch:  671 | train loss: 1.598087e-03 | valid loss: 1.577061e-03 
      	| train loss (relative): 3.139894e-02 | valid loss (relative): 3.092797e-02 
Epoch 671 use: 481.35 second.

epoch 672 starting......
Epoch:  672 | train loss: 1.597533e-03 | valid loss: 1.589343e-03 
      	| train loss (relative): 3.138954e-02 | valid loss (relative): 3.121715e-02 
Epoch 672 use: 478.63 second.

epoch 673 starting......
Epoch:  673 | train loss: 1.600350e-03 | valid loss: 1.581527e-03 
      	| train loss (relative): 3.144835e-02 | valid loss (relative): 3.100287e-02 
Epoch 673 use: 487.02 second.

epoch 674 starting......
Epoch:  674 | train loss: 1.599199e-03 | valid loss: 1.583235e-03 
      	| train loss (relative): 3.141910e-02 | valid loss (relative): 3.118693e-02 
Epoch 674 use: 535.04 second.

epoch 675 starting......
Epoch:  675 | train loss: 1.598798e-03 | valid loss: 1.582735e-03 
      	| train loss (relative): 3.141830e-02 | valid loss (relative): 3.091613e-02 
Epoch 675 use: 501.92 second.

epoch 676 starting......
Epoch:  676 | train loss: 1.596115e-03 | valid loss: 1.589826e-03 
      	| train loss (relative): 3.136362e-02 | valid loss (relative): 3.124371e-02 
Epoch 676 use: 487.34 second.

epoch 677 starting......
Epoch:  677 | train loss: 1.595005e-03 | valid loss: 1.570216e-03 
      	| train loss (relative): 3.134126e-02 | valid loss (relative): 3.058671e-02 
Epoch 677 use: 483.03 second.

epoch 678 starting......
Epoch:  678 | train loss: 1.591950e-03 | valid loss: 1.572181e-03 
      	| train loss (relative): 3.127298e-02 | valid loss (relative): 3.075157e-02 
Epoch 678 use: 492.60 second.

epoch 679 starting......
Epoch:  679 | train loss: 1.593888e-03 | valid loss: 1.583822e-03 
      	| train loss (relative): 3.131339e-02 | valid loss (relative): 3.098498e-02 
Epoch 679 use: 480.65 second.

epoch 680 starting......
Epoch:  680 | train loss: 1.599152e-03 | valid loss: 1.577684e-03 
      	| train loss (relative): 3.141676e-02 | valid loss (relative): 3.076882e-02 
Epoch 680 use: 486.04 second.

epoch 681 starting......
Epoch:  681 | train loss: 1.594716e-03 | valid loss: 1.574596e-03 
      	| train loss (relative): 3.132625e-02 | valid loss (relative): 3.090365e-02 
Epoch 681 use: 501.80 second.

epoch 682 starting......
Epoch:  682 | train loss: 1.594570e-03 | valid loss: 1.580632e-03 
      	| train loss (relative): 3.132771e-02 | valid loss (relative): 3.105998e-02 
Epoch 682 use: 496.37 second.

epoch 683 starting......
Epoch:  683 | train loss: 1.593766e-03 | valid loss: 1.577053e-03 
      	| train loss (relative): 3.130939e-02 | valid loss (relative): 3.095085e-02 
Epoch 683 use: 473.36 second.

epoch 684 starting......
Epoch:  684 | train loss: 1.588779e-03 | valid loss: 1.577583e-03 
      	| train loss (relative): 3.121540e-02 | valid loss (relative): 3.085271e-02 
Epoch 684 use: 519.22 second.

epoch 685 starting......
Epoch:  685 | train loss: 1.588747e-03 | valid loss: 1.593465e-03 
      	| train loss (relative): 3.120804e-02 | valid loss (relative): 3.106858e-02 
Epoch 685 use: 499.71 second.

epoch 686 starting......
Epoch:  686 | train loss: 1.597499e-03 | valid loss: 1.564387e-03 
      	| train loss (relative): 3.138926e-02 | valid loss (relative): 3.054938e-02 
Epoch 686 use: 474.24 second.

epoch 687 starting......
Epoch:  687 | train loss: 1.582847e-03 | valid loss: 1.565723e-03 
      	| train loss (relative): 3.109453e-02 | valid loss (relative): 3.054167e-02 
Epoch 687 use: 511.15 second.

epoch 688 starting......
Epoch:  688 | train loss: 1.582318e-03 | valid loss: 1.566523e-03 
      	| train loss (relative): 3.108747e-02 | valid loss (relative): 3.061687e-02 
Epoch 688 use: 493.64 second.

epoch 689 starting......
Epoch:  689 | train loss: 1.583054e-03 | valid loss: 1.565357e-03 
      	| train loss (relative): 3.109973e-02 | valid loss (relative): 3.059752e-02 
Epoch 689 use: 490.59 second.

epoch 690 starting......
Epoch:  690 | train loss: 1.585101e-03 | valid loss: 1.570916e-03 
      	| train loss (relative): 3.113629e-02 | valid loss (relative): 3.068102e-02 
Epoch 690 use: 484.73 second.

epoch 691 starting......
Epoch:  691 | train loss: 1.587568e-03 | valid loss: 1.574082e-03 
      	| train loss (relative): 3.118690e-02 | valid loss (relative): 3.073365e-02 
Epoch 691 use: 483.90 second.

epoch 692 starting......
Epoch:  692 | train loss: 1.585134e-03 | valid loss: 1.566896e-03 
      	| train loss (relative): 3.113587e-02 | valid loss (relative): 3.066855e-02 
Epoch 692 use: 489.93 second.

epoch 693 starting......
Epoch:  693 | train loss: 1.580126e-03 | valid loss: 1.561342e-03 
      	| train loss (relative): 3.103526e-02 | valid loss (relative): 3.038080e-02 
Epoch 693 use: 469.68 second.

epoch 694 starting......
Epoch:  694 | train loss: 1.578247e-03 | valid loss: 1.562935e-03 
      	| train loss (relative): 3.099892e-02 | valid loss (relative): 3.046550e-02 
Epoch 694 use: 482.23 second.

epoch 695 starting......
Epoch:  695 | train loss: 1.580761e-03 | valid loss: 1.573440e-03 
      	| train loss (relative): 3.104275e-02 | valid loss (relative): 3.081535e-02 
Epoch 695 use: 487.25 second.

epoch 696 starting......
Epoch:  696 | train loss: 1.584272e-03 | valid loss: 1.567337e-03 
      	| train loss (relative): 3.112194e-02 | valid loss (relative): 3.059228e-02 
Epoch 696 use: 490.71 second.

epoch 697 starting......
Epoch:  697 | train loss: 1.580715e-03 | valid loss: 1.568426e-03 
      	| train loss (relative): 3.104561e-02 | valid loss (relative): 3.055446e-02 
Epoch 697 use: 474.00 second.

epoch 698 starting......
Epoch:  698 | train loss: 1.581694e-03 | valid loss: 1.564044e-03 
      	| train loss (relative): 3.106713e-02 | valid loss (relative): 3.055894e-02 
Epoch 698 use: 482.59 second.

epoch 699 starting......
Epoch:  699 | train loss: 1.579971e-03 | valid loss: 1.565121e-03 
      	| train loss (relative): 3.103209e-02 | valid loss (relative): 3.058286e-02 
Epoch 699 use: 488.34 second.

test MSE Error: 1.589836e-03 | relative MSE Error: 3.120508e-02 
 Total time used for training: 13.52 hour.
MESLoss saved to  /rds/general/user/jy220/home/new_results/Variational_False_Changelr_False_MSELoss_Latent_256_nearest_neighbouring_True_SFC_nums_3_startlr_0.001_n_epoches_700.txt
relative MSELoss saved to  /rds/general/user/jy220/home/new_results/Variational_False_Changelr_False_reMSELoss_Latent_256_nearest_neighbouring_True_SFC_nums_3_startlr_0.001_n_epoches_700.txt
model saved to /rds/general/user/jy220/home/new_results/Variational_False_Changelr_False_Latent_256_Nearest_neighbouring_True_SFC_nums_3_startlr_0.001_n_epoches_700.pth
model_dict saved to /rds/general/user/jy220/home/new_results/Variational_False_Changelr_False_Latent_256_Nearest_neighbouring_True_SFC_nums_3_startlr_0.001_n_epoches_700_dict.pth
... Training slugflow data completed, Run finished Thu 19 Aug 07:13:32 BST 2021 ...
{'data_dir': '/rds/general/user/jy220/home/tensors/', 'data_type': 'tensors', 'mode': 'train', 'vtu_fields': 'Component1::ComponentMassFractionPhase1, phase1::Velocity', 'variational': 'False', 'optimizer': 'Adamax', 'structured': 'False', 'changing_lr': 'False', 'self_concat': '2', 'dimension': '3', 'sfc_nums': '3', 'components': '4', 'nearest_neighbouring': 'True', 'dims_latent': '256', 'activation': 'Tanh', 'tk_file': '/rds/general/user/jy220/home/slugflow_tk.pt', 'tb_file': '/rds/general/user/jy220/home/slugflow_tb.pt', 'sfc_file': '/rds/general/user/jy220/home/SFC-CAE-Ready-to-use/sfcs.pt', 'inv_sfc_file': '/rds/general/user/jy220/home/SFC-CAE-Ready-to-use/inv_sfcs.pt', 'coords_file': '/rds/general/user/jy220/home/SFC-CAE-Ready-to-use/coords.pt', 'cells_file': '/rds/general/user/jy220/home/SFC-CAE-Ready-to-use/cells.npy', 'state_load': '/rds/general/user/jy220/home/new_results/Variational_False_Changelr_False_Latent_256_Nearest_neighbouring_True_SFC_nums_3_startlr_0.001_n_epoches_700_dict.pth', 'batch_size': '16', 'lr': '0.001', 'n_epoches': '150', 'seed': '17', 'visualize': 'False', 'reconstructed_path': 'None', 'reconstruct_start_index': '0', 'reconstruct_end_index': '50', 'save_path': '/rds/general/user/jy220/home/new_results/'}
[[ 2.50825269e-01 -1.67256990e-02 -1.22268730e-03]
 [ 2.38611959e-01 -5.50627777e-03 -5.06451913e-03]
 [ 2.39454874e-01 -1.59563257e-02  3.96778323e-03]
 ...
 [ 9.11361096e+00 -2.21908381e-02  2.22384902e-03]
 [ 9.11847310e+00 -2.84346931e-02 -2.34839590e-04]
 [ 9.11039661e+00 -2.51498573e-02 -8.70661044e-03]]
{'tetra': array([[      0,       1,       2,       3],
       [      4,       5,       6,       7],
       [      8,       9,      10,      11],
       ...,
       [1342744, 1342745, 1342746, 1342747],
       [1342748, 1342749, 1342750, 1342751],
       [1342752, 1342753, 1342754, 1342755]])}
vtu fields:  ['Component1::ComponentMassFractionPhase1', 'phase1::Velocity'] 
 structured  False 
 activation  Tanh() 
 self concat  2 
 sfc_nums  3 

dims_latent  256 
 components  4 
 nearest_neighbouring  True 

visualize  False 
 sample number  1706 

reading sfc nums......
[array([  41684,   41685,   41674, ..., 1235560, 1235564, 1235558]), array([954289, 954290, 954291, ..., 420685, 420687, 420688]), array([  40156,   40155,   40158, ..., 1123478, 1123475, 1123467])]
reading inverse sfc nums......
[array([   8146,    8145,    8144, ..., 1274444, 1274445, 1273166]), array([547280, 547283, 593037, ..., 933933, 933932, 864488]), array([ 66437,  66439, 122512, ..., 459416, 415130, 459418])]
tk:  tensor([0.7581, 0.0418, 0.1840, 0.1464], dtype=torch.float64) 

tb:  tensor([-0.3816, -0.3618, -0.0308,  0.1446], dtype=torch.float64) 

length of train set: 1505 

length of valid set: 100 

length of test set: 101 

torch device num: 4 

Let's use 4 GPUs!
epoch 700 starting......
Epoch:  700 | train loss: 1.809120e-03 | valid loss: 1.562705e-03 
      	| train loss (relative): 3.554495e-02 | valid loss (relative): 3.066396e-02 
Epoch 700 use: 507.73 second.

epoch 701 starting......
Epoch:  701 | train loss: 1.583029e-03 | valid loss: 1.547012e-03 
      	| train loss (relative): 3.109863e-02 | valid loss (relative): 3.033882e-02 
Epoch 701 use: 452.36 second.

epoch 702 starting......
Epoch:  702 | train loss: 1.572080e-03 | valid loss: 1.546418e-03 
      	| train loss (relative): 3.087983e-02 | valid loss (relative): 3.027572e-02 
Epoch 702 use: 432.38 second.

epoch 703 starting......
Epoch:  703 | train loss: 1.569112e-03 | valid loss: 1.543636e-03 
      	| train loss (relative): 3.081813e-02 | valid loss (relative): 3.028091e-02 
Epoch 703 use: 425.99 second.

epoch 704 starting......
Epoch:  704 | train loss: 1.566843e-03 | valid loss: 1.544066e-03 
      	| train loss (relative): 3.077387e-02 | valid loss (relative): 3.022832e-02 
Epoch 704 use: 418.95 second.

epoch 705 starting......
Epoch:  705 | train loss: 1.566466e-03 | valid loss: 1.545190e-03 
      	| train loss (relative): 3.076201e-02 | valid loss (relative): 3.030351e-02 
Epoch 705 use: 427.66 second.

epoch 706 starting......
Epoch:  706 | train loss: 1.566923e-03 | valid loss: 1.547233e-03 
      	| train loss (relative): 3.076609e-02 | valid loss (relative): 3.032871e-02 
Epoch 706 use: 413.34 second.

epoch 707 starting......
Epoch:  707 | train loss: 1.569040e-03 | valid loss: 1.550230e-03 
      	| train loss (relative): 3.081382e-02 | valid loss (relative): 3.038454e-02 
Epoch 707 use: 415.95 second.

epoch 708 starting......
Epoch:  708 | train loss: 1.571497e-03 | valid loss: 1.552804e-03 
      	| train loss (relative): 3.085776e-02 | valid loss (relative): 3.049052e-02 
Epoch 708 use: 442.81 second.

epoch 709 starting......
Epoch:  709 | train loss: 1.573154e-03 | valid loss: 1.554334e-03 
      	| train loss (relative): 3.089703e-02 | valid loss (relative): 3.043794e-02 
Epoch 709 use: 419.47 second.

epoch 710 starting......
Epoch:  710 | train loss: 1.572391e-03 | valid loss: 1.552336e-03 
      	| train loss (relative): 3.087647e-02 | valid loss (relative): 3.040713e-02 
Epoch 710 use: 418.92 second.

epoch 711 starting......
Epoch:  711 | train loss: 1.571757e-03 | valid loss: 1.554688e-03 
      	| train loss (relative): 3.086521e-02 | valid loss (relative): 3.048792e-02 
Epoch 711 use: 432.29 second.

epoch 712 starting......
Epoch:  712 | train loss: 1.572806e-03 | valid loss: 1.556188e-03 
      	| train loss (relative): 3.088613e-02 | valid loss (relative): 3.056820e-02 
Epoch 712 use: 414.22 second.

epoch 713 starting......
Epoch:  713 | train loss: 1.576067e-03 | valid loss: 1.558510e-03 
      	| train loss (relative): 3.095166e-02 | valid loss (relative): 3.049548e-02 
Epoch 713 use: 408.42 second.

epoch 714 starting......
Epoch:  714 | train loss: 1.575719e-03 | valid loss: 1.567964e-03 
      	| train loss (relative): 3.094110e-02 | valid loss (relative): 3.049033e-02 
Epoch 714 use: 405.23 second.

epoch 715 starting......
Epoch:  715 | train loss: 1.578991e-03 | valid loss: 1.562591e-03 
      	| train loss (relative): 3.100319e-02 | valid loss (relative): 3.053492e-02 
Epoch 715 use: 420.59 second.

epoch 716 starting......
Epoch:  716 | train loss: 1.576779e-03 | valid loss: 1.562760e-03 
      	| train loss (relative): 3.096221e-02 | valid loss (relative): 3.056737e-02 
Epoch 716 use: 425.99 second.

epoch 717 starting......
Epoch:  717 | train loss: 1.577526e-03 | valid loss: 1.562942e-03 
      	| train loss (relative): 3.097712e-02 | valid loss (relative): 3.069584e-02 
Epoch 717 use: 405.84 second.

epoch 718 starting......
Epoch:  718 | train loss: 1.580324e-03 | valid loss: 1.566607e-03 
      	| train loss (relative): 3.103749e-02 | valid loss (relative): 3.071019e-02 
Epoch 718 use: 422.38 second.

epoch 719 starting......
Epoch:  719 | train loss: 1.577915e-03 | valid loss: 1.568104e-03 
      	| train loss (relative): 3.098383e-02 | valid loss (relative): 3.081318e-02 
Epoch 719 use: 427.48 second.

epoch 720 starting......
Epoch:  720 | train loss: 1.577509e-03 | valid loss: 1.574627e-03 
      	| train loss (relative): 3.098018e-02 | valid loss (relative): 3.092965e-02 
Epoch 720 use: 415.69 second.

epoch 721 starting......
Epoch:  721 | train loss: 1.573076e-03 | valid loss: 1.563875e-03 
      	| train loss (relative): 3.088744e-02 | valid loss (relative): 3.065315e-02 
Epoch 721 use: 444.00 second.

epoch 722 starting......
Epoch:  722 | train loss: 1.574918e-03 | valid loss: 1.566108e-03 
      	| train loss (relative): 3.092333e-02 | valid loss (relative): 3.070352e-02 
Epoch 722 use: 410.29 second.

epoch 723 starting......
Epoch:  723 | train loss: 1.576410e-03 | valid loss: 1.567255e-03 
      	| train loss (relative): 3.095575e-02 | valid loss (relative): 3.077508e-02 
Epoch 723 use: 494.93 second.

epoch 724 starting......
Epoch:  724 | train loss: 1.576566e-03 | valid loss: 1.563216e-03 
      	| train loss (relative): 3.096132e-02 | valid loss (relative): 3.064095e-02 
Epoch 724 use: 485.56 second.

epoch 725 starting......
Epoch:  725 | train loss: 1.575484e-03 | valid loss: 1.569116e-03 
      	| train loss (relative): 3.093280e-02 | valid loss (relative): 3.094405e-02 
Epoch 725 use: 515.43 second.

epoch 726 starting......
Epoch:  726 | train loss: 1.575670e-03 | valid loss: 1.560425e-03 
      	| train loss (relative): 3.093902e-02 | valid loss (relative): 3.052717e-02 
Epoch 726 use: 458.48 second.

epoch 727 starting......
Epoch:  727 | train loss: 1.569986e-03 | valid loss: 1.564153e-03 
      	| train loss (relative): 3.082422e-02 | valid loss (relative): 3.050616e-02 
Epoch 727 use: 483.45 second.

epoch 728 starting......
Epoch:  728 | train loss: 1.569466e-03 | valid loss: 1.563408e-03 
      	| train loss (relative): 3.081522e-02 | valid loss (relative): 3.070901e-02 
Epoch 728 use: 507.27 second.

epoch 729 starting......
Epoch:  729 | train loss: 1.569627e-03 | valid loss: 1.565412e-03 
      	| train loss (relative): 3.081824e-02 | valid loss (relative): 3.061074e-02 
Epoch 729 use: 500.33 second.

epoch 730 starting......
Epoch:  730 | train loss: 1.576962e-03 | valid loss: 1.560496e-03 
      	| train loss (relative): 3.096485e-02 | valid loss (relative): 3.058943e-02 
Epoch 730 use: 454.20 second.

epoch 731 starting......
Epoch:  731 | train loss: 1.567183e-03 | valid loss: 1.556720e-03 
      	| train loss (relative): 3.077025e-02 | valid loss (relative): 3.052300e-02 
Epoch 731 use: 439.72 second.

epoch 732 starting......
Epoch:  732 | train loss: 1.565946e-03 | valid loss: 1.557636e-03 
      	| train loss (relative): 3.074555e-02 | valid loss (relative): 3.060213e-02 
Epoch 732 use: 465.23 second.

epoch 733 starting......
Epoch:  733 | train loss: 1.567971e-03 | valid loss: 1.557833e-03 
      	| train loss (relative): 3.079079e-02 | valid loss (relative): 3.060656e-02 
Epoch 733 use: 504.49 second.

epoch 734 starting......
Epoch:  734 | train loss: 1.568285e-03 | valid loss: 1.566162e-03 
      	| train loss (relative): 3.078965e-02 | valid loss (relative): 3.075193e-02 
Epoch 734 use: 412.01 second.

epoch 735 starting......
Epoch:  735 | train loss: 1.570550e-03 | valid loss: 1.567105e-03 
      	| train loss (relative): 3.083814e-02 | valid loss (relative): 3.066695e-02 
Epoch 735 use: 413.75 second.

epoch 736 starting......
Epoch:  736 | train loss: 1.567401e-03 | valid loss: 1.562964e-03 
      	| train loss (relative): 3.077246e-02 | valid loss (relative): 3.059951e-02 
Epoch 736 use: 587.54 second.

epoch 737 starting......
Epoch:  737 | train loss: 1.567051e-03 | valid loss: 1.555083e-03 
      	| train loss (relative): 3.076841e-02 | valid loss (relative): 3.036011e-02 
Epoch 737 use: 481.16 second.

epoch 738 starting......
Epoch:  738 | train loss: 1.567333e-03 | valid loss: 1.564590e-03 
      	| train loss (relative): 3.076914e-02 | valid loss (relative): 3.058316e-02 
Epoch 738 use: 437.88 second.

epoch 739 starting......
Epoch:  739 | train loss: 1.568760e-03 | valid loss: 1.556350e-03 
      	| train loss (relative): 3.080172e-02 | valid loss (relative): 3.045143e-02 
Epoch 739 use: 543.98 second.

epoch 740 starting......
Epoch:  740 | train loss: 1.562081e-03 | valid loss: 1.561443e-03 
      	| train loss (relative): 3.066310e-02 | valid loss (relative): 3.076626e-02 
Epoch 740 use: 477.21 second.

epoch 741 starting......
Epoch:  741 | train loss: 1.567832e-03 | valid loss: 1.561524e-03 
      	| train loss (relative): 3.078346e-02 | valid loss (relative): 3.047235e-02 
Epoch 741 use: 463.66 second.

epoch 742 starting......
Epoch:  742 | train loss: 1.562344e-03 | valid loss: 1.554174e-03 
      	| train loss (relative): 3.067147e-02 | valid loss (relative): 3.049346e-02 
Epoch 742 use: 494.05 second.

epoch 743 starting......
Epoch:  743 | train loss: 1.559285e-03 | valid loss: 1.551346e-03 
      	| train loss (relative): 3.061128e-02 | valid loss (relative): 3.064711e-02 
Epoch 743 use: 445.87 second.

epoch 744 starting......
Epoch:  744 | train loss: 1.561819e-03 | valid loss: 1.557573e-03 
      	| train loss (relative): 3.066194e-02 | valid loss (relative): 3.056768e-02 
Epoch 744 use: 437.03 second.

epoch 745 starting......
Epoch:  745 | train loss: 1.562356e-03 | valid loss: 1.556160e-03 
      	| train loss (relative): 3.067103e-02 | valid loss (relative): 3.058385e-02 
Epoch 745 use: 510.31 second.

epoch 746 starting......
Epoch:  746 | train loss: 1.560361e-03 | valid loss: 1.559518e-03 
      	| train loss (relative): 3.063128e-02 | valid loss (relative): 3.058370e-02 
Epoch 746 use: 439.86 second.

epoch 747 starting......
Epoch:  747 | train loss: 1.562098e-03 | valid loss: 1.564026e-03 
      	| train loss (relative): 3.066475e-02 | valid loss (relative): 3.077907e-02 
Epoch 747 use: 433.56 second.

epoch 748 starting......
Epoch:  748 | train loss: 1.564001e-03 | valid loss: 1.556055e-03 
      	| train loss (relative): 3.070169e-02 | valid loss (relative): 3.059083e-02 
Epoch 748 use: 422.05 second.

epoch 749 starting......
Epoch:  749 | train loss: 1.559743e-03 | valid loss: 1.556023e-03 
      	| train loss (relative): 3.062029e-02 | valid loss (relative): 3.042585e-02 
Epoch 749 use: 506.25 second.

epoch 750 starting......
Epoch:  750 | train loss: 1.565364e-03 | valid loss: 1.556989e-03 
      	| train loss (relative): 3.073194e-02 | valid loss (relative): 3.047748e-02 
Epoch 750 use: 434.96 second.

epoch 751 starting......
Epoch:  751 | train loss: 1.559837e-03 | valid loss: 1.551132e-03 
      	| train loss (relative): 3.061556e-02 | valid loss (relative): 3.043210e-02 
Epoch 751 use: 533.91 second.

epoch 752 starting......
Epoch:  752 | train loss: 1.556082e-03 | valid loss: 1.555296e-03 
      	| train loss (relative): 3.054508e-02 | valid loss (relative): 3.040641e-02 
Epoch 752 use: 505.67 second.

epoch 753 starting......
Epoch:  753 | train loss: 1.556272e-03 | valid loss: 1.548595e-03 
      	| train loss (relative): 3.054338e-02 | valid loss (relative): 3.036896e-02 
Epoch 753 use: 462.75 second.

epoch 754 starting......
Epoch:  754 | train loss: 1.557362e-03 | valid loss: 1.560383e-03 
      	| train loss (relative): 3.057089e-02 | valid loss (relative): 3.050646e-02 
Epoch 754 use: 434.27 second.

epoch 755 starting......
Epoch:  755 | train loss: 1.563640e-03 | valid loss: 1.558756e-03 
      	| train loss (relative): 3.069520e-02 | valid loss (relative): 3.052972e-02 
Epoch 755 use: 472.65 second.

epoch 756 starting......
Epoch:  756 | train loss: 1.561665e-03 | valid loss: 1.558617e-03 
      	| train loss (relative): 3.065851e-02 | valid loss (relative): 3.070818e-02 
Epoch 756 use: 495.41 second.

epoch 757 starting......
Epoch:  757 | train loss: 1.556568e-03 | valid loss: 1.552231e-03 
      	| train loss (relative): 3.055479e-02 | valid loss (relative): 3.036390e-02 
Epoch 757 use: 475.10 second.

epoch 758 starting......
Epoch:  758 | train loss: 1.555857e-03 | valid loss: 1.563391e-03 
      	| train loss (relative): 3.053691e-02 | valid loss (relative): 3.097771e-02 
Epoch 758 use: 470.16 second.

epoch 759 starting......
Epoch:  759 | train loss: 1.559465e-03 | valid loss: 1.547389e-03 
      	| train loss (relative): 3.061504e-02 | valid loss (relative): 3.040356e-02 
Epoch 759 use: 545.68 second.

epoch 760 starting......
Epoch:  760 | train loss: 1.551820e-03 | valid loss: 1.553614e-03 
      	| train loss (relative): 3.045935e-02 | valid loss (relative): 3.052605e-02 
Epoch 760 use: 469.18 second.

epoch 761 starting......
Epoch:  761 | train loss: 1.555956e-03 | valid loss: 1.551031e-03 
      	| train loss (relative): 3.054017e-02 | valid loss (relative): 3.052594e-02 
Epoch 761 use: 481.16 second.

epoch 762 starting......
Epoch:  762 | train loss: 1.553662e-03 | valid loss: 1.555878e-03 
      	| train loss (relative): 3.049658e-02 | valid loss (relative): 3.069370e-02 
Epoch 762 use: 425.94 second.

epoch 763 starting......
Epoch:  763 | train loss: 1.553420e-03 | valid loss: 1.547973e-03 
      	| train loss (relative): 3.049130e-02 | valid loss (relative): 3.035571e-02 
Epoch 763 use: 492.48 second.

epoch 764 starting......
Epoch:  764 | train loss: 1.550557e-03 | valid loss: 1.543828e-03 
      	| train loss (relative): 3.043241e-02 | valid loss (relative): 3.023008e-02 
Epoch 764 use: 444.33 second.

epoch 765 starting......
Epoch:  765 | train loss: 1.547220e-03 | valid loss: 1.545952e-03 
      	| train loss (relative): 3.036806e-02 | valid loss (relative): 3.042701e-02 
Epoch 765 use: 432.87 second.

epoch 766 starting......
Epoch:  766 | train loss: 1.549247e-03 | valid loss: 1.547213e-03 
      	| train loss (relative): 3.040519e-02 | valid loss (relative): 3.042969e-02 
Epoch 766 use: 441.89 second.

epoch 767 starting......
Epoch:  767 | train loss: 1.551809e-03 | valid loss: 1.548955e-03 
      	| train loss (relative): 3.046384e-02 | valid loss (relative): 3.011086e-02 
Epoch 767 use: 450.73 second.

epoch 768 starting......
Epoch:  768 | train loss: 1.550357e-03 | valid loss: 1.552173e-03 
      	| train loss (relative): 3.042496e-02 | valid loss (relative): 3.028279e-02 
Epoch 768 use: 521.92 second.

epoch 769 starting......
Epoch:  769 | train loss: 1.550147e-03 | valid loss: 1.544805e-03 
      	| train loss (relative): 3.042661e-02 | valid loss (relative): 3.033900e-02 
Epoch 769 use: 506.07 second.

epoch 770 starting......
Epoch:  770 | train loss: 1.545126e-03 | valid loss: 1.537960e-03 
      	| train loss (relative): 3.032701e-02 | valid loss (relative): 3.014669e-02 
Epoch 770 use: 514.24 second.

epoch 771 starting......
Epoch:  771 | train loss: 1.543312e-03 | valid loss: 1.538370e-03 
      	| train loss (relative): 3.028851e-02 | valid loss (relative): 3.015725e-02 
Epoch 771 use: 601.29 second.

epoch 772 starting......
Epoch:  772 | train loss: 1.543797e-03 | valid loss: 1.541020e-03 
      	| train loss (relative): 3.029672e-02 | valid loss (relative): 3.021440e-02 
Epoch 772 use: 526.52 second.

epoch 773 starting......
Epoch:  773 | train loss: 1.544562e-03 | valid loss: 1.546504e-03 
      	| train loss (relative): 3.031191e-02 | valid loss (relative): 3.025405e-02 
Epoch 773 use: 478.00 second.

epoch 774 starting......
Epoch:  774 | train loss: 1.545401e-03 | valid loss: 1.543850e-03 
      	| train loss (relative): 3.033020e-02 | valid loss (relative): 3.024613e-02 
Epoch 774 use: 511.55 second.

epoch 775 starting......
Epoch:  775 | train loss: 1.548518e-03 | valid loss: 1.544374e-03 
      	| train loss (relative): 3.039414e-02 | valid loss (relative): 3.019497e-02 
Epoch 775 use: 671.02 second.

epoch 776 starting......
Epoch:  776 | train loss: 1.545705e-03 | valid loss: 1.542476e-03 
      	| train loss (relative): 3.033606e-02 | valid loss (relative): 3.014399e-02 
Epoch 776 use: 636.82 second.

epoch 777 starting......
Epoch:  777 | train loss: 1.546470e-03 | valid loss: 1.548330e-03 
      	| train loss (relative): 3.034657e-02 | valid loss (relative): 3.006474e-02 
Epoch 777 use: 499.25 second.

epoch 778 starting......
Epoch:  778 | train loss: 1.546453e-03 | valid loss: 1.554036e-03 
      	| train loss (relative): 3.034319e-02 | valid loss (relative): 3.033861e-02 
Epoch 778 use: 491.67 second.

epoch 779 starting......
Epoch:  779 | train loss: 1.547318e-03 | valid loss: 1.542454e-03 
      	| train loss (relative): 3.036350e-02 | valid loss (relative): 3.013975e-02 
Epoch 779 use: 487.88 second.

epoch 780 starting......
Epoch:  780 | train loss: 1.541820e-03 | valid loss: 1.537602e-03 
      	| train loss (relative): 3.025552e-02 | valid loss (relative): 3.007352e-02 
Epoch 780 use: 482.55 second.

epoch 781 starting......
Epoch:  781 | train loss: 1.538643e-03 | valid loss: 1.535755e-03 
      	| train loss (relative): 3.019433e-02 | valid loss (relative): 3.015608e-02 
Epoch 781 use: 470.46 second.

epoch 782 starting......
Epoch:  782 | train loss: 1.539637e-03 | valid loss: 1.540488e-03 
      	| train loss (relative): 3.021225e-02 | valid loss (relative): 3.023948e-02 
Epoch 782 use: 499.99 second.

epoch 783 starting......
Epoch:  783 | train loss: 1.543600e-03 | valid loss: 1.536639e-03 
      	| train loss (relative): 3.029454e-02 | valid loss (relative): 3.008887e-02 
Epoch 783 use: 494.00 second.

epoch 784 starting......
Epoch:  784 | train loss: 1.542172e-03 | valid loss: 1.542301e-03 
      	| train loss (relative): 3.026515e-02 | valid loss (relative): 3.009819e-02 
Epoch 784 use: 481.12 second.

epoch 785 starting......
Epoch:  785 | train loss: 1.541622e-03 | valid loss: 1.543273e-03 
      	| train loss (relative): 3.025170e-02 | valid loss (relative): 3.038988e-02 
Epoch 785 use: 506.98 second.

epoch 786 starting......
Epoch:  786 | train loss: 1.544638e-03 | valid loss: 1.543403e-03 
      	| train loss (relative): 3.031195e-02 | valid loss (relative): 3.010303e-02 
Epoch 786 use: 506.26 second.

epoch 787 starting......
Epoch:  787 | train loss: 1.544298e-03 | valid loss: 1.551372e-03 
      	| train loss (relative): 3.030679e-02 | valid loss (relative): 3.041888e-02 
Epoch 787 use: 456.99 second.

epoch 788 starting......
Epoch:  788 | train loss: 1.541818e-03 | valid loss: 1.536717e-03 
      	| train loss (relative): 3.025910e-02 | valid loss (relative): 3.012553e-02 
Epoch 788 use: 453.59 second.

epoch 789 starting......
Epoch:  789 | train loss: 1.538167e-03 | valid loss: 1.543275e-03 
      	| train loss (relative): 3.018208e-02 | valid loss (relative): 3.034335e-02 
Epoch 789 use: 476.04 second.

epoch 790 starting......
Epoch:  790 | train loss: 1.539205e-03 | valid loss: 1.541723e-03 
      	| train loss (relative): 3.020281e-02 | valid loss (relative): 3.029554e-02 
Epoch 790 use: 499.79 second.

epoch 791 starting......
Epoch:  791 | train loss: 1.535794e-03 | valid loss: 1.540258e-03 
      	| train loss (relative): 3.013181e-02 | valid loss (relative): 3.045781e-02 
Epoch 791 use: 449.97 second.

epoch 792 starting......
Epoch:  792 | train loss: 1.537062e-03 | valid loss: 1.539281e-03 
      	| train loss (relative): 3.016259e-02 | valid loss (relative): 3.011487e-02 
Epoch 792 use: 508.23 second.

epoch 793 starting......
Epoch:  793 | train loss: 1.540434e-03 | valid loss: 1.540949e-03 
      	| train loss (relative): 3.022364e-02 | valid loss (relative): 3.021893e-02 
Epoch 793 use: 454.35 second.

epoch 794 starting......
Epoch:  794 | train loss: 1.539266e-03 | valid loss: 1.542130e-03 
      	| train loss (relative): 3.020868e-02 | valid loss (relative): 3.014603e-02 
Epoch 794 use: 462.08 second.

epoch 795 starting......
Epoch:  795 | train loss: 1.539025e-03 | valid loss: 1.547195e-03 
      	| train loss (relative): 3.019585e-02 | valid loss (relative): 3.065909e-02 
Epoch 795 use: 445.04 second.

epoch 796 starting......
Epoch:  796 | train loss: 1.539009e-03 | valid loss: 1.535655e-03 
      	| train loss (relative): 3.019916e-02 | valid loss (relative): 3.023211e-02 
Epoch 796 use: 433.93 second.

epoch 797 starting......
Epoch:  797 | train loss: 1.533605e-03 | valid loss: 1.533168e-03 
      	| train loss (relative): 3.009507e-02 | valid loss (relative): 2.999707e-02 
Epoch 797 use: 434.03 second.

epoch 798 starting......
Epoch:  798 | train loss: 1.530143e-03 | valid loss: 1.523638e-03 
      	| train loss (relative): 3.002366e-02 | valid loss (relative): 2.985025e-02 
Epoch 798 use: 428.30 second.

epoch 799 starting......
Epoch:  799 | train loss: 1.525143e-03 | valid loss: 1.526072e-03 
      	| train loss (relative): 2.992145e-02 | valid loss (relative): 2.999341e-02 
Epoch 799 use: 417.86 second.

epoch 800 starting......
Epoch:  800 | train loss: 1.526067e-03 | valid loss: 1.526262e-03 
      	| train loss (relative): 2.994499e-02 | valid loss (relative): 2.987212e-02 
Epoch 800 use: 422.35 second.

epoch 801 starting......
Epoch:  801 | train loss: 1.526390e-03 | valid loss: 1.525419e-03 
      	| train loss (relative): 2.994394e-02 | valid loss (relative): 2.993434e-02 
Epoch 801 use: 422.38 second.

epoch 802 starting......
Epoch:  802 | train loss: 1.528987e-03 | valid loss: 1.530524e-03 
      	| train loss (relative): 2.999686e-02 | valid loss (relative): 2.982427e-02 
Epoch 802 use: 444.87 second.

epoch 803 starting......
Epoch:  803 | train loss: 1.530106e-03 | valid loss: 1.533438e-03 
      	| train loss (relative): 3.001788e-02 | valid loss (relative): 3.016532e-02 
Epoch 803 use: 430.35 second.

epoch 804 starting......
Epoch:  804 | train loss: 1.531547e-03 | valid loss: 1.534967e-03 
      	| train loss (relative): 3.004716e-02 | valid loss (relative): 2.994203e-02 
Epoch 804 use: 420.03 second.

epoch 805 starting......
Epoch:  805 | train loss: 1.532503e-03 | valid loss: 1.530695e-03 
      	| train loss (relative): 3.006660e-02 | valid loss (relative): 2.995464e-02 
Epoch 805 use: 424.21 second.

epoch 806 starting......
Epoch:  806 | train loss: 1.530531e-03 | valid loss: 1.538034e-03 
      	| train loss (relative): 3.002812e-02 | valid loss (relative): 3.006011e-02 
Epoch 806 use: 427.65 second.

epoch 807 starting......
Epoch:  807 | train loss: 1.532279e-03 | valid loss: 1.527878e-03 
      	| train loss (relative): 3.005971e-02 | valid loss (relative): 2.984299e-02 
Epoch 807 use: 484.80 second.

epoch 808 starting......
Epoch:  808 | train loss: 1.530563e-03 | valid loss: 1.529341e-03 
      	| train loss (relative): 3.002835e-02 | valid loss (relative): 2.999689e-02 
Epoch 808 use: 443.29 second.

epoch 809 starting......
Epoch:  809 | train loss: 1.529394e-03 | valid loss: 1.533882e-03 
      	| train loss (relative): 3.000616e-02 | valid loss (relative): 3.007021e-02 
Epoch 809 use: 418.80 second.

epoch 810 starting......
Epoch:  810 | train loss: 1.532934e-03 | valid loss: 1.530333e-03 
      	| train loss (relative): 3.007402e-02 | valid loss (relative): 2.984993e-02 
Epoch 810 use: 432.14 second.

epoch 811 starting......
Epoch:  811 | train loss: 1.528998e-03 | valid loss: 1.536816e-03 
      	| train loss (relative): 2.999962e-02 | valid loss (relative): 3.031113e-02 
Epoch 811 use: 445.94 second.

epoch 812 starting......
Epoch:  812 | train loss: 1.530472e-03 | valid loss: 1.525710e-03 
      	| train loss (relative): 3.002942e-02 | valid loss (relative): 2.980375e-02 
Epoch 812 use: 472.62 second.

epoch 813 starting......
Epoch:  813 | train loss: 1.526527e-03 | valid loss: 1.526924e-03 
      	| train loss (relative): 2.994925e-02 | valid loss (relative): 2.995568e-02 
Epoch 813 use: 473.23 second.

epoch 814 starting......
Epoch:  814 | train loss: 1.527715e-03 | valid loss: 1.539497e-03 
      	| train loss (relative): 2.997071e-02 | valid loss (relative): 3.047643e-02 
Epoch 814 use: 452.40 second.

epoch 815 starting......
Epoch:  815 | train loss: 1.529627e-03 | valid loss: 1.532435e-03 
      	| train loss (relative): 3.001540e-02 | valid loss (relative): 3.003000e-02 
Epoch 815 use: 489.10 second.

epoch 816 starting......
Epoch:  816 | train loss: 1.528866e-03 | valid loss: 1.526790e-03 
      	| train loss (relative): 2.999405e-02 | valid loss (relative): 2.995749e-02 
Epoch 816 use: 466.92 second.

epoch 817 starting......
Epoch:  817 | train loss: 1.528563e-03 | valid loss: 1.536296e-03 
      	| train loss (relative): 2.998987e-02 | valid loss (relative): 3.008713e-02 
Epoch 817 use: 482.61 second.

epoch 818 starting......
Epoch:  818 | train loss: 1.529303e-03 | valid loss: 1.527809e-03 
      	| train loss (relative): 3.000244e-02 | valid loss (relative): 3.006118e-02 
Epoch 818 use: 465.87 second.

epoch 819 starting......
Epoch:  819 | train loss: 1.524370e-03 | valid loss: 1.520408e-03 
      	| train loss (relative): 2.990638e-02 | valid loss (relative): 2.973111e-02 
Epoch 819 use: 456.38 second.

epoch 820 starting......
Epoch:  820 | train loss: 1.522205e-03 | valid loss: 1.526850e-03 
      	| train loss (relative): 2.985829e-02 | valid loss (relative): 2.983183e-02 
Epoch 820 use: 450.14 second.

epoch 821 starting......
Epoch:  821 | train loss: 1.524243e-03 | valid loss: 1.524306e-03 
      	| train loss (relative): 2.989716e-02 | valid loss (relative): 2.988594e-02 
Epoch 821 use: 445.37 second.

epoch 822 starting......
Epoch:  822 | train loss: 1.524784e-03 | valid loss: 1.524292e-03 
      	| train loss (relative): 2.991300e-02 | valid loss (relative): 2.990786e-02 
Epoch 822 use: 455.58 second.

epoch 823 starting......
Epoch:  823 | train loss: 1.521719e-03 | valid loss: 1.521605e-03 
      	| train loss (relative): 2.984912e-02 | valid loss (relative): 2.973400e-02 
Epoch 823 use: 466.89 second.

epoch 824 starting......
Epoch:  824 | train loss: 1.521707e-03 | valid loss: 1.525696e-03 
      	| train loss (relative): 2.985083e-02 | valid loss (relative): 2.988663e-02 
Epoch 824 use: 493.91 second.

epoch 825 starting......
Epoch:  825 | train loss: 1.523740e-03 | valid loss: 1.526549e-03 
      	| train loss (relative): 2.989018e-02 | valid loss (relative): 3.010282e-02 
Epoch 825 use: 501.11 second.

epoch 826 starting......
Epoch:  826 | train loss: 1.520777e-03 | valid loss: 1.525162e-03 
      	| train loss (relative): 2.983456e-02 | valid loss (relative): 2.998307e-02 
Epoch 826 use: 488.26 second.

epoch 827 starting......
Epoch:  827 | train loss: 1.521048e-03 | valid loss: 1.524349e-03 
      	| train loss (relative): 2.983899e-02 | valid loss (relative): 3.008435e-02 
Epoch 827 use: 477.02 second.

epoch 828 starting......
Epoch:  828 | train loss: 1.521740e-03 | valid loss: 1.525731e-03 
      	| train loss (relative): 2.985115e-02 | valid loss (relative): 2.990100e-02 
Epoch 828 use: 473.68 second.

epoch 829 starting......
Epoch:  829 | train loss: 1.520309e-03 | valid loss: 1.526358e-03 
      	| train loss (relative): 2.981773e-02 | valid loss (relative): 2.975058e-02 
Epoch 829 use: 463.86 second.

epoch 830 starting......
Epoch:  830 | train loss: 1.518738e-03 | valid loss: 1.523460e-03 
      	| train loss (relative): 2.978857e-02 | valid loss (relative): 2.987948e-02 
Epoch 830 use: 483.56 second.

epoch 831 starting......
Epoch:  831 | train loss: 1.517195e-03 | valid loss: 1.520173e-03 
      	| train loss (relative): 2.976113e-02 | valid loss (relative): 2.987623e-02 
Epoch 831 use: 475.07 second.

epoch 832 starting......
Epoch:  832 | train loss: 1.521355e-03 | valid loss: 1.528006e-03 
      	| train loss (relative): 2.984369e-02 | valid loss (relative): 2.995979e-02 
Epoch 832 use: 454.84 second.

epoch 833 starting......
Epoch:  833 | train loss: 1.519635e-03 | valid loss: 1.529943e-03 
      	| train loss (relative): 2.981039e-02 | valid loss (relative): 3.009886e-02 
Epoch 833 use: 457.04 second.

epoch 834 starting......
Epoch:  834 | train loss: 1.518863e-03 | valid loss: 1.523261e-03 
      	| train loss (relative): 2.979320e-02 | valid loss (relative): 2.994885e-02 
Epoch 834 use: 461.87 second.

epoch 835 starting......
Epoch:  835 | train loss: 1.518380e-03 | valid loss: 1.527470e-03 
      	| train loss (relative): 2.978163e-02 | valid loss (relative): 3.002988e-02 
Epoch 835 use: 483.73 second.

epoch 836 starting......
Epoch:  836 | train loss: 1.518314e-03 | valid loss: 1.518065e-03 
      	| train loss (relative): 2.978300e-02 | valid loss (relative): 2.979316e-02 
Epoch 836 use: 466.50 second.

epoch 837 starting......
Epoch:  837 | train loss: 1.514343e-03 | valid loss: 1.516549e-03 
      	| train loss (relative): 2.970621e-02 | valid loss (relative): 2.980134e-02 
Epoch 837 use: 458.41 second.

epoch 838 starting......
Epoch:  838 | train loss: 1.515692e-03 | valid loss: 1.522484e-03 
      	| train loss (relative): 2.972936e-02 | valid loss (relative): 2.977889e-02 
Epoch 838 use: 464.22 second.

epoch 839 starting......
Epoch:  839 | train loss: 1.516975e-03 | valid loss: 1.517704e-03 
      	| train loss (relative): 2.975806e-02 | valid loss (relative): 2.973212e-02 
Epoch 839 use: 451.94 second.

epoch 840 starting......
Epoch:  840 | train loss: 1.517038e-03 | valid loss: 1.524649e-03 
      	| train loss (relative): 2.975289e-02 | valid loss (relative): 2.995990e-02 
Epoch 840 use: 458.15 second.

epoch 841 starting......
Epoch:  841 | train loss: 1.517497e-03 | valid loss: 1.519057e-03 
      	| train loss (relative): 2.976965e-02 | valid loss (relative): 2.983917e-02 
Epoch 841 use: 455.41 second.

epoch 842 starting......
Epoch:  842 | train loss: 1.516235e-03 | valid loss: 1.518527e-03 
      	| train loss (relative): 2.973808e-02 | valid loss (relative): 2.971832e-02 
Epoch 842 use: 443.00 second.

epoch 843 starting......
Epoch:  843 | train loss: 1.513214e-03 | valid loss: 1.516637e-03 
      	| train loss (relative): 2.968039e-02 | valid loss (relative): 2.971209e-02 
Epoch 843 use: 454.65 second.

epoch 844 starting......
Epoch:  844 | train loss: 1.511677e-03 | valid loss: 1.515720e-03 
      	| train loss (relative): 2.964601e-02 | valid loss (relative): 2.974015e-02 
Epoch 844 use: 454.23 second.

epoch 845 starting......
Epoch:  845 | train loss: 1.512149e-03 | valid loss: 1.510293e-03 
      	| train loss (relative): 2.965549e-02 | valid loss (relative): 2.957873e-02 
Epoch 845 use: 465.76 second.

epoch 846 starting......
Epoch:  846 | train loss: 1.507882e-03 | valid loss: 1.511170e-03 
      	| train loss (relative): 2.957102e-02 | valid loss (relative): 2.947327e-02 
Epoch 846 use: 504.75 second.

epoch 847 starting......
Epoch:  847 | train loss: 1.508642e-03 | valid loss: 1.513175e-03 
      	| train loss (relative): 2.958494e-02 | valid loss (relative): 2.952688e-02 
Epoch 847 use: 472.62 second.

epoch 848 starting......
Epoch:  848 | train loss: 1.508859e-03 | valid loss: 1.516415e-03 
      	| train loss (relative): 2.959078e-02 | valid loss (relative): 2.979957e-02 
Epoch 848 use: 445.66 second.

epoch 849 starting......
Epoch:  849 | train loss: 1.509376e-03 | valid loss: 1.519383e-03 
      	| train loss (relative): 2.960280e-02 | valid loss (relative): 2.971804e-02 
Epoch 849 use: 425.02 second.

test MSE Error: 1.485044e-03 | relative MSE Error: 2.901541e-02 
 Total time used for training: 19.40 hour.
MESLoss saved to  /rds/general/user/jy220/home/new_results/Variational_False_Changelr_False_MSELoss_Latent_256_nearest_neighbouring_True_SFC_nums_3_startlr_0.001_n_epoches_850.txt
relative MSELoss saved to  /rds/general/user/jy220/home/new_results/Variational_False_Changelr_False_reMSELoss_Latent_256_nearest_neighbouring_True_SFC_nums_3_startlr_0.001_n_epoches_850.txt
model saved to /rds/general/user/jy220/home/new_results/Variational_False_Changelr_False_Latent_256_Nearest_neighbouring_True_SFC_nums_3_startlr_0.001_n_epoches_850.pth
model_dict saved to /rds/general/user/jy220/home/new_results/Variational_False_Changelr_False_Latent_256_Nearest_neighbouring_True_SFC_nums_3_startlr_0.001_n_epoches_850_dict.pth
... Training slugflow data completed, Run finished Fri 20 Aug 09:43:43 BST 2021 ...
{'data_dir': '/rds/general/user/jy220/home/tensors/', 'data_type': 'tensors', 'mode': 'train', 'vtu_fields': 'Component1::ComponentMassFractionPhase1, phase1::Velocity', 'variational': 'False', 'optimizer': 'Adamax', 'structured': 'False', 'changing_lr': 'False', 'self_concat': '2', 'dimension': '3', 'sfc_nums': '3', 'components': '4', 'nearest_neighbouring': 'True', 'dims_latent': '256', 'activation': 'Tanh', 'tk_file': '/rds/general/user/jy220/home/slugflow_tk.pt', 'tb_file': '/rds/general/user/jy220/home/slugflow_tb.pt', 'sfc_file': '/rds/general/user/jy220/home/SFC-CAE-Ready-to-use/sfcs.pt', 'inv_sfc_file': '/rds/general/user/jy220/home/SFC-CAE-Ready-to-use/inv_sfcs.pt', 'coords_file': '/rds/general/user/jy220/home/SFC-CAE-Ready-to-use/coords.pt', 'cells_file': '/rds/general/user/jy220/home/SFC-CAE-Ready-to-use/cells.npy', 'state_load': '/rds/general/user/jy220/home/new_results/Variational_False_Changelr_False_Latent_256_Nearest_neighbouring_True_SFC_nums_3_startlr_0.001_n_epoches_850_dict.pth', 'batch_size': '16', 'lr': '0.001', 'n_epoches': '150', 'seed': '17', 'visualize': 'False', 'reconstructed_path': 'None', 'reconstruct_start_index': '0', 'reconstruct_end_index': '50', 'save_path': '/rds/general/user/jy220/home/new_results/'}
[[ 2.50825269e-01 -1.67256990e-02 -1.22268730e-03]
 [ 2.38611959e-01 -5.50627777e-03 -5.06451913e-03]
 [ 2.39454874e-01 -1.59563257e-02  3.96778323e-03]
 ...
 [ 9.11361096e+00 -2.21908381e-02  2.22384902e-03]
 [ 9.11847310e+00 -2.84346931e-02 -2.34839590e-04]
 [ 9.11039661e+00 -2.51498573e-02 -8.70661044e-03]]
{'tetra': array([[      0,       1,       2,       3],
       [      4,       5,       6,       7],
       [      8,       9,      10,      11],
       ...,
       [1342744, 1342745, 1342746, 1342747],
       [1342748, 1342749, 1342750, 1342751],
       [1342752, 1342753, 1342754, 1342755]])}
vtu fields:  ['Component1::ComponentMassFractionPhase1', 'phase1::Velocity'] 
 structured  False 
 activation  Tanh() 
 self concat  2 
 sfc_nums  3 

dims_latent  256 
 components  4 
 nearest_neighbouring  True 

visualize  False 
 sample number  1706 

reading sfc nums......
[array([  41684,   41685,   41674, ..., 1235560, 1235564, 1235558]), array([954289, 954290, 954291, ..., 420685, 420687, 420688]), array([  40156,   40155,   40158, ..., 1123478, 1123475, 1123467])]
reading inverse sfc nums......
[array([   8146,    8145,    8144, ..., 1274444, 1274445, 1273166]), array([547280, 547283, 593037, ..., 933933, 933932, 864488]), array([ 66437,  66439, 122512, ..., 459416, 415130, 459418])]
tk:  tensor([0.7581, 0.0418, 0.1840, 0.1464], dtype=torch.float64) 

tb:  tensor([-0.3816, -0.3618, -0.0308,  0.1446], dtype=torch.float64) 

length of train set: 1505 

length of valid set: 100 

length of test set: 101 

torch device num: 4 

Let's use 4 GPUs!
epoch 850 starting......
Epoch:  850 | train loss: 1.743449e-03 | valid loss: 1.504446e-03 
      	| train loss (relative): 3.417434e-02 | valid loss (relative): 2.946432e-02 
Epoch 850 use: 452.08 second.

epoch 851 starting......
Epoch:  851 | train loss: 1.507738e-03 | valid loss: 1.486589e-03 
      	| train loss (relative): 2.957357e-02 | valid loss (relative): 2.911414e-02 
Epoch 851 use: 444.07 second.

epoch 852 starting......
Epoch:  852 | train loss: 1.494533e-03 | valid loss: 1.483482e-03 
      	| train loss (relative): 2.930816e-02 | valid loss (relative): 2.902655e-02 
Epoch 852 use: 449.75 second.

epoch 853 starting......
Epoch:  853 | train loss: 1.491389e-03 | valid loss: 1.483620e-03 
      	| train loss (relative): 2.924257e-02 | valid loss (relative): 2.905106e-02 
Epoch 853 use: 426.00 second.

epoch 854 starting......
Epoch:  854 | train loss: 1.489628e-03 | valid loss: 1.484468e-03 
      	| train loss (relative): 2.920933e-02 | valid loss (relative): 2.906349e-02 
Epoch 854 use: 413.86 second.

epoch 855 starting......
Epoch:  855 | train loss: 1.487962e-03 | valid loss: 1.486521e-03 
      	| train loss (relative): 2.917655e-02 | valid loss (relative): 2.908402e-02 
Epoch 855 use: 431.45 second.

epoch 856 starting......
Epoch:  856 | train loss: 1.488829e-03 | valid loss: 1.488477e-03 
      	| train loss (relative): 2.919370e-02 | valid loss (relative): 2.909748e-02 
Epoch 856 use: 436.62 second.

epoch 857 starting......
Epoch:  857 | train loss: 1.489669e-03 | valid loss: 1.490522e-03 
      	| train loss (relative): 2.920314e-02 | valid loss (relative): 2.917662e-02 
Epoch 857 use: 443.46 second.

epoch 858 starting......
Epoch:  858 | train loss: 1.491202e-03 | valid loss: 1.495369e-03 
      	| train loss (relative): 2.923761e-02 | valid loss (relative): 2.930543e-02 
Epoch 858 use: 440.17 second.

epoch 859 starting......
Epoch:  859 | train loss: 1.494218e-03 | valid loss: 1.496054e-03 
      	| train loss (relative): 2.929792e-02 | valid loss (relative): 2.927260e-02 
Epoch 859 use: 434.50 second.

epoch 860 starting......
Epoch:  860 | train loss: 1.493735e-03 | valid loss: 1.496255e-03 
      	| train loss (relative): 2.928542e-02 | valid loss (relative): 2.923651e-02 
Epoch 860 use: 449.44 second.

epoch 861 starting......
Epoch:  861 | train loss: 1.493129e-03 | valid loss: 1.497383e-03 
      	| train loss (relative): 2.927897e-02 | valid loss (relative): 2.930914e-02 
Epoch 861 use: 438.30 second.

epoch 862 starting......
Epoch:  862 | train loss: 1.493331e-03 | valid loss: 1.497861e-03 
      	| train loss (relative): 2.927803e-02 | valid loss (relative): 2.929066e-02 
Epoch 862 use: 413.84 second.

epoch 863 starting......
Epoch:  863 | train loss: 1.495341e-03 | valid loss: 1.499308e-03 
      	| train loss (relative): 2.932051e-02 | valid loss (relative): 2.934147e-02 
Epoch 863 use: 432.78 second.

epoch 864 starting......
Epoch:  864 | train loss: 1.495002e-03 | valid loss: 1.502359e-03 
      	| train loss (relative): 2.931494e-02 | valid loss (relative): 2.943100e-02 
Epoch 864 use: 411.25 second.

epoch 865 starting......
Epoch:  865 | train loss: 1.493588e-03 | valid loss: 1.506473e-03 
      	| train loss (relative): 2.928399e-02 | valid loss (relative): 2.951573e-02 
Epoch 865 use: 380.80 second.

epoch 866 starting......
Epoch:  866 | train loss: 1.497514e-03 | valid loss: 1.508656e-03 
      	| train loss (relative): 2.936196e-02 | valid loss (relative): 2.954796e-02 
Epoch 866 use: 375.26 second.

epoch 867 starting......
Epoch:  867 | train loss: 1.497998e-03 | valid loss: 1.513889e-03 
      	| train loss (relative): 2.936899e-02 | valid loss (relative): 2.968482e-02 
Epoch 867 use: 381.77 second.

epoch 868 starting......
Epoch:  868 | train loss: 1.499488e-03 | valid loss: 1.504963e-03 
      	| train loss (relative): 2.940228e-02 | valid loss (relative): 2.952393e-02 
Epoch 868 use: 378.75 second.

epoch 869 starting......
Epoch:  869 | train loss: 1.492998e-03 | valid loss: 1.506627e-03 
      	| train loss (relative): 2.927112e-02 | valid loss (relative): 2.955302e-02 
Epoch 869 use: 369.75 second.

epoch 870 starting......
Epoch:  870 | train loss: 1.495301e-03 | valid loss: 1.505600e-03 
      	| train loss (relative): 2.931437e-02 | valid loss (relative): 2.944389e-02 
Epoch 870 use: 363.04 second.

epoch 871 starting......
Epoch:  871 | train loss: 1.494143e-03 | valid loss: 1.503773e-03 
      	| train loss (relative): 2.928988e-02 | valid loss (relative): 2.940700e-02 
Epoch 871 use: 381.13 second.

epoch 872 starting......
Epoch:  872 | train loss: 1.492082e-03 | valid loss: 1.509805e-03 
      	| train loss (relative): 2.925003e-02 | valid loss (relative): 2.955952e-02 
Epoch 872 use: 369.88 second.

epoch 873 starting......
Epoch:  873 | train loss: 1.496672e-03 | valid loss: 1.513800e-03 
      	| train loss (relative): 2.934029e-02 | valid loss (relative): 2.976999e-02 
Epoch 873 use: 371.78 second.

epoch 874 starting......
Epoch:  874 | train loss: 1.497096e-03 | valid loss: 1.513422e-03 
      	| train loss (relative): 2.935402e-02 | valid loss (relative): 2.976877e-02 
Epoch 874 use: 377.61 second.

epoch 875 starting......
Epoch:  875 | train loss: 1.496807e-03 | valid loss: 1.511627e-03 
      	| train loss (relative): 2.934756e-02 | valid loss (relative): 2.954836e-02 
Epoch 875 use: 367.19 second.

epoch 876 starting......
Epoch:  876 | train loss: 1.494634e-03 | valid loss: 1.516726e-03 
      	| train loss (relative): 2.930165e-02 | valid loss (relative): 2.976112e-02 
Epoch 876 use: 378.22 second.

epoch 877 starting......
Epoch:  877 | train loss: 1.498932e-03 | valid loss: 1.510840e-03 
      	| train loss (relative): 2.939043e-02 | valid loss (relative): 2.954062e-02 
Epoch 877 use: 395.02 second.

epoch 878 starting......
Epoch:  878 | train loss: 1.497670e-03 | valid loss: 1.514031e-03 
      	| train loss (relative): 2.936575e-02 | valid loss (relative): 2.956154e-02 
Epoch 878 use: 364.90 second.

epoch 879 starting......
Epoch:  879 | train loss: 1.497200e-03 | valid loss: 1.508869e-03 
      	| train loss (relative): 2.935242e-02 | valid loss (relative): 2.952327e-02 
Epoch 879 use: 387.82 second.

epoch 880 starting......
Epoch:  880 | train loss: 1.492937e-03 | valid loss: 1.509467e-03 
      	| train loss (relative): 2.927105e-02 | valid loss (relative): 2.954312e-02 
Epoch 880 use: 393.52 second.

epoch 881 starting......
Epoch:  881 | train loss: 1.495616e-03 | valid loss: 1.524530e-03 
      	| train loss (relative): 2.932114e-02 | valid loss (relative): 3.005233e-02 
Epoch 881 use: 401.73 second.

epoch 882 starting......
Epoch:  882 | train loss: 1.496584e-03 | valid loss: 1.513642e-03 
      	| train loss (relative): 2.934025e-02 | valid loss (relative): 2.970398e-02 
Epoch 882 use: 415.60 second.

epoch 883 starting......
Epoch:  883 | train loss: 1.495250e-03 | valid loss: 1.511549e-03 
      	| train loss (relative): 2.931695e-02 | valid loss (relative): 2.966294e-02 
Epoch 883 use: 388.69 second.

epoch 884 starting......
Epoch:  884 | train loss: 1.491538e-03 | valid loss: 1.516411e-03 
      	| train loss (relative): 2.924128e-02 | valid loss (relative): 2.951607e-02 
Epoch 884 use: 367.77 second.

epoch 885 starting......
Epoch:  885 | train loss: 1.493761e-03 | valid loss: 1.512255e-03 
      	| train loss (relative): 2.927902e-02 | valid loss (relative): 2.963734e-02 
Epoch 885 use: 458.70 second.

epoch 886 starting......
Epoch:  886 | train loss: 1.489733e-03 | valid loss: 1.504088e-03 
      	| train loss (relative): 2.920594e-02 | valid loss (relative): 2.933864e-02 
Epoch 886 use: 387.37 second.

epoch 887 starting......
Epoch:  887 | train loss: 1.487657e-03 | valid loss: 1.508603e-03 
      	| train loss (relative): 2.916063e-02 | valid loss (relative): 2.955210e-02 
Epoch 887 use: 394.31 second.

epoch 888 starting......
Epoch:  888 | train loss: 1.488953e-03 | valid loss: 1.512572e-03 
      	| train loss (relative): 2.918869e-02 | valid loss (relative): 2.972701e-02 
Epoch 888 use: 384.67 second.

epoch 889 starting......
Epoch:  889 | train loss: 1.490380e-03 | valid loss: 1.507043e-03 
      	| train loss (relative): 2.922295e-02 | valid loss (relative): 2.947567e-02 
Epoch 889 use: 368.69 second.

epoch 890 starting......
Epoch:  890 | train loss: 1.490805e-03 | valid loss: 1.523001e-03 
      	| train loss (relative): 2.922335e-02 | valid loss (relative): 2.961035e-02 
Epoch 890 use: 384.73 second.

epoch 891 starting......
Epoch:  891 | train loss: 1.491308e-03 | valid loss: 1.505514e-03 
      	| train loss (relative): 2.922938e-02 | valid loss (relative): 2.935647e-02 
Epoch 891 use: 373.24 second.

epoch 892 starting......
Epoch:  892 | train loss: 1.484256e-03 | valid loss: 1.506807e-03 
      	| train loss (relative): 2.908942e-02 | valid loss (relative): 2.941564e-02 
Epoch 892 use: 371.41 second.

epoch 893 starting......
Epoch:  893 | train loss: 1.486022e-03 | valid loss: 1.506848e-03 
      	| train loss (relative): 2.912783e-02 | valid loss (relative): 2.951092e-02 
Epoch 893 use: 377.04 second.

epoch 894 starting......
Epoch:  894 | train loss: 1.486099e-03 | valid loss: 1.506777e-03 
      	| train loss (relative): 2.912805e-02 | valid loss (relative): 2.956574e-02 
Epoch 894 use: 374.07 second.

epoch 895 starting......
Epoch:  895 | train loss: 1.487563e-03 | valid loss: 1.511776e-03 
      	| train loss (relative): 2.916095e-02 | valid loss (relative): 2.960862e-02 
Epoch 895 use: 369.22 second.

epoch 896 starting......
Epoch:  896 | train loss: 1.484809e-03 | valid loss: 1.499085e-03 
      	| train loss (relative): 2.910136e-02 | valid loss (relative): 2.942560e-02 
Epoch 896 use: 376.50 second.

epoch 897 starting......
Epoch:  897 | train loss: 1.480133e-03 | valid loss: 1.502703e-03 
      	| train loss (relative): 2.901097e-02 | valid loss (relative): 2.928084e-02 
Epoch 897 use: 368.82 second.

epoch 898 starting......
Epoch:  898 | train loss: 1.481028e-03 | valid loss: 1.509767e-03 
      	| train loss (relative): 2.902460e-02 | valid loss (relative): 2.963313e-02 
Epoch 898 use: 370.45 second.

epoch 899 starting......
Epoch:  899 | train loss: 1.488113e-03 | valid loss: 1.515851e-03 
      	| train loss (relative): 2.917328e-02 | valid loss (relative): 2.962758e-02 
Epoch 899 use: 368.99 second.

epoch 900 starting......
Epoch:  900 | train loss: 1.487416e-03 | valid loss: 1.513066e-03 
      	| train loss (relative): 2.915628e-02 | valid loss (relative): 2.951133e-02 
Epoch 900 use: 364.94 second.

epoch 901 starting......
Epoch:  901 | train loss: 1.487643e-03 | valid loss: 1.508878e-03 
      	| train loss (relative): 2.916074e-02 | valid loss (relative): 2.938610e-02 
Epoch 901 use: 365.93 second.

epoch 902 starting......
Epoch:  902 | train loss: 1.488087e-03 | valid loss: 1.515418e-03 
      	| train loss (relative): 2.916674e-02 | valid loss (relative): 2.967269e-02 
Epoch 902 use: 378.43 second.

epoch 903 starting......
Epoch:  903 | train loss: 1.486873e-03 | valid loss: 1.506715e-03 
      	| train loss (relative): 2.914297e-02 | valid loss (relative): 2.937207e-02 
Epoch 903 use: 357.38 second.

epoch 904 starting......
Epoch:  904 | train loss: 1.483216e-03 | valid loss: 1.506651e-03 
      	| train loss (relative): 2.907046e-02 | valid loss (relative): 2.940273e-02 
Epoch 904 use: 354.42 second.

epoch 905 starting......
Epoch:  905 | train loss: 1.481791e-03 | valid loss: 1.505732e-03 
      	| train loss (relative): 2.904262e-02 | valid loss (relative): 2.946299e-02 
Epoch 905 use: 363.96 second.

epoch 906 starting......
Epoch:  906 | train loss: 1.485083e-03 | valid loss: 1.508158e-03 
      	| train loss (relative): 2.911041e-02 | valid loss (relative): 2.934001e-02 
Epoch 906 use: 365.23 second.

epoch 907 starting......
Epoch:  907 | train loss: 1.481998e-03 | valid loss: 1.511342e-03 
      	| train loss (relative): 2.904577e-02 | valid loss (relative): 2.964565e-02 
Epoch 907 use: 365.54 second.

epoch 908 starting......
Epoch:  908 | train loss: 1.482070e-03 | valid loss: 1.509145e-03 
      	| train loss (relative): 2.905071e-02 | valid loss (relative): 2.942109e-02 
Epoch 908 use: 366.36 second.

epoch 909 starting......
Epoch:  909 | train loss: 1.484502e-03 | valid loss: 1.504014e-03 
      	| train loss (relative): 2.909503e-02 | valid loss (relative): 2.954894e-02 
Epoch 909 use: 371.93 second.

epoch 910 starting......
Epoch:  910 | train loss: 1.480068e-03 | valid loss: 1.505233e-03 
      	| train loss (relative): 2.900764e-02 | valid loss (relative): 2.958301e-02 
Epoch 910 use: 374.40 second.

epoch 911 starting......
Epoch:  911 | train loss: 1.481219e-03 | valid loss: 1.506239e-03 
      	| train loss (relative): 2.902707e-02 | valid loss (relative): 2.949494e-02 
Epoch 911 use: 379.72 second.

epoch 912 starting......
Epoch:  912 | train loss: 1.477917e-03 | valid loss: 1.508253e-03 
      	| train loss (relative): 2.896482e-02 | valid loss (relative): 2.965737e-02 
Epoch 912 use: 360.66 second.

epoch 913 starting......
Epoch:  913 | train loss: 1.480238e-03 | valid loss: 1.501760e-03 
      	| train loss (relative): 2.901462e-02 | valid loss (relative): 2.926425e-02 
Epoch 913 use: 379.49 second.

epoch 914 starting......
Epoch:  914 | train loss: 1.481927e-03 | valid loss: 1.506858e-03 
      	| train loss (relative): 2.904237e-02 | valid loss (relative): 2.947418e-02 
Epoch 914 use: 368.52 second.

epoch 915 starting......
Epoch:  915 | train loss: 1.478821e-03 | valid loss: 1.501865e-03 
      	| train loss (relative): 2.898325e-02 | valid loss (relative): 2.938076e-02 
Epoch 915 use: 438.16 second.

epoch 916 starting......
Epoch:  916 | train loss: 1.481011e-03 | valid loss: 1.505567e-03 
      	| train loss (relative): 2.902892e-02 | valid loss (relative): 2.950210e-02 
Epoch 916 use: 385.37 second.

epoch 917 starting......
Epoch:  917 | train loss: 1.480476e-03 | valid loss: 1.514781e-03 
      	| train loss (relative): 2.901640e-02 | valid loss (relative): 2.966272e-02 
Epoch 917 use: 378.26 second.

epoch 918 starting......
Epoch:  918 | train loss: 1.481555e-03 | valid loss: 1.502325e-03 
      	| train loss (relative): 2.903720e-02 | valid loss (relative): 2.944327e-02 
Epoch 918 use: 378.88 second.

epoch 919 starting......
Epoch:  919 | train loss: 1.478380e-03 | valid loss: 1.507051e-03 
      	| train loss (relative): 2.897373e-02 | valid loss (relative): 2.962577e-02 
Epoch 919 use: 374.87 second.

epoch 920 starting......
Epoch:  920 | train loss: 1.481617e-03 | valid loss: 1.505076e-03 
      	| train loss (relative): 2.903921e-02 | valid loss (relative): 2.937779e-02 
Epoch 920 use: 363.69 second.

epoch 921 starting......
Epoch:  921 | train loss: 1.479093e-03 | valid loss: 1.508174e-03 
      	| train loss (relative): 2.898962e-02 | valid loss (relative): 2.953226e-02 
Epoch 921 use: 366.74 second.

epoch 922 starting......
Epoch:  922 | train loss: 1.477852e-03 | valid loss: 1.502625e-03 
      	| train loss (relative): 2.896760e-02 | valid loss (relative): 2.938130e-02 
Epoch 922 use: 369.67 second.

epoch 923 starting......
Epoch:  923 | train loss: 1.477537e-03 | valid loss: 1.506013e-03 
      	| train loss (relative): 2.895297e-02 | valid loss (relative): 2.955359e-02 
Epoch 923 use: 377.81 second.

epoch 924 starting......
Epoch:  924 | train loss: 1.479021e-03 | valid loss: 1.502955e-03 
      	| train loss (relative): 2.898546e-02 | valid loss (relative): 2.941251e-02 
Epoch 924 use: 353.31 second.

epoch 925 starting......
Epoch:  925 | train loss: 1.474859e-03 | valid loss: 1.499334e-03 
      	| train loss (relative): 2.890457e-02 | valid loss (relative): 2.933502e-02 
Epoch 925 use: 390.82 second.

epoch 926 starting......
Epoch:  926 | train loss: 1.474557e-03 | valid loss: 1.506800e-03 
      	| train loss (relative): 2.890168e-02 | valid loss (relative): 2.952055e-02 
Epoch 926 use: 364.84 second.

epoch 927 starting......
Epoch:  927 | train loss: 1.477999e-03 | valid loss: 1.508423e-03 
      	| train loss (relative): 2.896611e-02 | valid loss (relative): 2.950438e-02 
Epoch 927 use: 377.92 second.

epoch 928 starting......
Epoch:  928 | train loss: 1.474236e-03 | valid loss: 1.500725e-03 
      	| train loss (relative): 2.888996e-02 | valid loss (relative): 2.948431e-02 
Epoch 928 use: 371.31 second.

epoch 929 starting......
Epoch:  929 | train loss: 1.472763e-03 | valid loss: 1.498511e-03 
      	| train loss (relative): 2.886439e-02 | valid loss (relative): 2.923723e-02 
Epoch 929 use: 359.96 second.

epoch 930 starting......
Epoch:  930 | train loss: 1.471497e-03 | valid loss: 1.500352e-03 
      	| train loss (relative): 2.883532e-02 | valid loss (relative): 2.928641e-02 
Epoch 930 use: 370.08 second.

epoch 931 starting......
Epoch:  931 | train loss: 1.470927e-03 | valid loss: 1.503488e-03 
      	| train loss (relative): 2.882425e-02 | valid loss (relative): 2.947963e-02 
Epoch 931 use: 377.46 second.

epoch 932 starting......
Epoch:  932 | train loss: 1.473456e-03 | valid loss: 1.504331e-03 
      	| train loss (relative): 2.887809e-02 | valid loss (relative): 2.924979e-02 
Epoch 932 use: 355.62 second.

epoch 933 starting......
Epoch:  933 | train loss: 1.470110e-03 | valid loss: 1.502788e-03 
      	| train loss (relative): 2.880633e-02 | valid loss (relative): 2.948927e-02 
Epoch 933 use: 380.31 second.

epoch 934 starting......
Epoch:  934 | train loss: 1.470738e-03 | valid loss: 1.497383e-03 
      	| train loss (relative): 2.882088e-02 | valid loss (relative): 2.932823e-02 
Epoch 934 use: 348.34 second.

epoch 935 starting......
Epoch:  935 | train loss: 1.469266e-03 | valid loss: 1.495486e-03 
      	| train loss (relative): 2.879401e-02 | valid loss (relative): 2.926856e-02 
Epoch 935 use: 373.48 second.

epoch 936 starting......
Epoch:  936 | train loss: 1.469025e-03 | valid loss: 1.503931e-03 
      	| train loss (relative): 2.878555e-02 | valid loss (relative): 2.941409e-02 
Epoch 936 use: 358.73 second.

epoch 937 starting......
Epoch:  937 | train loss: 1.473447e-03 | valid loss: 1.505837e-03 
      	| train loss (relative): 2.887804e-02 | valid loss (relative): 2.958357e-02 
Epoch 937 use: 369.94 second.

epoch 938 starting......
Epoch:  938 | train loss: 1.475862e-03 | valid loss: 1.505167e-03 
      	| train loss (relative): 2.891964e-02 | valid loss (relative): 2.954327e-02 
Epoch 938 use: 378.49 second.

epoch 939 starting......
Epoch:  939 | train loss: 1.474203e-03 | valid loss: 1.500987e-03 
      	| train loss (relative): 2.889133e-02 | valid loss (relative): 2.939723e-02 
Epoch 939 use: 370.47 second.

epoch 940 starting......
Epoch:  940 | train loss: 1.469046e-03 | valid loss: 1.497514e-03 
      	| train loss (relative): 2.878527e-02 | valid loss (relative): 2.922150e-02 
Epoch 940 use: 364.77 second.

epoch 941 starting......
Epoch:  941 | train loss: 1.466960e-03 | valid loss: 1.496904e-03 
      	| train loss (relative): 2.875188e-02 | valid loss (relative): 2.930887e-02 
Epoch 941 use: 371.77 second.

epoch 942 starting......
Epoch:  942 | train loss: 1.467563e-03 | valid loss: 1.495512e-03 
      	| train loss (relative): 2.876016e-02 | valid loss (relative): 2.930394e-02 
Epoch 942 use: 359.57 second.

epoch 943 starting......
Epoch:  943 | train loss: 1.467563e-03 | valid loss: 1.500390e-03 
      	| train loss (relative): 2.875610e-02 | valid loss (relative): 2.928060e-02 
Epoch 943 use: 360.16 second.

epoch 944 starting......
Epoch:  944 | train loss: 1.471722e-03 | valid loss: 1.492242e-03 
      	| train loss (relative): 2.883904e-02 | valid loss (relative): 2.907372e-02 
Epoch 944 use: 383.83 second.

epoch 945 starting......
Epoch:  945 | train loss: 1.467186e-03 | valid loss: 1.499637e-03 
      	| train loss (relative): 2.874861e-02 | valid loss (relative): 2.942537e-02 
Epoch 945 use: 352.99 second.

epoch 946 starting......
Epoch:  946 | train loss: 1.467925e-03 | valid loss: 1.493947e-03 
      	| train loss (relative): 2.876691e-02 | valid loss (relative): 2.921179e-02 
Epoch 946 use: 373.75 second.

epoch 947 starting......
Epoch:  947 | train loss: 1.464788e-03 | valid loss: 1.493231e-03 
      	| train loss (relative): 2.870153e-02 | valid loss (relative): 2.932302e-02 
Epoch 947 use: 371.93 second.

epoch 948 starting......
Epoch:  948 | train loss: 1.466618e-03 | valid loss: 1.501648e-03 
      	| train loss (relative): 2.873877e-02 | valid loss (relative): 2.941374e-02 
Epoch 948 use: 375.90 second.

epoch 949 starting......
Epoch:  949 | train loss: 1.465103e-03 | valid loss: 1.493195e-03 
      	| train loss (relative): 2.870489e-02 | valid loss (relative): 2.923775e-02 
Epoch 949 use: 380.21 second.

epoch 950 starting......
Epoch:  950 | train loss: 1.462663e-03 | valid loss: 1.494254e-03 
      	| train loss (relative): 2.866105e-02 | valid loss (relative): 2.931979e-02 
Epoch 950 use: 364.51 second.

epoch 951 starting......
Epoch:  951 | train loss: 1.462335e-03 | valid loss: 1.496578e-03 
      	| train loss (relative): 2.865027e-02 | valid loss (relative): 2.929841e-02 
Epoch 951 use: 385.37 second.

epoch 952 starting......
Epoch:  952 | train loss: 1.465196e-03 | valid loss: 1.493470e-03 
      	| train loss (relative): 2.870843e-02 | valid loss (relative): 2.919350e-02 
Epoch 952 use: 365.99 second.

epoch 953 starting......
Epoch:  953 | train loss: 1.462065e-03 | valid loss: 1.493009e-03 
      	| train loss (relative): 2.864721e-02 | valid loss (relative): 2.936560e-02 
Epoch 953 use: 361.58 second.

epoch 954 starting......
Epoch:  954 | train loss: 1.462528e-03 | valid loss: 1.495729e-03 
      	| train loss (relative): 2.865897e-02 | valid loss (relative): 2.920069e-02 
Epoch 954 use: 394.42 second.

epoch 955 starting......
Epoch:  955 | train loss: 1.462211e-03 | valid loss: 1.497322e-03 
      	| train loss (relative): 2.865246e-02 | valid loss (relative): 2.934278e-02 
Epoch 955 use: 434.01 second.

epoch 956 starting......
Epoch:  956 | train loss: 1.461799e-03 | valid loss: 1.488111e-03 
      	| train loss (relative): 2.863958e-02 | valid loss (relative): 2.907961e-02 
Epoch 956 use: 394.67 second.

epoch 957 starting......
Epoch:  957 | train loss: 1.456190e-03 | valid loss: 1.486208e-03 
      	| train loss (relative): 2.852761e-02 | valid loss (relative): 2.899878e-02 
Epoch 957 use: 364.37 second.

epoch 958 starting......
Epoch:  958 | train loss: 1.459335e-03 | valid loss: 1.489182e-03 
      	| train loss (relative): 2.858876e-02 | valid loss (relative): 2.918080e-02 
Epoch 958 use: 385.14 second.

epoch 959 starting......
Epoch:  959 | train loss: 1.457504e-03 | valid loss: 1.491783e-03 
      	| train loss (relative): 2.855610e-02 | valid loss (relative): 2.905222e-02 
Epoch 959 use: 369.74 second.

epoch 960 starting......
Epoch:  960 | train loss: 1.459253e-03 | valid loss: 1.490248e-03 
      	| train loss (relative): 2.858957e-02 | valid loss (relative): 2.925655e-02 
Epoch 960 use: 366.94 second.

epoch 961 starting......
Epoch:  961 | train loss: 1.459814e-03 | valid loss: 1.494592e-03 
      	| train loss (relative): 2.860370e-02 | valid loss (relative): 2.908561e-02 
Epoch 961 use: 448.97 second.

epoch 962 starting......
Epoch:  962 | train loss: 1.459730e-03 | valid loss: 1.490943e-03 
      	| train loss (relative): 2.859990e-02 | valid loss (relative): 2.914463e-02 
Epoch 962 use: 404.30 second.

epoch 963 starting......
Epoch:  963 | train loss: 1.459505e-03 | valid loss: 1.492039e-03 
      	| train loss (relative): 2.859234e-02 | valid loss (relative): 2.915591e-02 
Epoch 963 use: 420.11 second.

epoch 964 starting......
Epoch:  964 | train loss: 1.459224e-03 | valid loss: 1.496795e-03 
      	| train loss (relative): 2.858935e-02 | valid loss (relative): 2.911278e-02 
Epoch 964 use: 365.35 second.

epoch 965 starting......
Epoch:  965 | train loss: 1.462662e-03 | valid loss: 1.501315e-03 
      	| train loss (relative): 2.865627e-02 | valid loss (relative): 2.947953e-02 
Epoch 965 use: 389.83 second.

epoch 966 starting......
Epoch:  966 | train loss: 1.463289e-03 | valid loss: 1.496123e-03 
      	| train loss (relative): 2.867165e-02 | valid loss (relative): 2.932777e-02 
Epoch 966 use: 367.05 second.

epoch 967 starting......
Epoch:  967 | train loss: 1.462578e-03 | valid loss: 1.491110e-03 
      	| train loss (relative): 2.865281e-02 | valid loss (relative): 2.906542e-02 
Epoch 967 use: 360.40 second.

epoch 968 starting......
Epoch:  968 | train loss: 1.456264e-03 | valid loss: 1.491012e-03 
      	| train loss (relative): 2.852785e-02 | valid loss (relative): 2.930488e-02 
Epoch 968 use: 363.72 second.

epoch 969 starting......
Epoch:  969 | train loss: 1.454105e-03 | valid loss: 1.488404e-03 
      	| train loss (relative): 2.848752e-02 | valid loss (relative): 2.915498e-02 
Epoch 969 use: 364.84 second.

epoch 970 starting......
Epoch:  970 | train loss: 1.453274e-03 | valid loss: 1.483100e-03 
      	| train loss (relative): 2.847466e-02 | valid loss (relative): 2.878895e-02 
Epoch 970 use: 353.24 second.

epoch 971 starting......
Epoch:  971 | train loss: 1.451595e-03 | valid loss: 1.486040e-03 
      	| train loss (relative): 2.843453e-02 | valid loss (relative): 2.889849e-02 
Epoch 971 use: 365.62 second.

epoch 972 starting......
Epoch:  972 | train loss: 1.452847e-03 | valid loss: 1.486507e-03 
      	| train loss (relative): 2.845593e-02 | valid loss (relative): 2.907522e-02 
Epoch 972 use: 354.25 second.

epoch 973 starting......
Epoch:  973 | train loss: 1.454822e-03 | valid loss: 1.488154e-03 
      	| train loss (relative): 2.850020e-02 | valid loss (relative): 2.908231e-02 
Epoch 973 use: 356.20 second.

epoch 974 starting......
Epoch:  974 | train loss: 1.455597e-03 | valid loss: 1.486275e-03 
      	| train loss (relative): 2.851736e-02 | valid loss (relative): 2.904311e-02 
Epoch 974 use: 392.53 second.

epoch 975 starting......
Epoch:  975 | train loss: 1.455844e-03 | valid loss: 1.499417e-03 
      	| train loss (relative): 2.852033e-02 | valid loss (relative): 2.931859e-02 
Epoch 975 use: 346.43 second.

epoch 976 starting......
Epoch:  976 | train loss: 1.458361e-03 | valid loss: 1.485689e-03 
      	| train loss (relative): 2.856987e-02 | valid loss (relative): 2.913196e-02 
Epoch 976 use: 371.35 second.

epoch 977 starting......
Epoch:  977 | train loss: 1.453172e-03 | valid loss: 1.482622e-03 
      	| train loss (relative): 2.846800e-02 | valid loss (relative): 2.901359e-02 
Epoch 977 use: 357.62 second.

epoch 978 starting......
Epoch:  978 | train loss: 1.451836e-03 | valid loss: 1.486028e-03 
      	| train loss (relative): 2.844043e-02 | valid loss (relative): 2.910162e-02 
Epoch 978 use: 372.84 second.

epoch 979 starting......
Epoch:  979 | train loss: 1.452292e-03 | valid loss: 1.486299e-03 
      	| train loss (relative): 2.844995e-02 | valid loss (relative): 2.902585e-02 
Epoch 979 use: 371.24 second.

epoch 980 starting......
Epoch:  980 | train loss: 1.451978e-03 | valid loss: 1.486647e-03 
      	| train loss (relative): 2.844484e-02 | valid loss (relative): 2.902588e-02 
Epoch 980 use: 366.98 second.

epoch 981 starting......
Epoch:  981 | train loss: 1.452083e-03 | valid loss: 1.482999e-03 
      	| train loss (relative): 2.844537e-02 | valid loss (relative): 2.905745e-02 
Epoch 981 use: 374.83 second.

epoch 982 starting......
Epoch:  982 | train loss: 1.448627e-03 | valid loss: 1.480229e-03 
      	| train loss (relative): 2.837753e-02 | valid loss (relative): 2.897506e-02 
Epoch 982 use: 351.50 second.

epoch 983 starting......
Epoch:  983 | train loss: 1.448869e-03 | valid loss: 1.489717e-03 
      	| train loss (relative): 2.838234e-02 | valid loss (relative): 2.930157e-02 
Epoch 983 use: 354.24 second.

epoch 984 starting......
Epoch:  984 | train loss: 1.456881e-03 | valid loss: 1.487353e-03 
      	| train loss (relative): 2.854304e-02 | valid loss (relative): 2.915780e-02 
Epoch 984 use: 386.75 second.

epoch 985 starting......
Epoch:  985 | train loss: 1.451071e-03 | valid loss: 1.485992e-03 
      	| train loss (relative): 2.842681e-02 | valid loss (relative): 2.902882e-02 
Epoch 985 use: 358.37 second.

epoch 986 starting......
Epoch:  986 | train loss: 1.451396e-03 | valid loss: 1.488787e-03 
      	| train loss (relative): 2.842976e-02 | valid loss (relative): 2.910010e-02 
Epoch 986 use: 351.79 second.

epoch 987 starting......
Epoch:  987 | train loss: 1.450255e-03 | valid loss: 1.491271e-03 
      	| train loss (relative): 2.840632e-02 | valid loss (relative): 2.913141e-02 
Epoch 987 use: 376.37 second.

epoch 988 starting......
Epoch:  988 | train loss: 1.454066e-03 | valid loss: 1.492992e-03 
      	| train loss (relative): 2.848495e-02 | valid loss (relative): 2.893395e-02 
Epoch 988 use: 359.45 second.

epoch 989 starting......
Epoch:  989 | train loss: 1.450847e-03 | valid loss: 1.485690e-03 
      	| train loss (relative): 2.841770e-02 | valid loss (relative): 2.918151e-02 
Epoch 989 use: 358.39 second.

epoch 990 starting......
Epoch:  990 | train loss: 1.449882e-03 | valid loss: 1.486388e-03 
      	| train loss (relative): 2.840100e-02 | valid loss (relative): 2.901552e-02 
Epoch 990 use: 371.06 second.

epoch 991 starting......
Epoch:  991 | train loss: 1.450558e-03 | valid loss: 1.488411e-03 
      	| train loss (relative): 2.841153e-02 | valid loss (relative): 2.902295e-02 
Epoch 991 use: 359.56 second.

epoch 992 starting......
Epoch:  992 | train loss: 1.451792e-03 | valid loss: 1.486564e-03 
      	| train loss (relative): 2.843733e-02 | valid loss (relative): 2.907464e-02 
Epoch 992 use: 381.63 second.

epoch 993 starting......
Epoch:  993 | train loss: 1.449576e-03 | valid loss: 1.488030e-03 
      	| train loss (relative): 2.839703e-02 | valid loss (relative): 2.921323e-02 
Epoch 993 use: 363.97 second.

epoch 994 starting......
Epoch:  994 | train loss: 1.448689e-03 | valid loss: 1.486747e-03 
      	| train loss (relative): 2.838118e-02 | valid loss (relative): 2.890773e-02 
Epoch 994 use: 369.15 second.

epoch 995 starting......
Epoch:  995 | train loss: 1.448327e-03 | valid loss: 1.484092e-03 
      	| train loss (relative): 2.837034e-02 | valid loss (relative): 2.896387e-02 
Epoch 995 use: 356.98 second.

epoch 996 starting......
Epoch:  996 | train loss: 1.447216e-03 | valid loss: 1.477100e-03 
      	| train loss (relative): 2.834807e-02 | valid loss (relative): 2.887411e-02 
Epoch 996 use: 360.73 second.

epoch 997 starting......
Epoch:  997 | train loss: 1.443806e-03 | valid loss: 1.478575e-03 
      	| train loss (relative): 2.828324e-02 | valid loss (relative): 2.883507e-02 
Epoch 997 use: 360.94 second.

epoch 998 starting......
Epoch:  998 | train loss: 1.446641e-03 | valid loss: 1.482758e-03 
      	| train loss (relative): 2.833616e-02 | valid loss (relative): 2.887267e-02 
Epoch 998 use: 368.46 second.

epoch 999 starting......
Epoch:  999 | train loss: 1.448689e-03 | valid loss: 1.479951e-03 
      	| train loss (relative): 2.837543e-02 | valid loss (relative): 2.884850e-02 
Epoch 999 use: 362.03 second.

test MSE Error: 1.547887e-03 | relative MSE Error: 3.029523e-02 
 Total time used for training: 15.84 hour.
MESLoss saved to  /rds/general/user/jy220/home/new_results/Variational_False_Changelr_False_MSELoss_Latent_256_nearest_neighbouring_True_SFC_nums_3_startlr_0.001_n_epoches_1000.txt
relative MSELoss saved to  /rds/general/user/jy220/home/new_results/Variational_False_Changelr_False_reMSELoss_Latent_256_nearest_neighbouring_True_SFC_nums_3_startlr_0.001_n_epoches_1000.txt
model saved to /rds/general/user/jy220/home/new_results/Variational_False_Changelr_False_Latent_256_Nearest_neighbouring_True_SFC_nums_3_startlr_0.001_n_epoches_1000.pth
model_dict saved to /rds/general/user/jy220/home/new_results/Variational_False_Changelr_False_Latent_256_Nearest_neighbouring_True_SFC_nums_3_startlr_0.001_n_epoches_1000_dict.pth
... Training slugflow data completed, Run finished Sat 21 Aug 08:39:05 BST 2021 ...
{'data_dir': '/rds/general/user/jy220/home/tensors/', 'data_type': 'tensors', 'mode': 'train', 'vtu_fields': 'Component1::ComponentMassFractionPhase1, phase1::Velocity', 'variational': 'False', 'optimizer': 'Adamax', 'structured': 'False', 'changing_lr': 'False', 'self_concat': '2', 'dimension': '3', 'sfc_nums': '3', 'components': '4', 'nearest_neighbouring': 'True', 'dims_latent': '256', 'activation': 'Tanh', 'tk_file': '/rds/general/user/jy220/home/slugflow_tk.pt', 'tb_file': '/rds/general/user/jy220/home/slugflow_tb.pt', 'sfc_file': '/rds/general/user/jy220/home/SFC-CAE-Ready-to-use/sfcs.pt', 'inv_sfc_file': '/rds/general/user/jy220/home/SFC-CAE-Ready-to-use/inv_sfcs.pt', 'coords_file': '/rds/general/user/jy220/home/SFC-CAE-Ready-to-use/coords.pt', 'cells_file': '/rds/general/user/jy220/home/SFC-CAE-Ready-to-use/cells.npy', 'state_load': '/rds/general/user/jy220/home/new_results/Variational_False_Changelr_False_Latent_256_Nearest_neighbouring_True_SFC_nums_3_startlr_0.001_n_epoches_1000_dict.pth', 'batch_size': '16', 'lr': '0.001', 'n_epoches': '150', 'seed': '17', 'visualize': 'False', 'reconstructed_path': 'None', 'reconstruct_start_index': '0', 'reconstruct_end_index': '50', 'save_path': '/rds/general/user/jy220/home/new_results/'}
[[ 2.50825269e-01 -1.67256990e-02 -1.22268730e-03]
 [ 2.38611959e-01 -5.50627777e-03 -5.06451913e-03]
 [ 2.39454874e-01 -1.59563257e-02  3.96778323e-03]
 ...
 [ 9.11361096e+00 -2.21908381e-02  2.22384902e-03]
 [ 9.11847310e+00 -2.84346931e-02 -2.34839590e-04]
 [ 9.11039661e+00 -2.51498573e-02 -8.70661044e-03]]
{'tetra': array([[      0,       1,       2,       3],
       [      4,       5,       6,       7],
       [      8,       9,      10,      11],
       ...,
       [1342744, 1342745, 1342746, 1342747],
       [1342748, 1342749, 1342750, 1342751],
       [1342752, 1342753, 1342754, 1342755]])}
vtu fields:  ['Component1::ComponentMassFractionPhase1', 'phase1::Velocity'] 
 structured  False 
 activation  Tanh() 
 self concat  2 
 sfc_nums  3 

dims_latent  256 
 components  4 
 nearest_neighbouring  True 

visualize  False 
 sample number  1706 

reading sfc nums......
[array([  41684,   41685,   41674, ..., 1235560, 1235564, 1235558]), array([954289, 954290, 954291, ..., 420685, 420687, 420688]), array([  40156,   40155,   40158, ..., 1123478, 1123475, 1123467])]
reading inverse sfc nums......
[array([   8146,    8145,    8144, ..., 1274444, 1274445, 1273166]), array([547280, 547283, 593037, ..., 933933, 933932, 864488]), array([ 66437,  66439, 122512, ..., 459416, 415130, 459418])]
tk:  tensor([0.7581, 0.0418, 0.1840, 0.1464], dtype=torch.float64) 

tb:  tensor([-0.3816, -0.3618, -0.0308,  0.1446], dtype=torch.float64) 

length of train set: 1505 

length of valid set: 100 

length of test set: 101 

torch device num: 4 

Let's use 4 GPUs!
epoch 1000 starting......
Epoch:  1000 | train loss: 1.654070e-03 | valid loss: 1.504398e-03 
      	| train loss (relative): 3.239401e-02 | valid loss (relative): 2.956234e-02 
Epoch 1000 use: 517.43 second.

epoch 1001 starting......
Epoch:  1001 | train loss: 1.446873e-03 | valid loss: 1.492444e-03 
      	| train loss (relative): 2.834315e-02 | valid loss (relative): 2.929637e-02 
Epoch 1001 use: 439.66 second.

epoch 1002 starting......
Epoch:  1002 | train loss: 1.438311e-03 | valid loss: 1.491421e-03 
      	| train loss (relative): 2.817467e-02 | valid loss (relative): 2.929224e-02 
Epoch 1002 use: 420.35 second.

epoch 1003 starting......
Epoch:  1003 | train loss: 1.436084e-03 | valid loss: 1.489817e-03 
      	| train loss (relative): 2.812987e-02 | valid loss (relative): 2.925213e-02 
Epoch 1003 use: 421.40 second.

epoch 1004 starting......
Epoch:  1004 | train loss: 1.435428e-03 | valid loss: 1.490735e-03 
      	| train loss (relative): 2.811115e-02 | valid loss (relative): 2.927550e-02 
Epoch 1004 use: 381.03 second.

epoch 1005 starting......
Epoch:  1005 | train loss: 1.435325e-03 | valid loss: 1.493617e-03 
      	| train loss (relative): 2.811093e-02 | valid loss (relative): 2.932625e-02 
Epoch 1005 use: 420.15 second.

epoch 1006 starting......
Epoch:  1006 | train loss: 1.436915e-03 | valid loss: 1.498068e-03 
      	| train loss (relative): 2.814076e-02 | valid loss (relative): 2.947900e-02 
Epoch 1006 use: 420.71 second.

epoch 1007 starting......
Epoch:  1007 | train loss: 1.441159e-03 | valid loss: 1.502113e-03 
      	| train loss (relative): 2.822482e-02 | valid loss (relative): 2.948959e-02 
Epoch 1007 use: 413.12 second.

epoch 1008 starting......
Epoch:  1008 | train loss: 1.440464e-03 | valid loss: 1.498975e-03 
      	| train loss (relative): 2.820756e-02 | valid loss (relative): 2.943291e-02 
Epoch 1008 use: 412.81 second.

epoch 1009 starting......
Epoch:  1009 | train loss: 1.441399e-03 | valid loss: 1.501175e-03 
      	| train loss (relative): 2.822866e-02 | valid loss (relative): 2.949010e-02 
Epoch 1009 use: 406.81 second.

epoch 1010 starting......
Epoch:  1010 | train loss: 1.441562e-03 | valid loss: 1.503867e-03 
      	| train loss (relative): 2.823106e-02 | valid loss (relative): 2.952412e-02 
Epoch 1010 use: 400.46 second.

epoch 1011 starting......
Epoch:  1011 | train loss: 1.441601e-03 | valid loss: 1.504881e-03 
      	| train loss (relative): 2.823348e-02 | valid loss (relative): 2.955594e-02 
Epoch 1011 use: 385.14 second.

epoch 1012 starting......
Epoch:  1012 | train loss: 1.442888e-03 | valid loss: 1.508747e-03 
      	| train loss (relative): 2.825816e-02 | valid loss (relative): 2.964732e-02 
Epoch 1012 use: 391.12 second.

epoch 1013 starting......
Epoch:  1013 | train loss: 1.444764e-03 | valid loss: 1.510088e-03 
      	| train loss (relative): 2.829238e-02 | valid loss (relative): 2.973608e-02 
Epoch 1013 use: 405.95 second.

epoch 1014 starting......
Epoch:  1014 | train loss: 1.448060e-03 | valid loss: 1.513032e-03 
      	| train loss (relative): 2.836039e-02 | valid loss (relative): 2.973555e-02 
Epoch 1014 use: 401.88 second.

epoch 1015 starting......
Epoch:  1015 | train loss: 1.443435e-03 | valid loss: 1.508020e-03 
      	| train loss (relative): 2.827184e-02 | valid loss (relative): 2.965438e-02 
Epoch 1015 use: 407.31 second.

epoch 1016 starting......
Epoch:  1016 | train loss: 1.444065e-03 | valid loss: 1.511543e-03 
      	| train loss (relative): 2.828075e-02 | valid loss (relative): 2.975807e-02 
Epoch 1016 use: 420.34 second.

epoch 1017 starting......
Epoch:  1017 | train loss: 1.443444e-03 | valid loss: 1.508618e-03 
      	| train loss (relative): 2.827198e-02 | valid loss (relative): 2.957196e-02 
Epoch 1017 use: 409.34 second.

epoch 1018 starting......
Epoch:  1018 | train loss: 1.442825e-03 | valid loss: 1.515424e-03 
      	| train loss (relative): 2.825402e-02 | valid loss (relative): 2.978561e-02 
Epoch 1018 use: 408.89 second.

epoch 1019 starting......
Epoch:  1019 | train loss: 1.446839e-03 | valid loss: 1.512858e-03 
      	| train loss (relative): 2.833448e-02 | valid loss (relative): 2.964476e-02 
Epoch 1019 use: 386.50 second.

epoch 1020 starting......
Epoch:  1020 | train loss: 1.443696e-03 | valid loss: 1.513440e-03 
      	| train loss (relative): 2.827353e-02 | valid loss (relative): 2.963710e-02 
Epoch 1020 use: 395.68 second.

epoch 1021 starting......
Epoch:  1021 | train loss: 1.444923e-03 | valid loss: 1.514769e-03 
      	| train loss (relative): 2.829741e-02 | valid loss (relative): 2.979716e-02 
Epoch 1021 use: 387.15 second.

epoch 1022 starting......
Epoch:  1022 | train loss: 1.442132e-03 | valid loss: 1.508952e-03 
      	| train loss (relative): 2.823896e-02 | valid loss (relative): 2.966310e-02 
Epoch 1022 use: 412.76 second.

epoch 1023 starting......
Epoch:  1023 | train loss: 1.444271e-03 | valid loss: 1.509710e-03 
      	| train loss (relative): 2.828174e-02 | valid loss (relative): 2.967926e-02 
Epoch 1023 use: 405.40 second.

epoch 1024 starting......
Epoch:  1024 | train loss: 1.442214e-03 | valid loss: 1.511896e-03 
      	| train loss (relative): 2.824355e-02 | valid loss (relative): 2.970178e-02 
Epoch 1024 use: 381.98 second.

epoch 1025 starting......
Epoch:  1025 | train loss: 1.445472e-03 | valid loss: 1.516241e-03 
      	| train loss (relative): 2.830766e-02 | valid loss (relative): 2.960931e-02 
Epoch 1025 use: 405.61 second.

epoch 1026 starting......
Epoch:  1026 | train loss: 1.442954e-03 | valid loss: 1.508303e-03 
      	| train loss (relative): 2.825269e-02 | valid loss (relative): 2.962048e-02 
Epoch 1026 use: 407.08 second.

epoch 1027 starting......
Epoch:  1027 | train loss: 1.442423e-03 | valid loss: 1.515328e-03 
      	| train loss (relative): 2.824722e-02 | valid loss (relative): 2.985221e-02 
Epoch 1027 use: 409.21 second.

epoch 1028 starting......
Epoch:  1028 | train loss: 1.444591e-03 | valid loss: 1.515652e-03 
      	| train loss (relative): 2.828822e-02 | valid loss (relative): 2.970965e-02 
Epoch 1028 use: 400.49 second.

epoch 1029 starting......
Epoch:  1029 | train loss: 1.442036e-03 | valid loss: 1.515468e-03 
      	| train loss (relative): 2.823880e-02 | valid loss (relative): 2.972428e-02 
Epoch 1029 use: 400.36 second.

epoch 1030 starting......
Epoch:  1030 | train loss: 1.440403e-03 | valid loss: 1.507336e-03 
      	| train loss (relative): 2.820537e-02 | valid loss (relative): 2.948412e-02 
Epoch 1030 use: 385.68 second.

epoch 1031 starting......
Epoch:  1031 | train loss: 1.437494e-03 | valid loss: 1.511865e-03 
      	| train loss (relative): 2.814853e-02 | valid loss (relative): 2.971495e-02 
Epoch 1031 use: 379.27 second.

epoch 1032 starting......
Epoch:  1032 | train loss: 1.437766e-03 | valid loss: 1.507042e-03 
      	| train loss (relative): 2.815165e-02 | valid loss (relative): 2.970087e-02 
Epoch 1032 use: 416.34 second.

epoch 1033 starting......
Epoch:  1033 | train loss: 1.439478e-03 | valid loss: 1.512427e-03 
      	| train loss (relative): 2.818684e-02 | valid loss (relative): 2.953604e-02 
Epoch 1033 use: 379.10 second.

epoch 1034 starting......
Epoch:  1034 | train loss: 1.438923e-03 | valid loss: 1.512040e-03 
      	| train loss (relative): 2.817668e-02 | valid loss (relative): 2.969404e-02 
Epoch 1034 use: 389.41 second.

epoch 1035 starting......
Epoch:  1035 | train loss: 1.439841e-03 | valid loss: 1.512604e-03 
      	| train loss (relative): 2.819363e-02 | valid loss (relative): 2.960969e-02 
Epoch 1035 use: 387.40 second.

epoch 1036 starting......
Epoch:  1036 | train loss: 1.439056e-03 | valid loss: 1.511414e-03 
      	| train loss (relative): 2.817790e-02 | valid loss (relative): 2.981321e-02 
Epoch 1036 use: 409.58 second.

epoch 1037 starting......
Epoch:  1037 | train loss: 1.435809e-03 | valid loss: 1.514270e-03 
      	| train loss (relative): 2.811368e-02 | valid loss (relative): 2.957778e-02 
Epoch 1037 use: 399.24 second.

epoch 1038 starting......
Epoch:  1038 | train loss: 1.438524e-03 | valid loss: 1.510510e-03 
      	| train loss (relative): 2.816587e-02 | valid loss (relative): 2.964081e-02 
Epoch 1038 use: 401.66 second.

epoch 1039 starting......
Epoch:  1039 | train loss: 1.437493e-03 | valid loss: 1.512117e-03 
      	| train loss (relative): 2.814924e-02 | valid loss (relative): 2.973205e-02 
Epoch 1039 use: 392.81 second.

epoch 1040 starting......
Epoch:  1040 | train loss: 1.437190e-03 | valid loss: 1.512478e-03 
      	| train loss (relative): 2.813608e-02 | valid loss (relative): 2.983500e-02 
Epoch 1040 use: 414.05 second.

epoch 1041 starting......
Epoch:  1041 | train loss: 1.437465e-03 | valid loss: 1.510289e-03 
      	| train loss (relative): 2.814785e-02 | valid loss (relative): 2.959291e-02 
Epoch 1041 use: 400.15 second.

epoch 1042 starting......
Epoch:  1042 | train loss: 1.435210e-03 | valid loss: 1.511488e-03 
      	| train loss (relative): 2.810007e-02 | valid loss (relative): 2.948426e-02 
Epoch 1042 use: 414.28 second.

epoch 1043 starting......
Epoch:  1043 | train loss: 1.437441e-03 | valid loss: 1.515230e-03 
      	| train loss (relative): 2.814320e-02 | valid loss (relative): 2.974003e-02 
Epoch 1043 use: 395.91 second.

epoch 1044 starting......
Epoch:  1044 | train loss: 1.438934e-03 | valid loss: 1.517255e-03 
      	| train loss (relative): 2.817391e-02 | valid loss (relative): 2.981392e-02 
Epoch 1044 use: 399.13 second.

epoch 1045 starting......
Epoch:  1045 | train loss: 1.440174e-03 | valid loss: 1.517411e-03 
      	| train loss (relative): 2.819810e-02 | valid loss (relative): 2.990963e-02 
Epoch 1045 use: 386.18 second.

epoch 1046 starting......
Epoch:  1046 | train loss: 1.441749e-03 | valid loss: 1.515886e-03 
      	| train loss (relative): 2.823379e-02 | valid loss (relative): 2.975984e-02 
Epoch 1046 use: 392.82 second.

epoch 1047 starting......
Epoch:  1047 | train loss: 1.436791e-03 | valid loss: 1.515471e-03 
      	| train loss (relative): 2.812986e-02 | valid loss (relative): 2.976928e-02 
Epoch 1047 use: 396.37 second.

epoch 1048 starting......
Epoch:  1048 | train loss: 1.434242e-03 | valid loss: 1.504438e-03 
      	| train loss (relative): 2.807884e-02 | valid loss (relative): 2.958124e-02 
Epoch 1048 use: 397.75 second.

epoch 1049 starting......
Epoch:  1049 | train loss: 1.434339e-03 | valid loss: 1.515076e-03 
      	| train loss (relative): 2.808310e-02 | valid loss (relative): 2.967128e-02 
Epoch 1049 use: 410.61 second.

epoch 1050 starting......
Epoch:  1050 | train loss: 1.435561e-03 | valid loss: 1.517837e-03 
      	| train loss (relative): 2.810676e-02 | valid loss (relative): 2.993466e-02 
Epoch 1050 use: 391.99 second.

epoch 1051 starting......
Epoch:  1051 | train loss: 1.437644e-03 | valid loss: 1.512667e-03 
      	| train loss (relative): 2.815058e-02 | valid loss (relative): 2.985966e-02 
Epoch 1051 use: 383.06 second.

epoch 1052 starting......
Epoch:  1052 | train loss: 1.434903e-03 | valid loss: 1.519180e-03 
      	| train loss (relative): 2.809754e-02 | valid loss (relative): 2.987036e-02 
Epoch 1052 use: 384.20 second.

epoch 1053 starting......
Epoch:  1053 | train loss: 1.435753e-03 | valid loss: 1.508773e-03 
      	| train loss (relative): 2.811459e-02 | valid loss (relative): 2.976399e-02 
Epoch 1053 use: 393.02 second.

epoch 1054 starting......
Epoch:  1054 | train loss: 1.431963e-03 | valid loss: 1.506847e-03 
      	| train loss (relative): 2.803493e-02 | valid loss (relative): 2.968457e-02 
Epoch 1054 use: 397.85 second.

epoch 1055 starting......
Epoch:  1055 | train loss: 1.431097e-03 | valid loss: 1.504117e-03 
      	| train loss (relative): 2.802010e-02 | valid loss (relative): 2.954501e-02 
Epoch 1055 use: 388.72 second.

epoch 1056 starting......
Epoch:  1056 | train loss: 1.430876e-03 | valid loss: 1.508141e-03 
      	| train loss (relative): 2.801371e-02 | valid loss (relative): 2.956730e-02 
Epoch 1056 use: 378.44 second.

epoch 1057 starting......
Epoch:  1057 | train loss: 1.432481e-03 | valid loss: 1.516505e-03 
      	| train loss (relative): 2.804717e-02 | valid loss (relative): 2.954660e-02 
Epoch 1057 use: 395.67 second.

epoch 1058 starting......
Epoch:  1058 | train loss: 1.438534e-03 | valid loss: 1.509932e-03 
      	| train loss (relative): 2.816552e-02 | valid loss (relative): 2.950390e-02 
Epoch 1058 use: 398.54 second.

epoch 1059 starting......
Epoch:  1059 | train loss: 1.429201e-03 | valid loss: 1.506754e-03 
      	| train loss (relative): 2.798163e-02 | valid loss (relative): 2.959619e-02 
Epoch 1059 use: 397.25 second.

epoch 1060 starting......
Epoch:  1060 | train loss: 1.428778e-03 | valid loss: 1.507272e-03 
      	| train loss (relative): 2.796926e-02 | valid loss (relative): 2.943737e-02 
Epoch 1060 use: 384.92 second.

epoch 1061 starting......
Epoch:  1061 | train loss: 1.432990e-03 | valid loss: 1.507243e-03 
      	| train loss (relative): 2.805703e-02 | valid loss (relative): 2.950338e-02 
Epoch 1061 use: 406.19 second.

epoch 1062 starting......
Epoch:  1062 | train loss: 1.432557e-03 | valid loss: 1.507633e-03 
      	| train loss (relative): 2.804655e-02 | valid loss (relative): 2.961982e-02 
Epoch 1062 use: 392.37 second.

epoch 1063 starting......
Epoch:  1063 | train loss: 1.432166e-03 | valid loss: 1.513286e-03 
      	| train loss (relative): 2.803818e-02 | valid loss (relative): 2.986776e-02 
Epoch 1063 use: 403.86 second.

epoch 1064 starting......
Epoch:  1064 | train loss: 1.431534e-03 | valid loss: 1.507259e-03 
      	| train loss (relative): 2.802644e-02 | valid loss (relative): 2.953003e-02 
Epoch 1064 use: 399.09 second.

epoch 1065 starting......
Epoch:  1065 | train loss: 1.432476e-03 | valid loss: 1.511368e-03 
      	| train loss (relative): 2.804306e-02 | valid loss (relative): 2.972001e-02 
Epoch 1065 use: 389.30 second.

epoch 1066 starting......
Epoch:  1066 | train loss: 1.434475e-03 | valid loss: 1.511063e-03 
      	| train loss (relative): 2.808663e-02 | valid loss (relative): 2.962542e-02 
Epoch 1066 use: 395.20 second.

epoch 1067 starting......
Epoch:  1067 | train loss: 1.433488e-03 | valid loss: 1.504669e-03 
      	| train loss (relative): 2.806567e-02 | valid loss (relative): 2.942549e-02 
Epoch 1067 use: 386.08 second.

epoch 1068 starting......
Epoch:  1068 | train loss: 1.425758e-03 | valid loss: 1.503347e-03 
      	| train loss (relative): 2.791090e-02 | valid loss (relative): 2.937335e-02 
Epoch 1068 use: 419.58 second.

epoch 1069 starting......
Epoch:  1069 | train loss: 1.424256e-03 | valid loss: 1.501408e-03 
      	| train loss (relative): 2.787826e-02 | valid loss (relative): 2.946087e-02 
Epoch 1069 use: 394.82 second.

epoch 1070 starting......
Epoch:  1070 | train loss: 1.424406e-03 | valid loss: 1.505895e-03 
      	| train loss (relative): 2.788327e-02 | valid loss (relative): 2.956740e-02 
Epoch 1070 use: 408.58 second.

epoch 1071 starting......
Epoch:  1071 | train loss: 1.429954e-03 | valid loss: 1.509789e-03 
      	| train loss (relative): 2.799258e-02 | valid loss (relative): 2.971149e-02 
Epoch 1071 use: 421.32 second.

epoch 1072 starting......
Epoch:  1072 | train loss: 1.430258e-03 | valid loss: 1.505360e-03 
      	| train loss (relative): 2.800270e-02 | valid loss (relative): 2.956554e-02 
Epoch 1072 use: 396.77 second.

epoch 1073 starting......
Epoch:  1073 | train loss: 1.428190e-03 | valid loss: 1.508378e-03 
      	| train loss (relative): 2.796067e-02 | valid loss (relative): 2.973682e-02 
Epoch 1073 use: 390.64 second.

epoch 1074 starting......
Epoch:  1074 | train loss: 1.429178e-03 | valid loss: 1.503538e-03 
      	| train loss (relative): 2.798337e-02 | valid loss (relative): 2.959762e-02 
Epoch 1074 use: 407.41 second.

epoch 1075 starting......
Epoch:  1075 | train loss: 1.426802e-03 | valid loss: 1.514841e-03 
      	| train loss (relative): 2.793491e-02 | valid loss (relative): 2.979069e-02 
Epoch 1075 use: 401.42 second.

epoch 1076 starting......
Epoch:  1076 | train loss: 1.431965e-03 | valid loss: 1.512627e-03 
      	| train loss (relative): 2.803624e-02 | valid loss (relative): 2.960545e-02 
Epoch 1076 use: 414.11 second.

epoch 1077 starting......
Epoch:  1077 | train loss: 1.426658e-03 | valid loss: 1.506194e-03 
      	| train loss (relative): 2.792961e-02 | valid loss (relative): 2.954353e-02 
Epoch 1077 use: 391.09 second.

epoch 1078 starting......
Epoch:  1078 | train loss: 1.423795e-03 | valid loss: 1.503444e-03 
      	| train loss (relative): 2.786871e-02 | valid loss (relative): 2.946754e-02 
Epoch 1078 use: 417.18 second.

epoch 1079 starting......
Epoch:  1079 | train loss: 1.426222e-03 | valid loss: 1.501241e-03 
      	| train loss (relative): 2.791727e-02 | valid loss (relative): 2.955646e-02 
Epoch 1079 use: 385.21 second.

epoch 1080 starting......
Epoch:  1080 | train loss: 1.424302e-03 | valid loss: 1.500717e-03 
      	| train loss (relative): 2.788111e-02 | valid loss (relative): 2.935233e-02 
Epoch 1080 use: 411.66 second.

epoch 1081 starting......
Epoch:  1081 | train loss: 1.421842e-03 | valid loss: 1.499669e-03 
      	| train loss (relative): 2.782909e-02 | valid loss (relative): 2.952466e-02 
Epoch 1081 use: 394.77 second.

epoch 1082 starting......
Epoch:  1082 | train loss: 1.424206e-03 | valid loss: 1.504007e-03 
      	| train loss (relative): 2.788118e-02 | valid loss (relative): 2.949435e-02 
Epoch 1082 use: 392.89 second.

epoch 1083 starting......
Epoch:  1083 | train loss: 1.423994e-03 | valid loss: 1.501885e-03 
      	| train loss (relative): 2.787877e-02 | valid loss (relative): 2.944792e-02 
Epoch 1083 use: 421.38 second.

epoch 1084 starting......
Epoch:  1084 | train loss: 1.421922e-03 | valid loss: 1.501830e-03 
      	| train loss (relative): 2.783282e-02 | valid loss (relative): 2.935486e-02 
Epoch 1084 use: 393.43 second.

epoch 1085 starting......
Epoch:  1085 | train loss: 1.424595e-03 | valid loss: 1.506703e-03 
      	| train loss (relative): 2.789011e-02 | valid loss (relative): 2.945884e-02 
Epoch 1085 use: 403.33 second.

epoch 1086 starting......
Epoch:  1086 | train loss: 1.424830e-03 | valid loss: 1.499962e-03 
      	| train loss (relative): 2.789151e-02 | valid loss (relative): 2.938811e-02 
Epoch 1086 use: 383.54 second.

epoch 1087 starting......
Epoch:  1087 | train loss: 1.423399e-03 | valid loss: 1.507453e-03 
      	| train loss (relative): 2.786250e-02 | valid loss (relative): 2.952991e-02 
Epoch 1087 use: 396.99 second.

epoch 1088 starting......
Epoch:  1088 | train loss: 1.424848e-03 | valid loss: 1.502430e-03 
      	| train loss (relative): 2.789364e-02 | valid loss (relative): 2.938969e-02 
Epoch 1088 use: 381.73 second.

epoch 1089 starting......
Epoch:  1089 | train loss: 1.423759e-03 | valid loss: 1.503222e-03 
      	| train loss (relative): 2.786772e-02 | valid loss (relative): 2.948008e-02 
Epoch 1089 use: 384.64 second.

epoch 1090 starting......
Epoch:  1090 | train loss: 1.424514e-03 | valid loss: 1.500304e-03 
      	| train loss (relative): 2.788643e-02 | valid loss (relative): 2.946938e-02 
Epoch 1090 use: 392.72 second.

epoch 1091 starting......
Epoch:  1091 | train loss: 1.424935e-03 | valid loss: 1.506339e-03 
      	| train loss (relative): 2.789486e-02 | valid loss (relative): 2.957184e-02 
Epoch 1091 use: 388.71 second.

epoch 1092 starting......
Epoch:  1092 | train loss: 1.426875e-03 | valid loss: 1.505497e-03 
      	| train loss (relative): 2.792963e-02 | valid loss (relative): 2.963970e-02 
Epoch 1092 use: 409.15 second.

epoch 1093 starting......
Epoch:  1093 | train loss: 1.423728e-03 | valid loss: 1.510522e-03 
      	| train loss (relative): 2.787553e-02 | valid loss (relative): 2.953873e-02 
Epoch 1093 use: 390.14 second.

epoch 1094 starting......
Epoch:  1094 | train loss: 1.425434e-03 | valid loss: 1.506848e-03 
      	| train loss (relative): 2.790508e-02 | valid loss (relative): 2.955109e-02 
Epoch 1094 use: 402.24 second.

epoch 1095 starting......
Epoch:  1095 | train loss: 1.427743e-03 | valid loss: 1.502338e-03 
      	| train loss (relative): 2.794984e-02 | valid loss (relative): 2.963221e-02 
Epoch 1095 use: 391.72 second.

epoch 1096 starting......
Epoch:  1096 | train loss: 1.419824e-03 | valid loss: 1.503318e-03 
      	| train loss (relative): 2.779460e-02 | valid loss (relative): 2.949719e-02 
Epoch 1096 use: 379.56 second.

epoch 1097 starting......
Epoch:  1097 | train loss: 1.422361e-03 | valid loss: 1.494402e-03 
      	| train loss (relative): 2.783893e-02 | valid loss (relative): 2.945608e-02 
Epoch 1097 use: 400.34 second.

epoch 1098 starting......
Epoch:  1098 | train loss: 1.414015e-03 | valid loss: 1.491939e-03 
      	| train loss (relative): 2.768005e-02 | valid loss (relative): 2.928129e-02 
Epoch 1098 use: 380.51 second.

epoch 1099 starting......
Epoch:  1099 | train loss: 1.413821e-03 | valid loss: 1.494284e-03 
      	| train loss (relative): 2.767367e-02 | valid loss (relative): 2.939784e-02 
Epoch 1099 use: 412.95 second.

epoch 1100 starting......
Epoch:  1100 | train loss: 1.418247e-03 | valid loss: 1.497990e-03 
      	| train loss (relative): 2.776193e-02 | valid loss (relative): 2.931113e-02 
Epoch 1100 use: 389.61 second.

epoch 1101 starting......
Epoch:  1101 | train loss: 1.415845e-03 | valid loss: 1.496811e-03 
      	| train loss (relative): 2.770939e-02 | valid loss (relative): 2.965514e-02 
Epoch 1101 use: 392.97 second.

epoch 1102 starting......
Epoch:  1102 | train loss: 1.415725e-03 | valid loss: 1.496233e-03 
      	| train loss (relative): 2.771296e-02 | valid loss (relative): 2.928472e-02 
Epoch 1102 use: 395.50 second.

epoch 1103 starting......
Epoch:  1103 | train loss: 1.417452e-03 | valid loss: 1.497689e-03 
      	| train loss (relative): 2.774754e-02 | valid loss (relative): 2.941752e-02 
Epoch 1103 use: 401.90 second.

epoch 1104 starting......
Epoch:  1104 | train loss: 1.416842e-03 | valid loss: 1.494447e-03 
      	| train loss (relative): 2.773182e-02 | valid loss (relative): 2.935198e-02 
Epoch 1104 use: 389.34 second.

epoch 1105 starting......
Epoch:  1105 | train loss: 1.421088e-03 | valid loss: 1.500507e-03 
      	| train loss (relative): 2.781351e-02 | valid loss (relative): 2.941552e-02 
Epoch 1105 use: 403.75 second.

epoch 1106 starting......
Epoch:  1106 | train loss: 1.418893e-03 | valid loss: 1.502023e-03 
      	| train loss (relative): 2.777258e-02 | valid loss (relative): 2.951798e-02 
Epoch 1106 use: 392.96 second.

epoch 1107 starting......
Epoch:  1107 | train loss: 1.418451e-03 | valid loss: 1.502565e-03 
      	| train loss (relative): 2.776600e-02 | valid loss (relative): 2.943039e-02 
Epoch 1107 use: 422.01 second.

epoch 1108 starting......
Epoch:  1108 | train loss: 1.420318e-03 | valid loss: 1.501459e-03 
      	| train loss (relative): 2.780112e-02 | valid loss (relative): 2.934716e-02 
Epoch 1108 use: 390.93 second.

epoch 1109 starting......
Epoch:  1109 | train loss: 1.420464e-03 | valid loss: 1.508057e-03 
      	| train loss (relative): 2.780353e-02 | valid loss (relative): 2.968766e-02 
Epoch 1109 use: 388.43 second.

epoch 1110 starting......
Epoch:  1110 | train loss: 1.420959e-03 | valid loss: 1.494902e-03 
      	| train loss (relative): 2.781158e-02 | valid loss (relative): 2.940512e-02 
Epoch 1110 use: 386.18 second.

epoch 1111 starting......
Epoch:  1111 | train loss: 1.416922e-03 | valid loss: 1.499749e-03 
      	| train loss (relative): 2.773489e-02 | valid loss (relative): 2.938025e-02 
Epoch 1111 use: 376.99 second.

epoch 1112 starting......
Epoch:  1112 | train loss: 1.414574e-03 | valid loss: 1.497977e-03 
      	| train loss (relative): 2.768703e-02 | valid loss (relative): 2.947664e-02 
Epoch 1112 use: 389.66 second.

epoch 1113 starting......
Epoch:  1113 | train loss: 1.417737e-03 | valid loss: 1.499686e-03 
      	| train loss (relative): 2.775212e-02 | valid loss (relative): 2.955402e-02 
Epoch 1113 use: 396.01 second.

epoch 1114 starting......
Epoch:  1114 | train loss: 1.418274e-03 | valid loss: 1.501765e-03 
      	| train loss (relative): 2.775839e-02 | valid loss (relative): 2.957709e-02 
Epoch 1114 use: 390.99 second.

epoch 1115 starting......
Epoch:  1115 | train loss: 1.417965e-03 | valid loss: 1.504140e-03 
      	| train loss (relative): 2.775581e-02 | valid loss (relative): 2.945600e-02 
Epoch 1115 use: 388.71 second.

epoch 1116 starting......
Epoch:  1116 | train loss: 1.420143e-03 | valid loss: 1.503251e-03 
      	| train loss (relative): 2.779638e-02 | valid loss (relative): 2.955530e-02 
Epoch 1116 use: 393.47 second.

epoch 1117 starting......
Epoch:  1117 | train loss: 1.417869e-03 | valid loss: 1.490361e-03 
      	| train loss (relative): 2.775211e-02 | valid loss (relative): 2.928860e-02 
Epoch 1117 use: 403.02 second.

epoch 1118 starting......
Epoch:  1118 | train loss: 1.408768e-03 | valid loss: 1.494531e-03 
      	| train loss (relative): 2.757003e-02 | valid loss (relative): 2.950068e-02 
Epoch 1118 use: 397.22 second.

epoch 1119 starting......
Epoch:  1119 | train loss: 1.409471e-03 | valid loss: 1.500476e-03 
      	| train loss (relative): 2.758412e-02 | valid loss (relative): 2.970946e-02 
Epoch 1119 use: 380.16 second.

epoch 1120 starting......
Epoch:  1120 | train loss: 1.410865e-03 | valid loss: 1.492222e-03 
      	| train loss (relative): 2.761479e-02 | valid loss (relative): 2.922686e-02 
Epoch 1120 use: 393.62 second.

epoch 1121 starting......
Epoch:  1121 | train loss: 1.409904e-03 | valid loss: 1.494775e-03 
      	| train loss (relative): 2.759000e-02 | valid loss (relative): 2.930042e-02 
Epoch 1121 use: 383.08 second.

epoch 1122 starting......
Epoch:  1122 | train loss: 1.413416e-03 | valid loss: 1.495319e-03 
      	| train loss (relative): 2.766175e-02 | valid loss (relative): 2.935076e-02 
Epoch 1122 use: 398.81 second.

epoch 1123 starting......
Epoch:  1123 | train loss: 1.413076e-03 | valid loss: 1.495998e-03 
      	| train loss (relative): 2.765591e-02 | valid loss (relative): 2.946204e-02 
Epoch 1123 use: 381.78 second.

epoch 1124 starting......
Epoch:  1124 | train loss: 1.412059e-03 | valid loss: 1.496236e-03 
      	| train loss (relative): 2.763959e-02 | valid loss (relative): 2.947976e-02 
Epoch 1124 use: 402.64 second.

epoch 1125 starting......
Epoch:  1125 | train loss: 1.414183e-03 | valid loss: 1.494908e-03 
      	| train loss (relative): 2.767752e-02 | valid loss (relative): 2.921641e-02 
Epoch 1125 use: 384.82 second.

epoch 1126 starting......
Epoch:  1126 | train loss: 1.415283e-03 | valid loss: 1.508469e-03 
      	| train loss (relative): 2.770020e-02 | valid loss (relative): 2.955846e-02 
Epoch 1126 use: 379.49 second.

epoch 1127 starting......
Epoch:  1127 | train loss: 1.417028e-03 | valid loss: 1.496812e-03 
      	| train loss (relative): 2.773224e-02 | valid loss (relative): 2.943520e-02 
Epoch 1127 use: 413.35 second.

epoch 1128 starting......
Epoch:  1128 | train loss: 1.412355e-03 | valid loss: 1.492687e-03 
      	| train loss (relative): 2.764251e-02 | valid loss (relative): 2.940595e-02 
Epoch 1128 use: 392.17 second.

epoch 1129 starting......
Epoch:  1129 | train loss: 1.410562e-03 | valid loss: 1.497890e-03 
      	| train loss (relative): 2.761063e-02 | valid loss (relative): 2.913698e-02 
Epoch 1129 use: 414.99 second.

epoch 1130 starting......
Epoch:  1130 | train loss: 1.412618e-03 | valid loss: 1.493035e-03 
      	| train loss (relative): 2.764811e-02 | valid loss (relative): 2.926675e-02 
Epoch 1130 use: 378.22 second.

epoch 1131 starting......
Epoch:  1131 | train loss: 1.412947e-03 | valid loss: 1.495830e-03 
      	| train loss (relative): 2.765666e-02 | valid loss (relative): 2.942099e-02 
Epoch 1131 use: 393.44 second.

epoch 1132 starting......
Epoch:  1132 | train loss: 1.410306e-03 | valid loss: 1.489679e-03 
      	| train loss (relative): 2.760394e-02 | valid loss (relative): 2.915116e-02 
Epoch 1132 use: 407.10 second.

epoch 1133 starting......
Epoch:  1133 | train loss: 1.408609e-03 | valid loss: 1.495174e-03 
      	| train loss (relative): 2.756456e-02 | valid loss (relative): 2.953064e-02 
Epoch 1133 use: 383.52 second.

epoch 1134 starting......
Epoch:  1134 | train loss: 1.411255e-03 | valid loss: 1.497831e-03 
      	| train loss (relative): 2.762223e-02 | valid loss (relative): 2.960696e-02 
Epoch 1134 use: 383.35 second.

epoch 1135 starting......
Epoch:  1135 | train loss: 1.411496e-03 | valid loss: 1.492873e-03 
      	| train loss (relative): 2.762365e-02 | valid loss (relative): 2.919929e-02 
Epoch 1135 use: 390.77 second.

epoch 1136 starting......
Epoch:  1136 | train loss: 1.409781e-03 | valid loss: 1.498284e-03 
      	| train loss (relative): 2.758968e-02 | valid loss (relative): 2.957660e-02 
Epoch 1136 use: 381.97 second.

epoch 1137 starting......
Epoch:  1137 | train loss: 1.414242e-03 | valid loss: 1.493723e-03 
      	| train loss (relative): 2.767866e-02 | valid loss (relative): 2.929729e-02 
Epoch 1137 use: 402.79 second.

epoch 1138 starting......
Epoch:  1138 | train loss: 1.411043e-03 | valid loss: 1.499819e-03 
      	| train loss (relative): 2.761742e-02 | valid loss (relative): 2.940815e-02 
Epoch 1138 use: 402.57 second.

epoch 1139 starting......
Epoch:  1139 | train loss: 1.409630e-03 | valid loss: 1.492741e-03 
      	| train loss (relative): 2.758374e-02 | valid loss (relative): 2.923513e-02 
Epoch 1139 use: 387.79 second.

epoch 1140 starting......
Epoch:  1140 | train loss: 1.406505e-03 | valid loss: 1.489114e-03 
      	| train loss (relative): 2.753032e-02 | valid loss (relative): 2.922755e-02 
Epoch 1140 use: 387.68 second.

epoch 1141 starting......
Epoch:  1141 | train loss: 1.406527e-03 | valid loss: 1.491554e-03 
      	| train loss (relative): 2.753187e-02 | valid loss (relative): 2.916782e-02 
Epoch 1141 use: 376.87 second.

epoch 1142 starting......
Epoch:  1142 | train loss: 1.409889e-03 | valid loss: 1.490735e-03 
      	| train loss (relative): 2.759434e-02 | valid loss (relative): 2.941189e-02 
Epoch 1142 use: 401.89 second.

epoch 1143 starting......
Epoch:  1143 | train loss: 1.409920e-03 | valid loss: 1.489006e-03 
      	| train loss (relative): 2.759481e-02 | valid loss (relative): 2.911703e-02 
Epoch 1143 use: 399.79 second.

epoch 1144 starting......
Epoch:  1144 | train loss: 1.406149e-03 | valid loss: 1.493116e-03 
      	| train loss (relative): 2.751774e-02 | valid loss (relative): 2.929388e-02 
Epoch 1144 use: 375.38 second.

epoch 1145 starting......
Epoch:  1145 | train loss: 1.409396e-03 | valid loss: 1.487488e-03 
      	| train loss (relative): 2.758412e-02 | valid loss (relative): 2.908556e-02 
Epoch 1145 use: 420.08 second.

epoch 1146 starting......
Epoch:  1146 | train loss: 1.404060e-03 | valid loss: 1.486194e-03 
      	| train loss (relative): 2.747550e-02 | valid loss (relative): 2.900552e-02 
Epoch 1146 use: 391.94 second.

epoch 1147 starting......
Epoch:  1147 | train loss: 1.404818e-03 | valid loss: 1.490355e-03 
      	| train loss (relative): 2.748834e-02 | valid loss (relative): 2.926977e-02 
Epoch 1147 use: 422.88 second.

epoch 1148 starting......
Epoch:  1148 | train loss: 1.407330e-03 | valid loss: 1.495544e-03 
      	| train loss (relative): 2.754032e-02 | valid loss (relative): 2.931586e-02 
Epoch 1148 use: 407.83 second.

epoch 1149 starting......
Epoch:  1149 | train loss: 1.409724e-03 | valid loss: 1.499645e-03 
      	| train loss (relative): 2.758626e-02 | valid loss (relative): 2.939069e-02 
Epoch 1149 use: 474.70 second.

test MSE Error: 1.471097e-03 | relative MSE Error: 2.878103e-02 
 Total time used for training: 16.63 hour.
MESLoss saved to  /rds/general/user/jy220/home/new_results/Variational_False_Changelr_False_MSELoss_Latent_256_nearest_neighbouring_True_SFC_nums_3_startlr_0.001_n_epoches_1150.txt
relative MSELoss saved to  /rds/general/user/jy220/home/new_results/Variational_False_Changelr_False_reMSELoss_Latent_256_nearest_neighbouring_True_SFC_nums_3_startlr_0.001_n_epoches_1150.txt
model saved to /rds/general/user/jy220/home/new_results/Variational_False_Changelr_False_Latent_256_Nearest_neighbouring_True_SFC_nums_3_startlr_0.001_n_epoches_1150.pth
model_dict saved to /rds/general/user/jy220/home/new_results/Variational_False_Changelr_False_Latent_256_Nearest_neighbouring_True_SFC_nums_3_startlr_0.001_n_epoches_1150_dict.pth
... Training slugflow data completed, Run finished Sun 22 Aug 09:41:01 BST 2021 ...
{'data_dir': '/rds/general/user/jy220/home/tensors/', 'data_type': 'tensors', 'mode': 'train', 'vtu_fields': 'Component1::ComponentMassFractionPhase1, phase1::Velocity', 'variational': 'False', 'optimizer': 'Adamax', 'structured': 'False', 'changing_lr': 'False', 'self_concat': '2', 'dimension': '3', 'sfc_nums': '3', 'components': '4', 'nearest_neighbouring': 'True', 'dims_latent': '256', 'activation': 'Tanh', 'tk_file': '/rds/general/user/jy220/home/slugflow_tk.pt', 'tb_file': '/rds/general/user/jy220/home/slugflow_tb.pt', 'sfc_file': '/rds/general/user/jy220/home/SFC-CAE-Ready-to-use/sfcs.pt', 'inv_sfc_file': '/rds/general/user/jy220/home/SFC-CAE-Ready-to-use/inv_sfcs.pt', 'coords_file': '/rds/general/user/jy220/home/SFC-CAE-Ready-to-use/coords.pt', 'cells_file': '/rds/general/user/jy220/home/SFC-CAE-Ready-to-use/cells.npy', 'state_load': '/rds/general/user/jy220/home/new_results/Variational_False_Changelr_False_Latent_256_Nearest_neighbouring_True_SFC_nums_3_startlr_0.001_n_epoches_1150_dict.pth', 'batch_size': '16', 'lr': '0.001', 'n_epoches': '150', 'seed': '17', 'visualize': 'False', 'reconstructed_path': 'None', 'reconstruct_start_index': '0', 'reconstruct_end_index': '50', 'save_path': '/rds/general/user/jy220/home/new_results/'}
[[ 2.50825269e-01 -1.67256990e-02 -1.22268730e-03]
 [ 2.38611959e-01 -5.50627777e-03 -5.06451913e-03]
 [ 2.39454874e-01 -1.59563257e-02  3.96778323e-03]
 ...
 [ 9.11361096e+00 -2.21908381e-02  2.22384902e-03]
 [ 9.11847310e+00 -2.84346931e-02 -2.34839590e-04]
 [ 9.11039661e+00 -2.51498573e-02 -8.70661044e-03]]
{'tetra': array([[      0,       1,       2,       3],
       [      4,       5,       6,       7],
       [      8,       9,      10,      11],
       ...,
       [1342744, 1342745, 1342746, 1342747],
       [1342748, 1342749, 1342750, 1342751],
       [1342752, 1342753, 1342754, 1342755]])}
vtu fields:  ['Component1::ComponentMassFractionPhase1', 'phase1::Velocity'] 
 structured  False 
 activation  Tanh() 
 self concat  2 
 sfc_nums  3 

dims_latent  256 
 components  4 
 nearest_neighbouring  True 

visualize  False 
 sample number  1706 

reading sfc nums......
[array([  41684,   41685,   41674, ..., 1235560, 1235564, 1235558]), array([954289, 954290, 954291, ..., 420685, 420687, 420688]), array([  40156,   40155,   40158, ..., 1123478, 1123475, 1123467])]
reading inverse sfc nums......
[array([   8146,    8145,    8144, ..., 1274444, 1274445, 1273166]), array([547280, 547283, 593037, ..., 933933, 933932, 864488]), array([ 66437,  66439, 122512, ..., 459416, 415130, 459418])]
tk:  tensor([0.7581, 0.0418, 0.1840, 0.1464], dtype=torch.float64) 

tb:  tensor([-0.3816, -0.3618, -0.0308,  0.1446], dtype=torch.float64) 

length of train set: 1505 

length of valid set: 100 

length of test set: 101 

torch device num: 4 

Let's use 4 GPUs!
epoch 1150 starting......
Epoch:  1150 | train loss: 1.616113e-03 | valid loss: 1.462917e-03 
      	| train loss (relative): 3.161054e-02 | valid loss (relative): 2.863984e-02 
Epoch 1150 use: 473.44 second.

epoch 1151 starting......
Epoch:  1151 | train loss: 1.409873e-03 | valid loss: 1.448090e-03 
      	| train loss (relative): 2.760100e-02 | valid loss (relative): 2.834117e-02 
Epoch 1151 use: 378.18 second.

epoch 1152 starting......
Epoch:  1152 | train loss: 1.401289e-03 | valid loss: 1.444966e-03 
      	| train loss (relative): 2.743036e-02 | valid loss (relative): 2.828969e-02 
Epoch 1152 use: 359.13 second.

epoch 1153 starting......
Epoch:  1153 | train loss: 1.397089e-03 | valid loss: 1.444195e-03 
      	| train loss (relative): 2.734418e-02 | valid loss (relative): 2.832169e-02 
Epoch 1153 use: 363.80 second.

epoch 1154 starting......
Epoch:  1154 | train loss: 1.395931e-03 | valid loss: 1.446643e-03 
      	| train loss (relative): 2.732252e-02 | valid loss (relative): 2.832315e-02 
Epoch 1154 use: 414.60 second.

epoch 1155 starting......
Epoch:  1155 | train loss: 1.396298e-03 | valid loss: 1.447826e-03 
      	| train loss (relative): 2.732580e-02 | valid loss (relative): 2.836135e-02 
Epoch 1155 use: 439.89 second.

epoch 1156 starting......
Epoch:  1156 | train loss: 1.396525e-03 | valid loss: 1.449822e-03 
      	| train loss (relative): 2.733433e-02 | valid loss (relative): 2.837029e-02 
Epoch 1156 use: 415.78 second.

epoch 1157 starting......
Epoch:  1157 | train loss: 1.399925e-03 | valid loss: 1.452284e-03 
      	| train loss (relative): 2.740324e-02 | valid loss (relative): 2.847114e-02 
Epoch 1157 use: 384.88 second.

epoch 1158 starting......
Epoch:  1158 | train loss: 1.401476e-03 | valid loss: 1.455272e-03 
      	| train loss (relative): 2.743517e-02 | valid loss (relative): 2.848168e-02 
Epoch 1158 use: 373.59 second.

epoch 1159 starting......
Epoch:  1159 | train loss: 1.401915e-03 | valid loss: 1.456666e-03 
      	| train loss (relative): 2.743654e-02 | valid loss (relative): 2.852790e-02 
Epoch 1159 use: 357.37 second.

epoch 1160 starting......
Epoch:  1160 | train loss: 1.404890e-03 | valid loss: 1.459055e-03 
      	| train loss (relative): 2.749845e-02 | valid loss (relative): 2.862357e-02 
Epoch 1160 use: 349.31 second.

epoch 1161 starting......
Epoch:  1161 | train loss: 1.406114e-03 | valid loss: 1.461663e-03 
      	| train loss (relative): 2.752449e-02 | valid loss (relative): 2.863095e-02 
Epoch 1161 use: 347.36 second.

epoch 1162 starting......
Epoch:  1162 | train loss: 1.407836e-03 | valid loss: 1.467110e-03 
      	| train loss (relative): 2.755472e-02 | valid loss (relative): 2.871699e-02 
Epoch 1162 use: 346.02 second.

epoch 1163 starting......
Epoch:  1163 | train loss: 1.407987e-03 | valid loss: 1.469693e-03 
      	| train loss (relative): 2.756024e-02 | valid loss (relative): 2.879497e-02 
Epoch 1163 use: 360.09 second.

epoch 1164 starting......
Epoch:  1164 | train loss: 1.406709e-03 | valid loss: 1.462480e-03 
      	| train loss (relative): 2.753358e-02 | valid loss (relative): 2.862683e-02 
Epoch 1164 use: 347.31 second.

epoch 1165 starting......
Epoch:  1165 | train loss: 1.403788e-03 | valid loss: 1.464702e-03 
      	| train loss (relative): 2.747290e-02 | valid loss (relative): 2.881073e-02 
Epoch 1165 use: 360.35 second.

epoch 1166 starting......
Epoch:  1166 | train loss: 1.407487e-03 | valid loss: 1.462824e-03 
      	| train loss (relative): 2.754684e-02 | valid loss (relative): 2.866545e-02 
Epoch 1166 use: 390.14 second.

epoch 1167 starting......
Epoch:  1167 | train loss: 1.405869e-03 | valid loss: 1.464694e-03 
      	| train loss (relative): 2.751434e-02 | valid loss (relative): 2.875555e-02 
Epoch 1167 use: 348.84 second.

epoch 1168 starting......
Epoch:  1168 | train loss: 1.405467e-03 | valid loss: 1.465904e-03 
      	| train loss (relative): 2.750898e-02 | valid loss (relative): 2.870016e-02 
Epoch 1168 use: 340.76 second.

epoch 1169 starting......
Epoch:  1169 | train loss: 1.404556e-03 | valid loss: 1.465805e-03 
      	| train loss (relative): 2.748901e-02 | valid loss (relative): 2.865306e-02 
Epoch 1169 use: 348.20 second.

epoch 1170 starting......
Epoch:  1170 | train loss: 1.404829e-03 | valid loss: 1.468743e-03 
      	| train loss (relative): 2.749525e-02 | valid loss (relative): 2.880492e-02 
Epoch 1170 use: 331.14 second.

epoch 1171 starting......
Epoch:  1171 | train loss: 1.405394e-03 | valid loss: 1.465555e-03 
      	| train loss (relative): 2.750684e-02 | valid loss (relative): 2.864716e-02 
Epoch 1171 use: 331.88 second.

epoch 1172 starting......
Epoch:  1172 | train loss: 1.406645e-03 | valid loss: 1.470785e-03 
      	| train loss (relative): 2.753108e-02 | valid loss (relative): 2.892148e-02 
Epoch 1172 use: 332.69 second.

epoch 1173 starting......
Epoch:  1173 | train loss: 1.405084e-03 | valid loss: 1.470351e-03 
      	| train loss (relative): 2.749883e-02 | valid loss (relative): 2.885527e-02 
Epoch 1173 use: 341.79 second.

epoch 1174 starting......
Epoch:  1174 | train loss: 1.405241e-03 | valid loss: 1.469292e-03 
      	| train loss (relative): 2.750309e-02 | valid loss (relative): 2.872132e-02 
Epoch 1174 use: 331.10 second.

epoch 1175 starting......
Epoch:  1175 | train loss: 1.407509e-03 | valid loss: 1.468920e-03 
      	| train loss (relative): 2.754824e-02 | valid loss (relative): 2.880483e-02 
Epoch 1175 use: 384.95 second.

epoch 1176 starting......
Epoch:  1176 | train loss: 1.401533e-03 | valid loss: 1.465190e-03 
      	| train loss (relative): 2.742745e-02 | valid loss (relative): 2.875391e-02 
Epoch 1176 use: 361.01 second.

epoch 1177 starting......
Epoch:  1177 | train loss: 1.401256e-03 | valid loss: 1.470075e-03 
      	| train loss (relative): 2.742166e-02 | valid loss (relative): 2.887592e-02 
Epoch 1177 use: 362.19 second.

epoch 1178 starting......
Epoch:  1178 | train loss: 1.399407e-03 | valid loss: 1.469349e-03 
      	| train loss (relative): 2.738880e-02 | valid loss (relative): 2.867972e-02 
Epoch 1178 use: 343.94 second.

epoch 1179 starting......
Epoch:  1179 | train loss: 1.403074e-03 | valid loss: 1.471104e-03 
      	| train loss (relative): 2.745672e-02 | valid loss (relative): 2.894894e-02 
Epoch 1179 use: 343.46 second.

epoch 1180 starting......
Epoch:  1180 | train loss: 1.404626e-03 | valid loss: 1.473010e-03 
      	| train loss (relative): 2.748952e-02 | valid loss (relative): 2.887712e-02 
Epoch 1180 use: 341.02 second.

epoch 1181 starting......
Epoch:  1181 | train loss: 1.403889e-03 | valid loss: 1.471478e-03 
      	| train loss (relative): 2.747547e-02 | valid loss (relative): 2.873899e-02 
Epoch 1181 use: 341.28 second.

epoch 1182 starting......
Epoch:  1182 | train loss: 1.404908e-03 | valid loss: 1.478902e-03 
      	| train loss (relative): 2.749515e-02 | valid loss (relative): 2.886791e-02 
Epoch 1182 use: 338.40 second.

epoch 1183 starting......
Epoch:  1183 | train loss: 1.403768e-03 | valid loss: 1.468826e-03 
      	| train loss (relative): 2.746999e-02 | valid loss (relative): 2.864188e-02 
Epoch 1183 use: 341.31 second.

epoch 1184 starting......
Epoch:  1184 | train loss: 1.399743e-03 | valid loss: 1.461402e-03 
      	| train loss (relative): 2.739058e-02 | valid loss (relative): 2.863972e-02 
Epoch 1184 use: 338.66 second.

epoch 1185 starting......
Epoch:  1185 | train loss: 1.397953e-03 | valid loss: 1.469707e-03 
      	| train loss (relative): 2.735886e-02 | valid loss (relative): 2.870460e-02 
Epoch 1185 use: 336.86 second.

epoch 1186 starting......
Epoch:  1186 | train loss: 1.400364e-03 | valid loss: 1.469271e-03 
      	| train loss (relative): 2.740369e-02 | valid loss (relative): 2.883555e-02 
Epoch 1186 use: 354.84 second.

epoch 1187 starting......
Epoch:  1187 | train loss: 1.397645e-03 | valid loss: 1.463121e-03 
      	| train loss (relative): 2.735056e-02 | valid loss (relative): 2.860995e-02 
Epoch 1187 use: 361.67 second.

epoch 1188 starting......
Epoch:  1188 | train loss: 1.398850e-03 | valid loss: 1.469086e-03 
      	| train loss (relative): 2.737468e-02 | valid loss (relative): 2.871319e-02 
Epoch 1188 use: 332.69 second.

epoch 1189 starting......
Epoch:  1189 | train loss: 1.399923e-03 | valid loss: 1.470347e-03 
      	| train loss (relative): 2.739604e-02 | valid loss (relative): 2.861570e-02 
Epoch 1189 use: 331.29 second.

epoch 1190 starting......
Epoch:  1190 | train loss: 1.401279e-03 | valid loss: 1.466067e-03 
      	| train loss (relative): 2.742673e-02 | valid loss (relative): 2.855698e-02 
Epoch 1190 use: 342.84 second.

epoch 1191 starting......
Epoch:  1191 | train loss: 1.401652e-03 | valid loss: 1.471079e-03 
      	| train loss (relative): 2.742959e-02 | valid loss (relative): 2.892439e-02 
Epoch 1191 use: 342.88 second.

epoch 1192 starting......
Epoch:  1192 | train loss: 1.401398e-03 | valid loss: 1.469891e-03 
      	| train loss (relative): 2.742532e-02 | valid loss (relative): 2.876749e-02 
Epoch 1192 use: 341.37 second.

epoch 1193 starting......
Epoch:  1193 | train loss: 1.401082e-03 | valid loss: 1.472581e-03 
      	| train loss (relative): 2.742046e-02 | valid loss (relative): 2.867836e-02 
Epoch 1193 use: 342.41 second.

epoch 1194 starting......
Epoch:  1194 | train loss: 1.401910e-03 | valid loss: 1.474973e-03 
      	| train loss (relative): 2.743290e-02 | valid loss (relative): 2.910971e-02 
Epoch 1194 use: 338.73 second.

epoch 1195 starting......
Epoch:  1195 | train loss: 1.401328e-03 | valid loss: 1.471095e-03 
      	| train loss (relative): 2.742707e-02 | valid loss (relative): 2.888240e-02 
Epoch 1195 use: 345.69 second.

epoch 1196 starting......
Epoch:  1196 | train loss: 1.399138e-03 | valid loss: 1.471017e-03 
      	| train loss (relative): 2.737910e-02 | valid loss (relative): 2.873745e-02 
Epoch 1196 use: 328.12 second.

epoch 1197 starting......
Epoch:  1197 | train loss: 1.401489e-03 | valid loss: 1.480811e-03 
      	| train loss (relative): 2.742842e-02 | valid loss (relative): 2.915740e-02 
Epoch 1197 use: 336.45 second.

epoch 1198 starting......
Epoch:  1198 | train loss: 1.404159e-03 | valid loss: 1.468530e-03 
      	| train loss (relative): 2.748245e-02 | valid loss (relative): 2.870559e-02 
Epoch 1198 use: 348.79 second.

epoch 1199 starting......
Epoch:  1199 | train loss: 1.397715e-03 | valid loss: 1.469215e-03 
      	| train loss (relative): 2.735562e-02 | valid loss (relative): 2.878388e-02 
Epoch 1199 use: 334.11 second.

epoch 1200 starting......
Epoch:  1200 | train loss: 1.397534e-03 | valid loss: 1.472551e-03 
      	| train loss (relative): 2.734665e-02 | valid loss (relative): 2.892285e-02 
Epoch 1200 use: 334.38 second.

epoch 1201 starting......
Epoch:  1201 | train loss: 1.399368e-03 | valid loss: 1.467904e-03 
      	| train loss (relative): 2.738472e-02 | valid loss (relative): 2.861633e-02 
Epoch 1201 use: 338.91 second.

epoch 1202 starting......
Epoch:  1202 | train loss: 1.395882e-03 | valid loss: 1.470765e-03 
      	| train loss (relative): 2.731176e-02 | valid loss (relative): 2.870152e-02 
Epoch 1202 use: 335.25 second.

epoch 1203 starting......
Epoch:  1203 | train loss: 1.398816e-03 | valid loss: 1.479314e-03 
      	| train loss (relative): 2.737048e-02 | valid loss (relative): 2.891386e-02 
Epoch 1203 use: 334.52 second.

epoch 1204 starting......
Epoch:  1204 | train loss: 1.402825e-03 | valid loss: 1.472467e-03 
      	| train loss (relative): 2.745485e-02 | valid loss (relative): 2.901578e-02 
Epoch 1204 use: 337.54 second.

epoch 1205 starting......
Epoch:  1205 | train loss: 1.398080e-03 | valid loss: 1.469269e-03 
      	| train loss (relative): 2.736047e-02 | valid loss (relative): 2.862077e-02 
Epoch 1205 use: 330.44 second.

epoch 1206 starting......
Epoch:  1206 | train loss: 1.394535e-03 | valid loss: 1.463824e-03 
      	| train loss (relative): 2.728545e-02 | valid loss (relative): 2.853225e-02 
Epoch 1206 use: 344.39 second.

epoch 1207 starting......
Epoch:  1207 | train loss: 1.392808e-03 | valid loss: 1.470093e-03 
      	| train loss (relative): 2.725483e-02 | valid loss (relative): 2.873718e-02 
Epoch 1207 use: 326.42 second.

epoch 1208 starting......
Epoch:  1208 | train loss: 1.395828e-03 | valid loss: 1.472853e-03 
      	| train loss (relative): 2.730928e-02 | valid loss (relative): 2.880533e-02 
Epoch 1208 use: 329.19 second.

epoch 1209 starting......
Epoch:  1209 | train loss: 1.398239e-03 | valid loss: 1.482516e-03 
      	| train loss (relative): 2.735920e-02 | valid loss (relative): 2.915501e-02 
Epoch 1209 use: 337.66 second.

epoch 1210 starting......
Epoch:  1210 | train loss: 1.399751e-03 | valid loss: 1.472504e-03 
      	| train loss (relative): 2.739092e-02 | valid loss (relative): 2.885074e-02 
Epoch 1210 use: 328.64 second.

epoch 1211 starting......
Epoch:  1211 | train loss: 1.398946e-03 | valid loss: 1.471344e-03 
      	| train loss (relative): 2.737664e-02 | valid loss (relative): 2.894032e-02 
Epoch 1211 use: 336.61 second.

epoch 1212 starting......
Epoch:  1212 | train loss: 1.399443e-03 | valid loss: 1.467471e-03 
      	| train loss (relative): 2.738928e-02 | valid loss (relative): 2.870192e-02 
Epoch 1212 use: 325.77 second.

epoch 1213 starting......
Epoch:  1213 | train loss: 1.394047e-03 | valid loss: 1.469089e-03 
      	| train loss (relative): 2.727618e-02 | valid loss (relative): 2.879332e-02 
Epoch 1213 use: 318.03 second.

epoch 1214 starting......
Epoch:  1214 | train loss: 1.395602e-03 | valid loss: 1.473931e-03 
      	| train loss (relative): 2.730855e-02 | valid loss (relative): 2.889718e-02 
Epoch 1214 use: 328.70 second.

epoch 1215 starting......
Epoch:  1215 | train loss: 1.397079e-03 | valid loss: 1.463748e-03 
      	| train loss (relative): 2.734122e-02 | valid loss (relative): 2.870266e-02 
Epoch 1215 use: 333.29 second.

epoch 1216 starting......
Epoch:  1216 | train loss: 1.391517e-03 | valid loss: 1.464557e-03 
      	| train loss (relative): 2.722247e-02 | valid loss (relative): 2.880090e-02 
Epoch 1216 use: 328.16 second.

epoch 1217 starting......
Epoch:  1217 | train loss: 1.395973e-03 | valid loss: 1.471077e-03 
      	| train loss (relative): 2.731666e-02 | valid loss (relative): 2.908272e-02 
Epoch 1217 use: 344.48 second.

epoch 1218 starting......
Epoch:  1218 | train loss: 1.389181e-03 | valid loss: 1.458949e-03 
      	| train loss (relative): 2.718620e-02 | valid loss (relative): 2.848233e-02 
Epoch 1218 use: 321.84 second.

epoch 1219 starting......
Epoch:  1219 | train loss: 1.387012e-03 | valid loss: 1.462233e-03 
      	| train loss (relative): 2.713313e-02 | valid loss (relative): 2.866415e-02 
Epoch 1219 use: 330.17 second.

epoch 1220 starting......
Epoch:  1220 | train loss: 1.386966e-03 | valid loss: 1.459494e-03 
      	| train loss (relative): 2.713611e-02 | valid loss (relative): 2.862247e-02 
Epoch 1220 use: 337.41 second.

epoch 1221 starting......
Epoch:  1221 | train loss: 1.387933e-03 | valid loss: 1.466961e-03 
      	| train loss (relative): 2.715706e-02 | valid loss (relative): 2.883825e-02 
Epoch 1221 use: 322.14 second.

epoch 1222 starting......
Epoch:  1222 | train loss: 1.390784e-03 | valid loss: 1.460020e-03 
      	| train loss (relative): 2.721495e-02 | valid loss (relative): 2.858726e-02 
Epoch 1222 use: 325.54 second.

epoch 1223 starting......
Epoch:  1223 | train loss: 1.387083e-03 | valid loss: 1.465329e-03 
      	| train loss (relative): 2.713713e-02 | valid loss (relative): 2.856350e-02 
Epoch 1223 use: 334.06 second.

epoch 1224 starting......
Epoch:  1224 | train loss: 1.390068e-03 | valid loss: 1.458730e-03 
      	| train loss (relative): 2.719736e-02 | valid loss (relative): 2.865874e-02 
Epoch 1224 use: 325.97 second.

epoch 1225 starting......
Epoch:  1225 | train loss: 1.385878e-03 | valid loss: 1.459396e-03 
      	| train loss (relative): 2.711346e-02 | valid loss (relative): 2.855832e-02 
Epoch 1225 use: 328.72 second.

epoch 1226 starting......
Epoch:  1226 | train loss: 1.389143e-03 | valid loss: 1.464981e-03 
      	| train loss (relative): 2.718239e-02 | valid loss (relative): 2.867243e-02 
Epoch 1226 use: 328.30 second.

epoch 1227 starting......
Epoch:  1227 | train loss: 1.389663e-03 | valid loss: 1.465553e-03 
      	| train loss (relative): 2.719010e-02 | valid loss (relative): 2.858543e-02 
Epoch 1227 use: 346.02 second.

epoch 1228 starting......
Epoch:  1228 | train loss: 1.388851e-03 | valid loss: 1.464774e-03 
      	| train loss (relative): 2.717326e-02 | valid loss (relative): 2.863964e-02 
Epoch 1228 use: 336.33 second.

epoch 1229 starting......
Epoch:  1229 | train loss: 1.389491e-03 | valid loss: 1.463067e-03 
      	| train loss (relative): 2.718411e-02 | valid loss (relative): 2.870033e-02 
Epoch 1229 use: 329.56 second.

epoch 1230 starting......
Epoch:  1230 | train loss: 1.388545e-03 | valid loss: 1.468748e-03 
      	| train loss (relative): 2.716776e-02 | valid loss (relative): 2.881160e-02 
Epoch 1230 use: 323.65 second.

epoch 1231 starting......
Epoch:  1231 | train loss: 1.389761e-03 | valid loss: 1.462162e-03 
      	| train loss (relative): 2.719100e-02 | valid loss (relative): 2.853136e-02 
Epoch 1231 use: 321.68 second.

epoch 1232 starting......
Epoch:  1232 | train loss: 1.386665e-03 | valid loss: 1.462244e-03 
      	| train loss (relative): 2.713138e-02 | valid loss (relative): 2.867639e-02 
Epoch 1232 use: 326.62 second.

epoch 1233 starting......
Epoch:  1233 | train loss: 1.387597e-03 | valid loss: 1.462108e-03 
      	| train loss (relative): 2.714894e-02 | valid loss (relative): 2.882334e-02 
Epoch 1233 use: 313.88 second.

epoch 1234 starting......
Epoch:  1234 | train loss: 1.387434e-03 | valid loss: 1.466655e-03 
      	| train loss (relative): 2.714991e-02 | valid loss (relative): 2.864439e-02 
Epoch 1234 use: 319.77 second.

epoch 1235 starting......
Epoch:  1235 | train loss: 1.389844e-03 | valid loss: 1.467166e-03 
      	| train loss (relative): 2.719201e-02 | valid loss (relative): 2.867318e-02 
Epoch 1235 use: 341.77 second.

epoch 1236 starting......
Epoch:  1236 | train loss: 1.388810e-03 | valid loss: 1.467212e-03 
      	| train loss (relative): 2.717365e-02 | valid loss (relative): 2.858935e-02 
Epoch 1236 use: 336.99 second.

epoch 1237 starting......
Epoch:  1237 | train loss: 1.390252e-03 | valid loss: 1.475052e-03 
      	| train loss (relative): 2.720099e-02 | valid loss (relative): 2.873092e-02 
Epoch 1237 use: 325.40 second.

epoch 1238 starting......
Epoch:  1238 | train loss: 1.391111e-03 | valid loss: 1.463340e-03 
      	| train loss (relative): 2.721589e-02 | valid loss (relative): 2.855164e-02 
Epoch 1238 use: 342.31 second.

epoch 1239 starting......
Epoch:  1239 | train loss: 1.386718e-03 | valid loss: 1.461270e-03 
      	| train loss (relative): 2.713034e-02 | valid loss (relative): 2.856589e-02 
Epoch 1239 use: 319.44 second.

epoch 1240 starting......
Epoch:  1240 | train loss: 1.385886e-03 | valid loss: 1.461851e-03 
      	| train loss (relative): 2.711250e-02 | valid loss (relative): 2.856942e-02 
Epoch 1240 use: 327.24 second.

epoch 1241 starting......
Epoch:  1241 | train loss: 1.386092e-03 | valid loss: 1.464265e-03 
      	| train loss (relative): 2.711914e-02 | valid loss (relative): 2.871503e-02 
Epoch 1241 use: 336.01 second.

epoch 1242 starting......
Epoch:  1242 | train loss: 1.388816e-03 | valid loss: 1.464643e-03 
      	| train loss (relative): 2.717423e-02 | valid loss (relative): 2.870797e-02 
Epoch 1242 use: 331.86 second.

epoch 1243 starting......
Epoch:  1243 | train loss: 1.386451e-03 | valid loss: 1.467247e-03 
      	| train loss (relative): 2.712422e-02 | valid loss (relative): 2.872614e-02 
Epoch 1243 use: 322.44 second.

epoch 1244 starting......
Epoch:  1244 | train loss: 1.390304e-03 | valid loss: 1.476132e-03 
      	| train loss (relative): 2.720717e-02 | valid loss (relative): 2.900531e-02 
Epoch 1244 use: 336.21 second.

epoch 1245 starting......
Epoch:  1245 | train loss: 1.392242e-03 | valid loss: 1.474554e-03 
      	| train loss (relative): 2.724142e-02 | valid loss (relative): 2.890064e-02 
Epoch 1245 use: 327.04 second.

epoch 1246 starting......
Epoch:  1246 | train loss: 1.387933e-03 | valid loss: 1.464278e-03 
      	| train loss (relative): 2.716026e-02 | valid loss (relative): 2.871419e-02 
Epoch 1246 use: 330.71 second.

epoch 1247 starting......
Epoch:  1247 | train loss: 1.390455e-03 | valid loss: 1.467045e-03 
      	| train loss (relative): 2.720304e-02 | valid loss (relative): 2.865503e-02 
Epoch 1247 use: 346.04 second.

epoch 1248 starting......
Epoch:  1248 | train loss: 1.385792e-03 | valid loss: 1.464281e-03 
      	| train loss (relative): 2.711511e-02 | valid loss (relative): 2.867967e-02 
Epoch 1248 use: 322.62 second.

epoch 1249 starting......
Epoch:  1249 | train loss: 1.385655e-03 | valid loss: 1.459607e-03 
      	| train loss (relative): 2.710686e-02 | valid loss (relative): 2.853574e-02 
Epoch 1249 use: 341.72 second.

epoch 1250 starting......
Epoch:  1250 | train loss: 1.382059e-03 | valid loss: 1.459737e-03 
      	| train loss (relative): 2.703639e-02 | valid loss (relative): 2.865666e-02 
Epoch 1250 use: 327.05 second.

epoch 1251 starting......
Epoch:  1251 | train loss: 1.383325e-03 | valid loss: 1.466439e-03 
      	| train loss (relative): 2.706284e-02 | valid loss (relative): 2.873112e-02 
Epoch 1251 use: 326.56 second.

epoch 1252 starting......
Epoch:  1252 | train loss: 1.388731e-03 | valid loss: 1.462146e-03 
      	| train loss (relative): 2.717152e-02 | valid loss (relative): 2.844790e-02 
Epoch 1252 use: 325.99 second.

epoch 1253 starting......
Epoch:  1253 | train loss: 1.385264e-03 | valid loss: 1.468907e-03 
      	| train loss (relative): 2.710004e-02 | valid loss (relative): 2.875037e-02 
Epoch 1253 use: 319.69 second.

epoch 1254 starting......
Epoch:  1254 | train loss: 1.386527e-03 | valid loss: 1.465702e-03 
      	| train loss (relative): 2.712443e-02 | valid loss (relative): 2.871591e-02 
Epoch 1254 use: 320.96 second.

epoch 1255 starting......
Epoch:  1255 | train loss: 1.387003e-03 | valid loss: 1.462901e-03 
      	| train loss (relative): 2.713619e-02 | valid loss (relative): 2.877128e-02 
Epoch 1255 use: 323.05 second.

epoch 1256 starting......
Epoch:  1256 | train loss: 1.387826e-03 | valid loss: 1.465442e-03 
      	| train loss (relative): 2.715337e-02 | valid loss (relative): 2.868385e-02 
Epoch 1256 use: 335.05 second.

epoch 1257 starting......
Epoch:  1257 | train loss: 1.385572e-03 | valid loss: 1.463761e-03 
      	| train loss (relative): 2.711088e-02 | valid loss (relative): 2.856562e-02 
Epoch 1257 use: 326.04 second.

epoch 1258 starting......
Epoch:  1258 | train loss: 1.385757e-03 | valid loss: 1.467303e-03 
      	| train loss (relative): 2.710839e-02 | valid loss (relative): 2.884070e-02 
Epoch 1258 use: 345.61 second.

epoch 1259 starting......
Epoch:  1259 | train loss: 1.387531e-03 | valid loss: 1.465704e-03 
      	| train loss (relative): 2.714658e-02 | valid loss (relative): 2.868439e-02 
Epoch 1259 use: 329.93 second.

epoch 1260 starting......
Epoch:  1260 | train loss: 1.387820e-03 | valid loss: 1.466597e-03 
      	| train loss (relative): 2.714976e-02 | valid loss (relative): 2.872856e-02 
Epoch 1260 use: 319.47 second.

epoch 1261 starting......
Epoch:  1261 | train loss: 1.384835e-03 | valid loss: 1.462217e-03 
      	| train loss (relative): 2.709184e-02 | valid loss (relative): 2.863136e-02 
Epoch 1261 use: 337.27 second.

epoch 1262 starting......
Epoch:  1262 | train loss: 1.385348e-03 | valid loss: 1.461345e-03 
      	| train loss (relative): 2.710098e-02 | valid loss (relative): 2.858353e-02 
Epoch 1262 use: 351.30 second.

epoch 1263 starting......
Epoch:  1263 | train loss: 1.384236e-03 | valid loss: 1.465955e-03 
      	| train loss (relative): 2.708130e-02 | valid loss (relative): 2.865083e-02 
Epoch 1263 use: 340.16 second.

epoch 1264 starting......
Epoch:  1264 | train loss: 1.388202e-03 | valid loss: 1.467230e-03 
      	| train loss (relative): 2.715854e-02 | valid loss (relative): 2.880686e-02 
Epoch 1264 use: 358.59 second.

epoch 1265 starting......
Epoch:  1265 | train loss: 1.385922e-03 | valid loss: 1.466926e-03 
      	| train loss (relative): 2.711162e-02 | valid loss (relative): 2.876981e-02 
Epoch 1265 use: 327.65 second.

epoch 1266 starting......
Epoch:  1266 | train loss: 1.383947e-03 | valid loss: 1.457438e-03 
      	| train loss (relative): 2.707487e-02 | valid loss (relative): 2.854827e-02 
Epoch 1266 use: 329.17 second.

epoch 1267 starting......
Epoch:  1267 | train loss: 1.381055e-03 | valid loss: 1.459051e-03 
      	| train loss (relative): 2.701944e-02 | valid loss (relative): 2.864202e-02 
Epoch 1267 use: 325.09 second.

epoch 1268 starting......
Epoch:  1268 | train loss: 1.380131e-03 | valid loss: 1.457075e-03 
      	| train loss (relative): 2.699628e-02 | valid loss (relative): 2.844639e-02 
Epoch 1268 use: 328.53 second.

epoch 1269 starting......
Epoch:  1269 | train loss: 1.381494e-03 | valid loss: 1.462112e-03 
      	| train loss (relative): 2.702546e-02 | valid loss (relative): 2.853500e-02 
Epoch 1269 use: 353.72 second.

epoch 1270 starting......
Epoch:  1270 | train loss: 1.386043e-03 | valid loss: 1.474816e-03 
      	| train loss (relative): 2.711238e-02 | valid loss (relative): 2.886874e-02 
Epoch 1270 use: 340.84 second.

epoch 1271 starting......
Epoch:  1271 | train loss: 1.386627e-03 | valid loss: 1.463487e-03 
      	| train loss (relative): 2.712593e-02 | valid loss (relative): 2.857292e-02 
Epoch 1271 use: 335.06 second.

epoch 1272 starting......
Epoch:  1272 | train loss: 1.384547e-03 | valid loss: 1.462279e-03 
      	| train loss (relative): 2.708892e-02 | valid loss (relative): 2.865740e-02 
Epoch 1272 use: 330.77 second.

epoch 1273 starting......
Epoch:  1273 | train loss: 1.385505e-03 | valid loss: 1.465877e-03 
      	| train loss (relative): 2.710632e-02 | valid loss (relative): 2.862630e-02 
Epoch 1273 use: 336.91 second.

epoch 1274 starting......
Epoch:  1274 | train loss: 1.384390e-03 | valid loss: 1.464886e-03 
      	| train loss (relative): 2.708432e-02 | valid loss (relative): 2.872809e-02 
Epoch 1274 use: 347.20 second.

epoch 1275 starting......
Epoch:  1275 | train loss: 1.383286e-03 | valid loss: 1.461640e-03 
      	| train loss (relative): 2.706010e-02 | valid loss (relative): 2.842133e-02 
Epoch 1275 use: 338.93 second.

epoch 1276 starting......
Epoch:  1276 | train loss: 1.380969e-03 | valid loss: 1.460737e-03 
      	| train loss (relative): 2.701402e-02 | valid loss (relative): 2.859883e-02 
Epoch 1276 use: 325.49 second.

epoch 1277 starting......
Epoch:  1277 | train loss: 1.380553e-03 | valid loss: 1.455162e-03 
      	| train loss (relative): 2.700863e-02 | valid loss (relative): 2.838902e-02 
Epoch 1277 use: 340.68 second.

epoch 1278 starting......
Epoch:  1278 | train loss: 1.379656e-03 | valid loss: 1.462965e-03 
      	| train loss (relative): 2.698857e-02 | valid loss (relative): 2.875700e-02 
Epoch 1278 use: 344.15 second.

epoch 1279 starting......
Epoch:  1279 | train loss: 1.379358e-03 | valid loss: 1.472105e-03 
      	| train loss (relative): 2.698530e-02 | valid loss (relative): 2.889021e-02 
Epoch 1279 use: 348.65 second.

epoch 1280 starting......
Epoch:  1280 | train loss: 1.383506e-03 | valid loss: 1.466253e-03 
      	| train loss (relative): 2.706595e-02 | valid loss (relative): 2.872013e-02 
Epoch 1280 use: 351.32 second.

epoch 1281 starting......
Epoch:  1281 | train loss: 1.382418e-03 | valid loss: 1.463148e-03 
      	| train loss (relative): 2.704584e-02 | valid loss (relative): 2.864271e-02 
Epoch 1281 use: 338.70 second.

epoch 1282 starting......
Epoch:  1282 | train loss: 1.383224e-03 | valid loss: 1.460901e-03 
      	| train loss (relative): 2.705791e-02 | valid loss (relative): 2.864382e-02 
Epoch 1282 use: 344.48 second.

epoch 1283 starting......
Epoch:  1283 | train loss: 1.381556e-03 | valid loss: 1.461405e-03 
      	| train loss (relative): 2.702677e-02 | valid loss (relative): 2.865796e-02 
Epoch 1283 use: 332.51 second.

epoch 1284 starting......
Epoch:  1284 | train loss: 1.380595e-03 | valid loss: 1.457482e-03 
      	| train loss (relative): 2.700932e-02 | valid loss (relative): 2.835277e-02 
Epoch 1284 use: 332.47 second.

epoch 1285 starting......
Epoch:  1285 | train loss: 1.376046e-03 | valid loss: 1.450106e-03 
      	| train loss (relative): 2.691555e-02 | valid loss (relative): 2.832966e-02 
Epoch 1285 use: 331.82 second.

epoch 1286 starting......
Epoch:  1286 | train loss: 1.373203e-03 | valid loss: 1.452837e-03 
      	| train loss (relative): 2.686364e-02 | valid loss (relative): 2.843899e-02 
Epoch 1286 use: 347.59 second.

epoch 1287 starting......
Epoch:  1287 | train loss: 1.371563e-03 | valid loss: 1.452236e-03 
      	| train loss (relative): 2.682930e-02 | valid loss (relative): 2.841865e-02 
Epoch 1287 use: 333.42 second.

epoch 1288 starting......
Epoch:  1288 | train loss: 1.372469e-03 | valid loss: 1.451624e-03 
      	| train loss (relative): 2.684267e-02 | valid loss (relative): 2.839139e-02 
Epoch 1288 use: 348.29 second.

epoch 1289 starting......
Epoch:  1289 | train loss: 1.375809e-03 | valid loss: 1.454321e-03 
      	| train loss (relative): 2.691325e-02 | valid loss (relative): 2.839890e-02 
Epoch 1289 use: 344.81 second.

epoch 1290 starting......
Epoch:  1290 | train loss: 1.375832e-03 | valid loss: 1.459601e-03 
      	| train loss (relative): 2.691256e-02 | valid loss (relative): 2.856804e-02 
Epoch 1290 use: 328.93 second.

epoch 1291 starting......
Epoch:  1291 | train loss: 1.377812e-03 | valid loss: 1.455591e-03 
      	| train loss (relative): 2.695129e-02 | valid loss (relative): 2.839105e-02 
Epoch 1291 use: 347.56 second.

epoch 1292 starting......
Epoch:  1292 | train loss: 1.372669e-03 | valid loss: 1.451433e-03 
      	| train loss (relative): 2.684790e-02 | valid loss (relative): 2.848982e-02 
Epoch 1292 use: 345.23 second.

epoch 1293 starting......
Epoch:  1293 | train loss: 1.372392e-03 | valid loss: 1.452060e-03 
      	| train loss (relative): 2.684614e-02 | valid loss (relative): 2.837620e-02 
Epoch 1293 use: 345.66 second.

epoch 1294 starting......
Epoch:  1294 | train loss: 1.376081e-03 | valid loss: 1.456500e-03 
      	| train loss (relative): 2.691699e-02 | valid loss (relative): 2.848757e-02 
Epoch 1294 use: 342.03 second.

epoch 1295 starting......
Epoch:  1295 | train loss: 1.379625e-03 | valid loss: 1.464569e-03 
      	| train loss (relative): 2.698787e-02 | valid loss (relative): 2.893460e-02 
Epoch 1295 use: 323.75 second.

epoch 1296 starting......
Epoch:  1296 | train loss: 1.380733e-03 | valid loss: 1.459510e-03 
      	| train loss (relative): 2.700930e-02 | valid loss (relative): 2.860420e-02 
Epoch 1296 use: 336.08 second.

epoch 1297 starting......
Epoch:  1297 | train loss: 1.379971e-03 | valid loss: 1.460901e-03 
      	| train loss (relative): 2.699522e-02 | valid loss (relative): 2.854181e-02 
Epoch 1297 use: 319.81 second.

epoch 1298 starting......
Epoch:  1298 | train loss: 1.377731e-03 | valid loss: 1.460381e-03 
      	| train loss (relative): 2.695358e-02 | valid loss (relative): 2.858592e-02 
Epoch 1298 use: 336.56 second.

epoch 1299 starting......
Epoch:  1299 | train loss: 1.379328e-03 | valid loss: 1.458759e-03 
      	| train loss (relative): 2.697795e-02 | valid loss (relative): 2.849108e-02 
Epoch 1299 use: 328.53 second.

test MSE Error: 1.400727e-03 | relative MSE Error: 2.734444e-02 
 Total time used for training: 14.21 hour.
MESLoss saved to  /rds/general/user/jy220/home/new_results/Variational_False_Changelr_False_MSELoss_Latent_256_nearest_neighbouring_True_SFC_nums_3_startlr_0.001_n_epoches_1300.txt
relative MSELoss saved to  /rds/general/user/jy220/home/new_results/Variational_False_Changelr_False_reMSELoss_Latent_256_nearest_neighbouring_True_SFC_nums_3_startlr_0.001_n_epoches_1300.txt
model saved to /rds/general/user/jy220/home/new_results/Variational_False_Changelr_False_Latent_256_Nearest_neighbouring_True_SFC_nums_3_startlr_0.001_n_epoches_1300.pth
model_dict saved to /rds/general/user/jy220/home/new_results/Variational_False_Changelr_False_Latent_256_Nearest_neighbouring_True_SFC_nums_3_startlr_0.001_n_epoches_1300_dict.pth
... Training slugflow data completed, Run finished Mon 23 Aug 06:05:20 BST 2021 ...
{'data_dir': '/rds/general/user/jy220/home/tensors/', 'data_type': 'tensors', 'mode': 'train', 'vtu_fields': 'Component1::ComponentMassFractionPhase1, phase1::Velocity', 'variational': 'False', 'optimizer': 'Adamax', 'structured': 'False', 'changing_lr': 'False', 'self_concat': '2', 'dimension': '3', 'sfc_nums': '3', 'components': '4', 'nearest_neighbouring': 'True', 'dims_latent': '256', 'activation': 'Tanh', 'tk_file': '/rds/general/user/jy220/home/slugflow_tk.pt', 'tb_file': '/rds/general/user/jy220/home/slugflow_tb.pt', 'sfc_file': '/rds/general/user/jy220/home/SFC-CAE-Ready-to-use/sfcs.pt', 'inv_sfc_file': '/rds/general/user/jy220/home/SFC-CAE-Ready-to-use/inv_sfcs.pt', 'coords_file': '/rds/general/user/jy220/home/SFC-CAE-Ready-to-use/coords.pt', 'cells_file': '/rds/general/user/jy220/home/SFC-CAE-Ready-to-use/cells.npy', 'state_load': '/rds/general/user/jy220/home/new_results/Variational_False_Changelr_False_Latent_256_Nearest_neighbouring_True_SFC_nums_3_startlr_0.001_n_epoches_1300_dict.pth', 'batch_size': '16', 'lr': '0.001', 'n_epoches': '150', 'seed': '17', 'visualize': 'False', 'reconstructed_path': 'None', 'reconstruct_start_index': '0', 'reconstruct_end_index': '50', 'save_path': '/rds/general/user/jy220/home/new_results/'}
[[ 2.50825269e-01 -1.67256990e-02 -1.22268730e-03]
 [ 2.38611959e-01 -5.50627777e-03 -5.06451913e-03]
 [ 2.39454874e-01 -1.59563257e-02  3.96778323e-03]
 ...
 [ 9.11361096e+00 -2.21908381e-02  2.22384902e-03]
 [ 9.11847310e+00 -2.84346931e-02 -2.34839590e-04]
 [ 9.11039661e+00 -2.51498573e-02 -8.70661044e-03]]
{'tetra': array([[      0,       1,       2,       3],
       [      4,       5,       6,       7],
       [      8,       9,      10,      11],
       ...,
       [1342744, 1342745, 1342746, 1342747],
       [1342748, 1342749, 1342750, 1342751],
       [1342752, 1342753, 1342754, 1342755]])}
vtu fields:  ['Component1::ComponentMassFractionPhase1', 'phase1::Velocity'] 
 structured  False 
 activation  Tanh() 
 self concat  2 
 sfc_nums  3 

dims_latent  256 
 components  4 
 nearest_neighbouring  True 

visualize  False 
 sample number  1706 

reading sfc nums......
[array([  41684,   41685,   41674, ..., 1235560, 1235564, 1235558]), array([954289, 954290, 954291, ..., 420685, 420687, 420688]), array([  40156,   40155,   40158, ..., 1123478, 1123475, 1123467])]
reading inverse sfc nums......
[array([   8146,    8145,    8144, ..., 1274444, 1274445, 1273166]), array([547280, 547283, 593037, ..., 933933, 933932, 864488]), array([ 66437,  66439, 122512, ..., 459416, 415130, 459418])]
tk:  tensor([0.7581, 0.0418, 0.1840, 0.1464], dtype=torch.float64) 

tb:  tensor([-0.3816, -0.3618, -0.0308,  0.1446], dtype=torch.float64) 

length of train set: 1505 

length of valid set: 100 

length of test set: 101 

torch device num: 4 

Let's use 4 GPUs!
epoch 1300 starting......
Epoch:  1300 | train loss: 1.563247e-03 | valid loss: 1.400689e-03 
      	| train loss (relative): 3.065396e-02 | valid loss (relative): 2.743630e-02 
Epoch 1300 use: 464.87 second.

epoch 1301 starting......
Epoch:  1301 | train loss: 1.373331e-03 | valid loss: 1.386390e-03 
      	| train loss (relative): 2.686165e-02 | valid loss (relative): 2.715049e-02 
Epoch 1301 use: 457.22 second.

epoch 1302 starting......
Epoch:  1302 | train loss: 1.364373e-03 | valid loss: 1.382939e-03 
      	| train loss (relative): 2.668090e-02 | valid loss (relative): 2.708753e-02 
Epoch 1302 use: 460.01 second.

epoch 1303 starting......
Epoch:  1303 | train loss: 1.361458e-03 | valid loss: 1.383923e-03 
      	| train loss (relative): 2.662180e-02 | valid loss (relative): 2.707309e-02 
Epoch 1303 use: 440.77 second.

epoch 1304 starting......
Epoch:  1304 | train loss: 1.360413e-03 | valid loss: 1.383874e-03 
      	| train loss (relative): 2.659845e-02 | valid loss (relative): 2.710178e-02 
Epoch 1304 use: 372.37 second.

epoch 1305 starting......
Epoch:  1305 | train loss: 1.360964e-03 | valid loss: 1.386043e-03 
      	| train loss (relative): 2.661173e-02 | valid loss (relative): 2.711580e-02 
Epoch 1305 use: 359.25 second.

epoch 1306 starting......
Epoch:  1306 | train loss: 1.360712e-03 | valid loss: 1.387191e-03 
      	| train loss (relative): 2.660645e-02 | valid loss (relative): 2.713795e-02 
Epoch 1306 use: 366.30 second.

epoch 1307 starting......
Epoch:  1307 | train loss: 1.362285e-03 | valid loss: 1.392193e-03 
      	| train loss (relative): 2.663705e-02 | valid loss (relative): 2.725575e-02 
Epoch 1307 use: 372.64 second.

epoch 1308 starting......
Epoch:  1308 | train loss: 1.366837e-03 | valid loss: 1.394104e-03 
      	| train loss (relative): 2.672886e-02 | valid loss (relative): 2.728845e-02 
Epoch 1308 use: 364.65 second.

epoch 1309 starting......
Epoch:  1309 | train loss: 1.367248e-03 | valid loss: 1.400156e-03 
      	| train loss (relative): 2.673548e-02 | valid loss (relative): 2.743039e-02 
Epoch 1309 use: 363.11 second.

epoch 1310 starting......
Epoch:  1310 | train loss: 1.368653e-03 | valid loss: 1.396166e-03 
      	| train loss (relative): 2.676240e-02 | valid loss (relative): 2.733330e-02 
Epoch 1310 use: 362.90 second.

epoch 1311 starting......
Epoch:  1311 | train loss: 1.368623e-03 | valid loss: 1.400255e-03 
      	| train loss (relative): 2.676144e-02 | valid loss (relative): 2.743608e-02 
Epoch 1311 use: 349.56 second.

epoch 1312 starting......
Epoch:  1312 | train loss: 1.373123e-03 | valid loss: 1.403572e-03 
      	| train loss (relative): 2.685344e-02 | valid loss (relative): 2.747276e-02 
Epoch 1312 use: 356.37 second.

epoch 1313 starting......
Epoch:  1313 | train loss: 1.368763e-03 | valid loss: 1.401116e-03 
      	| train loss (relative): 2.676355e-02 | valid loss (relative): 2.747880e-02 
Epoch 1313 use: 374.54 second.

epoch 1314 starting......
Epoch:  1314 | train loss: 1.367957e-03 | valid loss: 1.403251e-03 
      	| train loss (relative): 2.674700e-02 | valid loss (relative): 2.747346e-02 
Epoch 1314 use: 361.24 second.

epoch 1315 starting......
Epoch:  1315 | train loss: 1.370264e-03 | valid loss: 1.405163e-03 
      	| train loss (relative): 2.679640e-02 | valid loss (relative): 2.748190e-02 
Epoch 1315 use: 364.68 second.

epoch 1316 starting......
Epoch:  1316 | train loss: 1.369045e-03 | valid loss: 1.402865e-03 
      	| train loss (relative): 2.676936e-02 | valid loss (relative): 2.749098e-02 
Epoch 1316 use: 366.93 second.

epoch 1317 starting......
Epoch:  1317 | train loss: 1.370425e-03 | valid loss: 1.403675e-03 
      	| train loss (relative): 2.679611e-02 | valid loss (relative): 2.752473e-02 
Epoch 1317 use: 349.27 second.

epoch 1318 starting......
Epoch:  1318 | train loss: 1.371778e-03 | valid loss: 1.411645e-03 
      	| train loss (relative): 2.682225e-02 | valid loss (relative): 2.763988e-02 
Epoch 1318 use: 365.72 second.

epoch 1319 starting......
Epoch:  1319 | train loss: 1.375292e-03 | valid loss: 1.407168e-03 
      	| train loss (relative): 2.689337e-02 | valid loss (relative): 2.749168e-02 
Epoch 1319 use: 366.08 second.

epoch 1320 starting......
Epoch:  1320 | train loss: 1.372017e-03 | valid loss: 1.407070e-03 
      	| train loss (relative): 2.682752e-02 | valid loss (relative): 2.761702e-02 
Epoch 1320 use: 353.79 second.

epoch 1321 starting......
Epoch:  1321 | train loss: 1.371856e-03 | valid loss: 1.407651e-03 
      	| train loss (relative): 2.682508e-02 | valid loss (relative): 2.755013e-02 
Epoch 1321 use: 356.94 second.

epoch 1322 starting......
Epoch:  1322 | train loss: 1.369319e-03 | valid loss: 1.405973e-03 
      	| train loss (relative): 2.677464e-02 | valid loss (relative): 2.753666e-02 
Epoch 1322 use: 373.48 second.

epoch 1323 starting......
Epoch:  1323 | train loss: 1.370729e-03 | valid loss: 1.407952e-03 
      	| train loss (relative): 2.680328e-02 | valid loss (relative): 2.755656e-02 
Epoch 1323 use: 382.55 second.

epoch 1324 starting......
Epoch:  1324 | train loss: 1.370923e-03 | valid loss: 1.406737e-03 
      	| train loss (relative): 2.680651e-02 | valid loss (relative): 2.746523e-02 
Epoch 1324 use: 360.79 second.

epoch 1325 starting......
Epoch:  1325 | train loss: 1.371140e-03 | valid loss: 1.411719e-03 
      	| train loss (relative): 2.681149e-02 | valid loss (relative): 2.768691e-02 
Epoch 1325 use: 360.11 second.

epoch 1326 starting......
Epoch:  1326 | train loss: 1.371960e-03 | valid loss: 1.410661e-03 
      	| train loss (relative): 2.682310e-02 | valid loss (relative): 2.767043e-02 
Epoch 1326 use: 359.29 second.

epoch 1327 starting......
Epoch:  1327 | train loss: 1.371219e-03 | valid loss: 1.409639e-03 
      	| train loss (relative): 2.681498e-02 | valid loss (relative): 2.767026e-02 
Epoch 1327 use: 355.69 second.

epoch 1328 starting......
Epoch:  1328 | train loss: 1.368374e-03 | valid loss: 1.405574e-03 
      	| train loss (relative): 2.675382e-02 | valid loss (relative): 2.734500e-02 
Epoch 1328 use: 360.22 second.

epoch 1329 starting......
Epoch:  1329 | train loss: 1.369452e-03 | valid loss: 1.408382e-03 
      	| train loss (relative): 2.677512e-02 | valid loss (relative): 2.758086e-02 
Epoch 1329 use: 363.32 second.

epoch 1330 starting......
Epoch:  1330 | train loss: 1.369902e-03 | valid loss: 1.415075e-03 
      	| train loss (relative): 2.678447e-02 | valid loss (relative): 2.760753e-02 
Epoch 1330 use: 360.32 second.

epoch 1331 starting......
Epoch:  1331 | train loss: 1.370233e-03 | valid loss: 1.413618e-03 
      	| train loss (relative): 2.678992e-02 | valid loss (relative): 2.768872e-02 
Epoch 1331 use: 368.69 second.

epoch 1332 starting......
Epoch:  1332 | train loss: 1.370796e-03 | valid loss: 1.406635e-03 
      	| train loss (relative): 2.680570e-02 | valid loss (relative): 2.758490e-02 
Epoch 1332 use: 363.26 second.

epoch 1333 starting......
Epoch:  1333 | train loss: 1.365990e-03 | valid loss: 1.402452e-03 
      	| train loss (relative): 2.670744e-02 | valid loss (relative): 2.749049e-02 
Epoch 1333 use: 359.29 second.

epoch 1334 starting......
Epoch:  1334 | train loss: 1.363474e-03 | valid loss: 1.401355e-03 
      	| train loss (relative): 2.666044e-02 | valid loss (relative): 2.739059e-02 
Epoch 1334 use: 357.18 second.

epoch 1335 starting......
Epoch:  1335 | train loss: 1.361920e-03 | valid loss: 1.406339e-03 
      	| train loss (relative): 2.662426e-02 | valid loss (relative): 2.763726e-02 
Epoch 1335 use: 355.97 second.

epoch 1336 starting......
Epoch:  1336 | train loss: 1.364430e-03 | valid loss: 1.407162e-03 
      	| train loss (relative): 2.667481e-02 | valid loss (relative): 2.751762e-02 
Epoch 1336 use: 357.24 second.

epoch 1337 starting......
Epoch:  1337 | train loss: 1.366311e-03 | valid loss: 1.404262e-03 
      	| train loss (relative): 2.671270e-02 | valid loss (relative): 2.754801e-02 
Epoch 1337 use: 368.29 second.

epoch 1338 starting......
Epoch:  1338 | train loss: 1.364955e-03 | valid loss: 1.404129e-03 
      	| train loss (relative): 2.668285e-02 | valid loss (relative): 2.758442e-02 
Epoch 1338 use: 354.51 second.

epoch 1339 starting......
Epoch:  1339 | train loss: 1.363166e-03 | valid loss: 1.414374e-03 
      	| train loss (relative): 2.665145e-02 | valid loss (relative): 2.776084e-02 
Epoch 1339 use: 351.97 second.

epoch 1340 starting......
Epoch:  1340 | train loss: 1.364839e-03 | valid loss: 1.403053e-03 
      	| train loss (relative): 2.668617e-02 | valid loss (relative): 2.753300e-02 
Epoch 1340 use: 372.30 second.

epoch 1341 starting......
Epoch:  1341 | train loss: 1.364904e-03 | valid loss: 1.409099e-03 
      	| train loss (relative): 2.668576e-02 | valid loss (relative): 2.745497e-02 
Epoch 1341 use: 362.99 second.

epoch 1342 starting......
Epoch:  1342 | train loss: 1.364722e-03 | valid loss: 1.408375e-03 
      	| train loss (relative): 2.667960e-02 | valid loss (relative): 2.762415e-02 
Epoch 1342 use: 365.59 second.

epoch 1343 starting......
Epoch:  1343 | train loss: 1.365665e-03 | valid loss: 1.412032e-03 
      	| train loss (relative): 2.669868e-02 | valid loss (relative): 2.787635e-02 
Epoch 1343 use: 374.95 second.

epoch 1344 starting......
Epoch:  1344 | train loss: 1.365149e-03 | valid loss: 1.410455e-03 
      	| train loss (relative): 2.668888e-02 | valid loss (relative): 2.755480e-02 
Epoch 1344 use: 360.30 second.

epoch 1345 starting......
Epoch:  1345 | train loss: 1.367301e-03 | valid loss: 1.406862e-03 
      	| train loss (relative): 2.673592e-02 | valid loss (relative): 2.750743e-02 
Epoch 1345 use: 359.01 second.

epoch 1346 starting......
Epoch:  1346 | train loss: 1.363030e-03 | valid loss: 1.404867e-03 
      	| train loss (relative): 2.664755e-02 | valid loss (relative): 2.754418e-02 
Epoch 1346 use: 351.77 second.

epoch 1347 starting......
Epoch:  1347 | train loss: 1.362462e-03 | valid loss: 1.410489e-03 
      	| train loss (relative): 2.663383e-02 | valid loss (relative): 2.763353e-02 
Epoch 1347 use: 360.67 second.

epoch 1348 starting......
Epoch:  1348 | train loss: 1.364813e-03 | valid loss: 1.409222e-03 
      	| train loss (relative): 2.668470e-02 | valid loss (relative): 2.765205e-02 
Epoch 1348 use: 357.12 second.

epoch 1349 starting......
Epoch:  1349 | train loss: 1.365008e-03 | valid loss: 1.405291e-03 
      	| train loss (relative): 2.668935e-02 | valid loss (relative): 2.766108e-02 
Epoch 1349 use: 352.82 second.

epoch 1350 starting......
Epoch:  1350 | train loss: 1.362141e-03 | valid loss: 1.409373e-03 
      	| train loss (relative): 2.663045e-02 | valid loss (relative): 2.756182e-02 
Epoch 1350 use: 340.01 second.

epoch 1351 starting......
Epoch:  1351 | train loss: 1.362644e-03 | valid loss: 1.408184e-03 
      	| train loss (relative): 2.664353e-02 | valid loss (relative): 2.746867e-02 
Epoch 1351 use: 370.67 second.

epoch 1352 starting......
Epoch:  1352 | train loss: 1.361843e-03 | valid loss: 1.402774e-03 
      	| train loss (relative): 2.663110e-02 | valid loss (relative): 2.744427e-02 
Epoch 1352 use: 359.73 second.

epoch 1353 starting......
Epoch:  1353 | train loss: 1.359018e-03 | valid loss: 1.400759e-03 
      	| train loss (relative): 2.656718e-02 | valid loss (relative): 2.752495e-02 
Epoch 1353 use: 355.14 second.

epoch 1354 starting......
Epoch:  1354 | train loss: 1.358060e-03 | valid loss: 1.401652e-03 
      	| train loss (relative): 2.654952e-02 | valid loss (relative): 2.754829e-02 
Epoch 1354 use: 359.07 second.

epoch 1355 starting......
Epoch:  1355 | train loss: 1.361260e-03 | valid loss: 1.406562e-03 
      	| train loss (relative): 2.661776e-02 | valid loss (relative): 2.751157e-02 
Epoch 1355 use: 356.81 second.

epoch 1356 starting......
Epoch:  1356 | train loss: 1.365397e-03 | valid loss: 1.409010e-03 
      	| train loss (relative): 2.669395e-02 | valid loss (relative): 2.762543e-02 
Epoch 1356 use: 347.14 second.

epoch 1357 starting......
Epoch:  1357 | train loss: 1.362639e-03 | valid loss: 1.404105e-03 
      	| train loss (relative): 2.664112e-02 | valid loss (relative): 2.743843e-02 
Epoch 1357 use: 369.80 second.

epoch 1358 starting......
Epoch:  1358 | train loss: 1.357178e-03 | valid loss: 1.402684e-03 
      	| train loss (relative): 2.653030e-02 | valid loss (relative): 2.737134e-02 
Epoch 1358 use: 353.24 second.

epoch 1359 starting......
Epoch:  1359 | train loss: 1.358148e-03 | valid loss: 1.405491e-03 
      	| train loss (relative): 2.654782e-02 | valid loss (relative): 2.743296e-02 
Epoch 1359 use: 355.77 second.

epoch 1360 starting......
Epoch:  1360 | train loss: 1.360797e-03 | valid loss: 1.404751e-03 
      	| train loss (relative): 2.660821e-02 | valid loss (relative): 2.748659e-02 
Epoch 1360 use: 366.52 second.

epoch 1361 starting......
Epoch:  1361 | train loss: 1.361506e-03 | valid loss: 1.401259e-03 
      	| train loss (relative): 2.661743e-02 | valid loss (relative): 2.733091e-02 
Epoch 1361 use: 342.77 second.

epoch 1362 starting......
Epoch:  1362 | train loss: 1.360519e-03 | valid loss: 1.403340e-03 
      	| train loss (relative): 2.659546e-02 | valid loss (relative): 2.749897e-02 
Epoch 1362 use: 351.47 second.

epoch 1363 starting......
Epoch:  1363 | train loss: 1.363140e-03 | valid loss: 1.408828e-03 
      	| train loss (relative): 2.664678e-02 | valid loss (relative): 2.760438e-02 
Epoch 1363 use: 365.10 second.

epoch 1364 starting......
Epoch:  1364 | train loss: 1.361021e-03 | valid loss: 1.405200e-03 
      	| train loss (relative): 2.660664e-02 | valid loss (relative): 2.751800e-02 
Epoch 1364 use: 353.73 second.

epoch 1365 starting......
Epoch:  1365 | train loss: 1.364220e-03 | valid loss: 1.415023e-03 
      	| train loss (relative): 2.667182e-02 | valid loss (relative): 2.766008e-02 
Epoch 1365 use: 359.91 second.

epoch 1366 starting......
Epoch:  1366 | train loss: 1.362777e-03 | valid loss: 1.407504e-03 
      	| train loss (relative): 2.664356e-02 | valid loss (relative): 2.743093e-02 
Epoch 1366 use: 361.52 second.

epoch 1367 starting......
Epoch:  1367 | train loss: 1.357611e-03 | valid loss: 1.402159e-03 
      	| train loss (relative): 2.653709e-02 | valid loss (relative): 2.735588e-02 
Epoch 1367 use: 351.91 second.

epoch 1368 starting......
Epoch:  1368 | train loss: 1.358576e-03 | valid loss: 1.399246e-03 
      	| train loss (relative): 2.655474e-02 | valid loss (relative): 2.736944e-02 
Epoch 1368 use: 373.77 second.

epoch 1369 starting......
Epoch:  1369 | train loss: 1.356223e-03 | valid loss: 1.400893e-03 
      	| train loss (relative): 2.651177e-02 | valid loss (relative): 2.750365e-02 
Epoch 1369 use: 363.52 second.

epoch 1370 starting......
Epoch:  1370 | train loss: 1.360497e-03 | valid loss: 1.406980e-03 
      	| train loss (relative): 2.659890e-02 | valid loss (relative): 2.773661e-02 
Epoch 1370 use: 356.89 second.

epoch 1371 starting......
Epoch:  1371 | train loss: 1.359304e-03 | valid loss: 1.402960e-03 
      	| train loss (relative): 2.657151e-02 | valid loss (relative): 2.739073e-02 
Epoch 1371 use: 350.93 second.

epoch 1372 starting......
Epoch:  1372 | train loss: 1.358515e-03 | valid loss: 1.403430e-03 
      	| train loss (relative): 2.655440e-02 | valid loss (relative): 2.731410e-02 
Epoch 1372 use: 358.73 second.

epoch 1373 starting......
Epoch:  1373 | train loss: 1.356723e-03 | valid loss: 1.406366e-03 
      	| train loss (relative): 2.651962e-02 | valid loss (relative): 2.751624e-02 
Epoch 1373 use: 356.30 second.

epoch 1374 starting......
Epoch:  1374 | train loss: 1.359711e-03 | valid loss: 1.409043e-03 
      	| train loss (relative): 2.658493e-02 | valid loss (relative): 2.758855e-02 
Epoch 1374 use: 353.83 second.

epoch 1375 starting......
Epoch:  1375 | train loss: 1.360712e-03 | valid loss: 1.404478e-03 
      	| train loss (relative): 2.660282e-02 | valid loss (relative): 2.751878e-02 
Epoch 1375 use: 352.45 second.

epoch 1376 starting......
Epoch:  1376 | train loss: 1.356918e-03 | valid loss: 1.408497e-03 
      	| train loss (relative): 2.652606e-02 | valid loss (relative): 2.746580e-02 
Epoch 1376 use: 367.29 second.

epoch 1377 starting......
Epoch:  1377 | train loss: 1.358870e-03 | valid loss: 1.403148e-03 
      	| train loss (relative): 2.656585e-02 | valid loss (relative): 2.740714e-02 
Epoch 1377 use: 366.75 second.

epoch 1378 starting......
Epoch:  1378 | train loss: 1.357965e-03 | valid loss: 1.411123e-03 
      	| train loss (relative): 2.654447e-02 | valid loss (relative): 2.764034e-02 
Epoch 1378 use: 364.80 second.

epoch 1379 starting......
Epoch:  1379 | train loss: 1.359993e-03 | valid loss: 1.407418e-03 
      	| train loss (relative): 2.658546e-02 | valid loss (relative): 2.742458e-02 
Epoch 1379 use: 362.28 second.

epoch 1380 starting......
Epoch:  1380 | train loss: 1.359336e-03 | valid loss: 1.406005e-03 
      	| train loss (relative): 2.657381e-02 | valid loss (relative): 2.744313e-02 
Epoch 1380 use: 350.88 second.

epoch 1381 starting......
Epoch:  1381 | train loss: 1.359271e-03 | valid loss: 1.407746e-03 
      	| train loss (relative): 2.657489e-02 | valid loss (relative): 2.763576e-02 
Epoch 1381 use: 360.81 second.

epoch 1382 starting......
Epoch:  1382 | train loss: 1.360511e-03 | valid loss: 1.405991e-03 
      	| train loss (relative): 2.659857e-02 | valid loss (relative): 2.761156e-02 
Epoch 1382 use: 366.34 second.

epoch 1383 starting......
Epoch:  1383 | train loss: 1.359416e-03 | valid loss: 1.406118e-03 
      	| train loss (relative): 2.657633e-02 | valid loss (relative): 2.757022e-02 
Epoch 1383 use: 367.24 second.

epoch 1384 starting......
Epoch:  1384 | train loss: 1.357065e-03 | valid loss: 1.403723e-03 
      	| train loss (relative): 2.653165e-02 | valid loss (relative): 2.744790e-02 
Epoch 1384 use: 359.76 second.

epoch 1385 starting......
Epoch:  1385 | train loss: 1.356727e-03 | valid loss: 1.401884e-03 
      	| train loss (relative): 2.652149e-02 | valid loss (relative): 2.745306e-02 
Epoch 1385 use: 348.08 second.

epoch 1386 starting......
Epoch:  1386 | train loss: 1.357130e-03 | valid loss: 1.403563e-03 
      	| train loss (relative): 2.653141e-02 | valid loss (relative): 2.742106e-02 
Epoch 1386 use: 357.50 second.

epoch 1387 starting......
Epoch:  1387 | train loss: 1.356829e-03 | valid loss: 1.405036e-03 
      	| train loss (relative): 2.652445e-02 | valid loss (relative): 2.742541e-02 
Epoch 1387 use: 350.56 second.

epoch 1388 starting......
Epoch:  1388 | train loss: 1.356598e-03 | valid loss: 1.397973e-03 
      	| train loss (relative): 2.651608e-02 | valid loss (relative): 2.733353e-02 
Epoch 1388 use: 352.31 second.

epoch 1389 starting......
Epoch:  1389 | train loss: 1.353894e-03 | valid loss: 1.400425e-03 
      	| train loss (relative): 2.646157e-02 | valid loss (relative): 2.738350e-02 
Epoch 1389 use: 366.86 second.

epoch 1390 starting......
Epoch:  1390 | train loss: 1.354112e-03 | valid loss: 1.404397e-03 
      	| train loss (relative): 2.646786e-02 | valid loss (relative): 2.750628e-02 
Epoch 1390 use: 355.38 second.

epoch 1391 starting......
Epoch:  1391 | train loss: 1.355107e-03 | valid loss: 1.403179e-03 
      	| train loss (relative): 2.649239e-02 | valid loss (relative): 2.751146e-02 
Epoch 1391 use: 346.20 second.

epoch 1392 starting......
Epoch:  1392 | train loss: 1.354448e-03 | valid loss: 1.403299e-03 
      	| train loss (relative): 2.647503e-02 | valid loss (relative): 2.746460e-02 
Epoch 1392 use: 354.96 second.

epoch 1393 starting......
Epoch:  1393 | train loss: 1.353972e-03 | valid loss: 1.403145e-03 
      	| train loss (relative): 2.646746e-02 | valid loss (relative): 2.732556e-02 
Epoch 1393 use: 355.44 second.

epoch 1394 starting......
Epoch:  1394 | train loss: 1.354854e-03 | valid loss: 1.412290e-03 
      	| train loss (relative): 2.648471e-02 | valid loss (relative): 2.759268e-02 
Epoch 1394 use: 355.02 second.

epoch 1395 starting......
Epoch:  1395 | train loss: 1.358805e-03 | valid loss: 1.406431e-03 
      	| train loss (relative): 2.656428e-02 | valid loss (relative): 2.759440e-02 
Epoch 1395 use: 365.41 second.

epoch 1396 starting......
Epoch:  1396 | train loss: 1.358319e-03 | valid loss: 1.406808e-03 
      	| train loss (relative): 2.655185e-02 | valid loss (relative): 2.748527e-02 
Epoch 1396 use: 362.35 second.

epoch 1397 starting......
Epoch:  1397 | train loss: 1.355416e-03 | valid loss: 1.403446e-03 
      	| train loss (relative): 2.649628e-02 | valid loss (relative): 2.731848e-02 
Epoch 1397 use: 357.66 second.

epoch 1398 starting......
Epoch:  1398 | train loss: 1.354489e-03 | valid loss: 1.404201e-03 
      	| train loss (relative): 2.647955e-02 | valid loss (relative): 2.737784e-02 
Epoch 1398 use: 358.49 second.

epoch 1399 starting......
Epoch:  1399 | train loss: 1.353948e-03 | valid loss: 1.403481e-03 
      	| train loss (relative): 2.646171e-02 | valid loss (relative): 2.745134e-02 
Epoch 1399 use: 356.37 second.

epoch 1400 starting......
Epoch:  1400 | train loss: 1.355378e-03 | valid loss: 1.399325e-03 
      	| train loss (relative): 2.649055e-02 | valid loss (relative): 2.746953e-02 
Epoch 1400 use: 367.57 second.

epoch 1401 starting......
Epoch:  1401 | train loss: 1.353018e-03 | valid loss: 1.403503e-03 
      	| train loss (relative): 2.644563e-02 | valid loss (relative): 2.737187e-02 
Epoch 1401 use: 360.98 second.

epoch 1402 starting......
Epoch:  1402 | train loss: 1.353163e-03 | valid loss: 1.401513e-03 
      	| train loss (relative): 2.644735e-02 | valid loss (relative): 2.746246e-02 
Epoch 1402 use: 357.23 second.

epoch 1403 starting......
Epoch:  1403 | train loss: 1.350824e-03 | valid loss: 1.401780e-03 
      	| train loss (relative): 2.640224e-02 | valid loss (relative): 2.747696e-02 
Epoch 1403 use: 366.47 second.

epoch 1404 starting......
Epoch:  1404 | train loss: 1.350048e-03 | valid loss: 1.398449e-03 
      	| train loss (relative): 2.638798e-02 | valid loss (relative): 2.740498e-02 
Epoch 1404 use: 355.99 second.

epoch 1405 starting......
Epoch:  1405 | train loss: 1.348731e-03 | valid loss: 1.410535e-03 
      	| train loss (relative): 2.636413e-02 | valid loss (relative): 2.763504e-02 
Epoch 1405 use: 366.90 second.

epoch 1406 starting......
Epoch:  1406 | train loss: 1.353815e-03 | valid loss: 1.402421e-03 
      	| train loss (relative): 2.646564e-02 | valid loss (relative): 2.752169e-02 
Epoch 1406 use: 368.42 second.

epoch 1407 starting......
Epoch:  1407 | train loss: 1.353369e-03 | valid loss: 1.397721e-03 
      	| train loss (relative): 2.645470e-02 | valid loss (relative): 2.742371e-02 
Epoch 1407 use: 370.70 second.

epoch 1408 starting......
Epoch:  1408 | train loss: 1.351460e-03 | valid loss: 1.402019e-03 
      	| train loss (relative): 2.641666e-02 | valid loss (relative): 2.745314e-02 
Epoch 1408 use: 357.08 second.

epoch 1409 starting......
Epoch:  1409 | train loss: 1.353240e-03 | valid loss: 1.404350e-03 
      	| train loss (relative): 2.645334e-02 | valid loss (relative): 2.746306e-02 
Epoch 1409 use: 362.49 second.

epoch 1410 starting......
Epoch:  1410 | train loss: 1.355016e-03 | valid loss: 1.399765e-03 
      	| train loss (relative): 2.648681e-02 | valid loss (relative): 2.749481e-02 
Epoch 1410 use: 355.39 second.

epoch 1411 starting......
Epoch:  1411 | train loss: 1.350345e-03 | valid loss: 1.397274e-03 
      	| train loss (relative): 2.639424e-02 | valid loss (relative): 2.738741e-02 
Epoch 1411 use: 367.70 second.

epoch 1412 starting......
Epoch:  1412 | train loss: 1.349028e-03 | valid loss: 1.395859e-03 
      	| train loss (relative): 2.636925e-02 | valid loss (relative): 2.741714e-02 
Epoch 1412 use: 354.63 second.

epoch 1413 starting......
Epoch:  1413 | train loss: 1.348465e-03 | valid loss: 1.403725e-03 
      	| train loss (relative): 2.635855e-02 | valid loss (relative): 2.745289e-02 
Epoch 1413 use: 359.09 second.

epoch 1414 starting......
Epoch:  1414 | train loss: 1.350099e-03 | valid loss: 1.394951e-03 
      	| train loss (relative): 2.638832e-02 | valid loss (relative): 2.726931e-02 
Epoch 1414 use: 346.21 second.

epoch 1415 starting......
Epoch:  1415 | train loss: 1.349630e-03 | valid loss: 1.400611e-03 
      	| train loss (relative): 2.637894e-02 | valid loss (relative): 2.750069e-02 
Epoch 1415 use: 360.57 second.

epoch 1416 starting......
Epoch:  1416 | train loss: 1.349263e-03 | valid loss: 1.400696e-03 
      	| train loss (relative): 2.637285e-02 | valid loss (relative): 2.741783e-02 
Epoch 1416 use: 359.03 second.

epoch 1417 starting......
Epoch:  1417 | train loss: 1.349335e-03 | valid loss: 1.396689e-03 
      	| train loss (relative): 2.637347e-02 | valid loss (relative): 2.732832e-02 
Epoch 1417 use: 359.75 second.

epoch 1418 starting......
Epoch:  1418 | train loss: 1.351192e-03 | valid loss: 1.405058e-03 
      	| train loss (relative): 2.641019e-02 | valid loss (relative): 2.739193e-02 
Epoch 1418 use: 356.67 second.

epoch 1419 starting......
Epoch:  1419 | train loss: 1.349481e-03 | valid loss: 1.405390e-03 
      	| train loss (relative): 2.637350e-02 | valid loss (relative): 2.766011e-02 
Epoch 1419 use: 375.72 second.

epoch 1420 starting......
Epoch:  1420 | train loss: 1.349806e-03 | valid loss: 1.401074e-03 
      	| train loss (relative): 2.638483e-02 | valid loss (relative): 2.746923e-02 
Epoch 1420 use: 349.28 second.

epoch 1421 starting......
Epoch:  1421 | train loss: 1.349175e-03 | valid loss: 1.397775e-03 
      	| train loss (relative): 2.637373e-02 | valid loss (relative): 2.732718e-02 
Epoch 1421 use: 359.22 second.

epoch 1422 starting......
Epoch:  1422 | train loss: 1.347506e-03 | valid loss: 1.392966e-03 
      	| train loss (relative): 2.633757e-02 | valid loss (relative): 2.722918e-02 
Epoch 1422 use: 350.42 second.

epoch 1423 starting......
Epoch:  1423 | train loss: 1.343162e-03 | valid loss: 1.393865e-03 
      	| train loss (relative): 2.625046e-02 | valid loss (relative): 2.732488e-02 
Epoch 1423 use: 352.18 second.

epoch 1424 starting......
Epoch:  1424 | train loss: 1.346123e-03 | valid loss: 1.404891e-03 
      	| train loss (relative): 2.630980e-02 | valid loss (relative): 2.751125e-02 
Epoch 1424 use: 345.34 second.

epoch 1425 starting......
Epoch:  1425 | train loss: 1.348397e-03 | valid loss: 1.398398e-03 
      	| train loss (relative): 2.635629e-02 | valid loss (relative): 2.731306e-02 
Epoch 1425 use: 345.17 second.

epoch 1426 starting......
Epoch:  1426 | train loss: 1.349300e-03 | valid loss: 1.396910e-03 
      	| train loss (relative): 2.637117e-02 | valid loss (relative): 2.727707e-02 
Epoch 1426 use: 340.83 second.

epoch 1427 starting......
Epoch:  1427 | train loss: 1.349276e-03 | valid loss: 1.399247e-03 
      	| train loss (relative): 2.636860e-02 | valid loss (relative): 2.745295e-02 
Epoch 1427 use: 354.32 second.

epoch 1428 starting......
Epoch:  1428 | train loss: 1.348347e-03 | valid loss: 1.399211e-03 
      	| train loss (relative): 2.635409e-02 | valid loss (relative): 2.740210e-02 
Epoch 1428 use: 365.21 second.

epoch 1429 starting......
Epoch:  1429 | train loss: 1.349565e-03 | valid loss: 1.398078e-03 
      	| train loss (relative): 2.637937e-02 | valid loss (relative): 2.734580e-02 
Epoch 1429 use: 360.57 second.

epoch 1430 starting......
Epoch:  1430 | train loss: 1.348626e-03 | valid loss: 1.402665e-03 
      	| train loss (relative): 2.635498e-02 | valid loss (relative): 2.758048e-02 
Epoch 1430 use: 334.73 second.

epoch 1431 starting......
Epoch:  1431 | train loss: 1.350319e-03 | valid loss: 1.398215e-03 
      	| train loss (relative): 2.639981e-02 | valid loss (relative): 2.729519e-02 
Epoch 1431 use: 363.13 second.

epoch 1432 starting......
Epoch:  1432 | train loss: 1.348851e-03 | valid loss: 1.397018e-03 
      	| train loss (relative): 2.636452e-02 | valid loss (relative): 2.733602e-02 
Epoch 1432 use: 366.75 second.

epoch 1433 starting......
Epoch:  1433 | train loss: 1.348440e-03 | valid loss: 1.399604e-03 
      	| train loss (relative): 2.635709e-02 | valid loss (relative): 2.729473e-02 
Epoch 1433 use: 353.83 second.

epoch 1434 starting......
Epoch:  1434 | train loss: 1.345435e-03 | valid loss: 1.393818e-03 
      	| train loss (relative): 2.629566e-02 | valid loss (relative): 2.728294e-02 
Epoch 1434 use: 348.58 second.

epoch 1435 starting......
Epoch:  1435 | train loss: 1.345902e-03 | valid loss: 1.398678e-03 
      	| train loss (relative): 2.630786e-02 | valid loss (relative): 2.735432e-02 
Epoch 1435 use: 340.36 second.

epoch 1436 starting......
Epoch:  1436 | train loss: 1.347811e-03 | valid loss: 1.396202e-03 
      	| train loss (relative): 2.634213e-02 | valid loss (relative): 2.739410e-02 
Epoch 1436 use: 330.26 second.

epoch 1437 starting......
Epoch:  1437 | train loss: 1.344274e-03 | valid loss: 1.395519e-03 
      	| train loss (relative): 2.627232e-02 | valid loss (relative): 2.730608e-02 
Epoch 1437 use: 346.77 second.

epoch 1438 starting......
Epoch:  1438 | train loss: 1.343862e-03 | valid loss: 1.397046e-03 
      	| train loss (relative): 2.626673e-02 | valid loss (relative): 2.729690e-02 
Epoch 1438 use: 340.10 second.

epoch 1439 starting......
Epoch:  1439 | train loss: 1.345819e-03 | valid loss: 1.398471e-03 
      	| train loss (relative): 2.630509e-02 | valid loss (relative): 2.731565e-02 
Epoch 1439 use: 355.29 second.

epoch 1440 starting......
Epoch:  1440 | train loss: 1.346609e-03 | valid loss: 1.407271e-03 
      	| train loss (relative): 2.631931e-02 | valid loss (relative): 2.747127e-02 
Epoch 1440 use: 342.28 second.

epoch 1441 starting......
Epoch:  1441 | train loss: 1.348071e-03 | valid loss: 1.402246e-03 
      	| train loss (relative): 2.634645e-02 | valid loss (relative): 2.755715e-02 
Epoch 1441 use: 350.38 second.

epoch 1442 starting......
Epoch:  1442 | train loss: 1.347754e-03 | valid loss: 1.396675e-03 
      	| train loss (relative): 2.634359e-02 | valid loss (relative): 2.729227e-02 
Epoch 1442 use: 341.20 second.

epoch 1443 starting......
Epoch:  1443 | train loss: 1.347409e-03 | valid loss: 1.396202e-03 
      	| train loss (relative): 2.633610e-02 | valid loss (relative): 2.745766e-02 
Epoch 1443 use: 361.06 second.

epoch 1444 starting......
Epoch:  1444 | train loss: 1.343575e-03 | valid loss: 1.400929e-03 
      	| train loss (relative): 2.626139e-02 | valid loss (relative): 2.739249e-02 
Epoch 1444 use: 353.06 second.

epoch 1445 starting......
Epoch:  1445 | train loss: 1.345773e-03 | valid loss: 1.394521e-03 
      	| train loss (relative): 2.630300e-02 | valid loss (relative): 2.735875e-02 
Epoch 1445 use: 360.34 second.

epoch 1446 starting......
Epoch:  1446 | train loss: 1.344916e-03 | valid loss: 1.401733e-03 
      	| train loss (relative): 2.628686e-02 | valid loss (relative): 2.729307e-02 
Epoch 1446 use: 350.58 second.

epoch 1447 starting......
Epoch:  1447 | train loss: 1.349239e-03 | valid loss: 1.396927e-03 
      	| train loss (relative): 2.636980e-02 | valid loss (relative): 2.741379e-02 
Epoch 1447 use: 349.91 second.

epoch 1448 starting......
Epoch:  1448 | train loss: 1.344183e-03 | valid loss: 1.395913e-03 
      	| train loss (relative): 2.626835e-02 | valid loss (relative): 2.734788e-02 
Epoch 1448 use: 353.43 second.

epoch 1449 starting......
Epoch:  1449 | train loss: 1.345944e-03 | valid loss: 1.396532e-03 
      	| train loss (relative): 2.630881e-02 | valid loss (relative): 2.723657e-02 
Epoch 1449 use: 361.58 second.

test MSE Error: 1.464011e-03 | relative MSE Error: 2.868700e-02 
 Total time used for training: 15.04 hour.
MESLoss saved to  /rds/general/user/jy220/home/new_results/Variational_False_Changelr_False_MSELoss_Latent_256_nearest_neighbouring_True_SFC_nums_3_startlr_0.001_n_epoches_1450.txt
relative MSELoss saved to  /rds/general/user/jy220/home/new_results/Variational_False_Changelr_False_reMSELoss_Latent_256_nearest_neighbouring_True_SFC_nums_3_startlr_0.001_n_epoches_1450.txt
model saved to /rds/general/user/jy220/home/new_results/Variational_False_Changelr_False_Latent_256_Nearest_neighbouring_True_SFC_nums_3_startlr_0.001_n_epoches_1450.pth
model_dict saved to /rds/general/user/jy220/home/new_results/Variational_False_Changelr_False_Latent_256_Nearest_neighbouring_True_SFC_nums_3_startlr_0.001_n_epoches_1450_dict.pth
... Training slugflow data completed, Run finished Tue 24 Aug 14:40:29 BST 2021 ...
{'data_dir': '/rds/general/user/jy220/home/tensors/', 'data_type': 'tensors', 'mode': 'train', 'vtu_fields': 'Component1::ComponentMassFractionPhase1, phase1::Velocity', 'variational': 'False', 'optimizer': 'Adamax', 'structured': 'False', 'changing_lr': 'False', 'self_concat': '2', 'dimension': '3', 'sfc_nums': '3', 'components': '4', 'nearest_neighbouring': 'True', 'dims_latent': '256', 'activation': 'Tanh', 'tk_file': '/rds/general/user/jy220/home/slugflow_tk.pt', 'tb_file': '/rds/general/user/jy220/home/slugflow_tb.pt', 'sfc_file': '/rds/general/user/jy220/home/SFC-CAE-Ready-to-use/sfcs.pt', 'inv_sfc_file': '/rds/general/user/jy220/home/SFC-CAE-Ready-to-use/inv_sfcs.pt', 'coords_file': '/rds/general/user/jy220/home/SFC-CAE-Ready-to-use/coords.pt', 'cells_file': '/rds/general/user/jy220/home/SFC-CAE-Ready-to-use/cells.npy', 'state_load': '/rds/general/user/jy220/home/new_results/Variational_False_Changelr_False_Latent_256_Nearest_neighbouring_True_SFC_nums_3_startlr_0.001_n_epoches_1450_dict.pth', 'batch_size': '16', 'lr': '0.001', 'n_epoches': '1', 'seed': '17', 'visualize': 'False', 'reconstructed_path': 'None', 'reconstruct_start_index': '0', 'reconstruct_end_index': '50', 'save_path': '/rds/general/user/jy220/home/new_results/'}
[[ 2.50825269e-01 -1.67256990e-02 -1.22268730e-03]
 [ 2.38611959e-01 -5.50627777e-03 -5.06451913e-03]
 [ 2.39454874e-01 -1.59563257e-02  3.96778323e-03]
 ...
 [ 9.11361096e+00 -2.21908381e-02  2.22384902e-03]
 [ 9.11847310e+00 -2.84346931e-02 -2.34839590e-04]
 [ 9.11039661e+00 -2.51498573e-02 -8.70661044e-03]]
{'tetra': array([[      0,       1,       2,       3],
       [      4,       5,       6,       7],
       [      8,       9,      10,      11],
       ...,
       [1342744, 1342745, 1342746, 1342747],
       [1342748, 1342749, 1342750, 1342751],
       [1342752, 1342753, 1342754, 1342755]])}
vtu fields:  ['Component1::ComponentMassFractionPhase1', 'phase1::Velocity'] 
 structured  False 
 activation  Tanh() 
 self concat  2 
 sfc_nums  3 

dims_latent  256 
 components  4 
 nearest_neighbouring  True 

visualize  False 
 sample number  1706 

reading sfc nums......
[array([  41684,   41685,   41674, ..., 1235560, 1235564, 1235558]), array([954289, 954290, 954291, ..., 420685, 420687, 420688]), array([  40156,   40155,   40158, ..., 1123478, 1123475, 1123467])]
reading inverse sfc nums......
[array([   8146,    8145,    8144, ..., 1274444, 1274445, 1273166]), array([547280, 547283, 593037, ..., 933933, 933932, 864488]), array([ 66437,  66439, 122512, ..., 459416, 415130, 459418])]
tk:  tensor([0.7581, 0.0418, 0.1840, 0.1464], dtype=torch.float64) 

tb:  tensor([-0.3816, -0.3618, -0.0308,  0.1446], dtype=torch.float64) 

length of train set: 1505 

length of valid set: 100 

length of test set: 101 

torch device num: 4 

Let's use 4 GPUs!
... Training slugflow data completed, Run finished Tue 24 Aug 19:14:02 BST 2021 ...
{'data_dir': '/rds/general/user/jy220/home/tensors/', 'data_type': 'tensors', 'mode': 'train', 'vtu_fields': 'Component1::ComponentMassFractionPhase1, phase1::Velocity', 'variational': 'False', 'optimizer': 'Adamax', 'structured': 'False', 'changing_lr': 'False', 'self_concat': '2', 'dimension': '3', 'sfc_nums': '3', 'components': '4', 'nearest_neighbouring': 'True', 'dims_latent': '256', 'activation': 'Tanh', 'tk_file': '/rds/general/user/jy220/home/slugflow_tk.pt', 'tb_file': '/rds/general/user/jy220/home/slugflow_tb.pt', 'sfc_file': '/rds/general/user/jy220/home/SFC-CAE-Ready-to-use/sfcs.pt', 'inv_sfc_file': '/rds/general/user/jy220/home/SFC-CAE-Ready-to-use/inv_sfcs.pt', 'coords_file': '/rds/general/user/jy220/home/SFC-CAE-Ready-to-use/coords.pt', 'cells_file': '/rds/general/user/jy220/home/SFC-CAE-Ready-to-use/cells.npy', 'state_load': '/rds/general/user/jy220/home/new_results/Variational_False_Changelr_False_Latent_256_Nearest_neighbouring_True_SFC_nums_3_startlr_0.001_n_epoches_1450_dict.pth', 'batch_size': '16', 'lr': '0.001', 'n_epoches': '1', 'seed': '17', 'visualize': 'False', 'reconstructed_path': 'None', 'reconstruct_start_index': '0', 'reconstruct_end_index': '50', 'save_path': '/rds/general/user/jy220/home/new_results/'}
[[ 2.50825269e-01 -1.67256990e-02 -1.22268730e-03]
 [ 2.38611959e-01 -5.50627777e-03 -5.06451913e-03]
 [ 2.39454874e-01 -1.59563257e-02  3.96778323e-03]
 ...
 [ 9.11361096e+00 -2.21908381e-02  2.22384902e-03]
 [ 9.11847310e+00 -2.84346931e-02 -2.34839590e-04]
 [ 9.11039661e+00 -2.51498573e-02 -8.70661044e-03]]
{'tetra': array([[      0,       1,       2,       3],
       [      4,       5,       6,       7],
       [      8,       9,      10,      11],
       ...,
       [1342744, 1342745, 1342746, 1342747],
       [1342748, 1342749, 1342750, 1342751],
       [1342752, 1342753, 1342754, 1342755]])}
vtu fields:  ['Component1::ComponentMassFractionPhase1', 'phase1::Velocity'] 
 structured  False 
 activation  Tanh() 
 self concat  2 
 sfc_nums  3 

dims_latent  256 
 components  4 
 nearest_neighbouring  True 

visualize  False 
 sample number  1706 

reading sfc nums......
[array([  41684,   41685,   41674, ..., 1235560, 1235564, 1235558]), array([954289, 954290, 954291, ..., 420685, 420687, 420688]), array([  40156,   40155,   40158, ..., 1123478, 1123475, 1123467])]
reading inverse sfc nums......
[array([   8146,    8145,    8144, ..., 1274444, 1274445, 1273166]), array([547280, 547283, 593037, ..., 933933, 933932, 864488]), array([ 66437,  66439, 122512, ..., 459416, 415130, 459418])]
tk:  tensor([0.7581, 0.0418, 0.1840, 0.1464], dtype=torch.float64) 

tb:  tensor([-0.3816, -0.3618, -0.0308,  0.1446], dtype=torch.float64) 

length of train set: 1505 

length of valid set: 100 

length of test set: 101 

torch device num: 4 

Let's use 4 GPUs!
epoch 1450 starting......
Epoch:  1450 | train loss: 1.527645e-03 | valid loss: 1.356121e-03 
      	| train loss (relative): 2.993517e-02 | valid loss (relative): 2.652329e-02 
Epoch 1450 use: 519.94 second.

test MSE Error: 1.379706e-03 | relative MSE Error: 2.704070e-02 
 Total time used for training: 0.15 hour.
MESLoss saved to  /rds/general/user/jy220/home/new_results/Variational_False_Changelr_False_MSELoss_Latent_256_nearest_neighbouring_True_SFC_nums_3_startlr_0.001_n_epoches_1451.txt
relative MSELoss saved to  /rds/general/user/jy220/home/new_results/Variational_False_Changelr_False_reMSELoss_Latent_256_nearest_neighbouring_True_SFC_nums_3_startlr_0.001_n_epoches_1451.txt
model saved to /rds/general/user/jy220/home/new_results/Variational_False_Changelr_False_Latent_256_Nearest_neighbouring_True_SFC_nums_3_startlr_0.001_n_epoches_1451.pth
model_dict saved to /rds/general/user/jy220/home/new_results/Variational_False_Changelr_False_Latent_256_Nearest_neighbouring_True_SFC_nums_3_startlr_0.001_n_epoches_1451_dict.pth
... Training slugflow data completed, Run finished Tue 24 Aug 23:29:10 BST 2021 ...
{'data_dir': '/rds/general/user/jy220/home/tensors/', 'data_type': 'tensors', 'mode': 'train', 'vtu_fields': 'Component1::ComponentMassFractionPhase1, phase1::Velocity', 'variational': 'False', 'optimizer': 'Adamax', 'structured': 'False', 'changing_lr': 'False', 'self_concat': '2', 'dimension': '3', 'sfc_nums': '3', 'components': '4', 'nearest_neighbouring': 'True', 'dims_latent': '256', 'activation': 'Tanh', 'tk_file': '/rds/general/user/jy220/home/slugflow_tk.pt', 'tb_file': '/rds/general/user/jy220/home/slugflow_tb.pt', 'sfc_file': '/rds/general/user/jy220/home/SFC-CAE-Ready-to-use/sfcs.pt', 'inv_sfc_file': '/rds/general/user/jy220/home/SFC-CAE-Ready-to-use/inv_sfcs.pt', 'coords_file': '/rds/general/user/jy220/home/SFC-CAE-Ready-to-use/coords.pt', 'cells_file': '/rds/general/user/jy220/home/SFC-CAE-Ready-to-use/cells.npy', 'state_load': '/rds/general/user/jy220/home/new_results/Variational_False_Changelr_False_Latent_256_Nearest_neighbouring_True_SFC_nums_3_startlr_0.001_n_epoches_1451_dict.pth', 'batch_size': '16', 'lr': '0.001', 'n_epoches': '150', 'seed': '17', 'visualize': 'False', 'reconstructed_path': 'None', 'reconstruct_start_index': '0', 'reconstruct_end_index': '50', 'save_path': '/rds/general/user/jy220/home/new_results/'}
[[ 2.50825269e-01 -1.67256990e-02 -1.22268730e-03]
 [ 2.38611959e-01 -5.50627777e-03 -5.06451913e-03]
 [ 2.39454874e-01 -1.59563257e-02  3.96778323e-03]
 ...
 [ 9.11361096e+00 -2.21908381e-02  2.22384902e-03]
 [ 9.11847310e+00 -2.84346931e-02 -2.34839590e-04]
 [ 9.11039661e+00 -2.51498573e-02 -8.70661044e-03]]
{'tetra': array([[      0,       1,       2,       3],
       [      4,       5,       6,       7],
       [      8,       9,      10,      11],
       ...,
       [1342744, 1342745, 1342746, 1342747],
       [1342748, 1342749, 1342750, 1342751],
       [1342752, 1342753, 1342754, 1342755]])}
vtu fields:  ['Component1::ComponentMassFractionPhase1', 'phase1::Velocity'] 
 structured  False 
 activation  Tanh() 
 self concat  2 
 sfc_nums  3 

dims_latent  256 
 components  4 
 nearest_neighbouring  True 

visualize  False 
 sample number  1706 

reading sfc nums......
[array([  41684,   41685,   41674, ..., 1235560, 1235564, 1235558]), array([954289, 954290, 954291, ..., 420685, 420687, 420688]), array([  40156,   40155,   40158, ..., 1123478, 1123475, 1123467])]
reading inverse sfc nums......
[array([   8146,    8145,    8144, ..., 1274444, 1274445, 1273166]), array([547280, 547283, 593037, ..., 933933, 933932, 864488]), array([ 66437,  66439, 122512, ..., 459416, 415130, 459418])]
tk:  tensor([0.7581, 0.0418, 0.1840, 0.1464], dtype=torch.float64) 

tb:  tensor([-0.3816, -0.3618, -0.0308,  0.1446], dtype=torch.float64) 

length of train set: 1505 

length of valid set: 100 

length of test set: 101 

torch device num: 4 

Let's use 4 GPUs!
epoch 1451 starting......
Epoch:  1451 | train loss: 1.340924e-03 | valid loss: 1.419212e-03 
      	| train loss (relative): 2.621371e-02 | valid loss (relative): 2.784776e-02 
Epoch 1451 use: 533.56 second.

epoch 1452 starting......
Epoch:  1452 | train loss: 1.332985e-03 | valid loss: 1.417764e-03 
      	| train loss (relative): 2.605784e-02 | valid loss (relative): 2.781939e-02 
Epoch 1452 use: 481.95 second.

epoch 1453 starting......
Epoch:  1453 | train loss: 1.329999e-03 | valid loss: 1.418184e-03 
      	| train loss (relative): 2.599811e-02 | valid loss (relative): 2.781349e-02 
Epoch 1453 use: 441.77 second.

epoch 1454 starting......
Epoch:  1454 | train loss: 1.329391e-03 | valid loss: 1.419425e-03 
      	| train loss (relative): 2.598488e-02 | valid loss (relative): 2.781310e-02 
Epoch 1454 use: 451.22 second.

epoch 1455 starting......
Epoch:  1455 | train loss: 1.330514e-03 | valid loss: 1.422891e-03 
      	| train loss (relative): 2.600560e-02 | valid loss (relative): 2.790434e-02 
Epoch 1455 use: 445.11 second.

epoch 1456 starting......
Epoch:  1456 | train loss: 1.333393e-03 | valid loss: 1.428976e-03 
      	| train loss (relative): 2.606324e-02 | valid loss (relative): 2.801894e-02 
Epoch 1456 use: 427.22 second.

epoch 1457 starting......
Epoch:  1457 | train loss: 1.336197e-03 | valid loss: 1.432691e-03 
      	| train loss (relative): 2.611891e-02 | valid loss (relative): 2.808611e-02 
Epoch 1457 use: 436.58 second.

epoch 1458 starting......
Epoch:  1458 | train loss: 1.336297e-03 | valid loss: 1.434029e-03 
      	| train loss (relative): 2.612183e-02 | valid loss (relative): 2.812200e-02 
Epoch 1458 use: 427.04 second.

epoch 1459 starting......
Epoch:  1459 | train loss: 1.338038e-03 | valid loss: 1.435989e-03 
      	| train loss (relative): 2.615446e-02 | valid loss (relative): 2.810081e-02 
Epoch 1459 use: 433.60 second.

epoch 1460 starting......
Epoch:  1460 | train loss: 1.340823e-03 | valid loss: 1.440857e-03 
      	| train loss (relative): 2.621493e-02 | valid loss (relative): 2.822844e-02 
Epoch 1460 use: 441.64 second.

epoch 1461 starting......
Epoch:  1461 | train loss: 1.341796e-03 | valid loss: 1.444450e-03 
      	| train loss (relative): 2.623017e-02 | valid loss (relative): 2.834908e-02 
Epoch 1461 use: 432.98 second.

epoch 1462 starting......
Epoch:  1462 | train loss: 1.341546e-03 | valid loss: 1.442725e-03 
      	| train loss (relative): 2.622266e-02 | valid loss (relative): 2.829899e-02 
Epoch 1462 use: 462.77 second.

epoch 1463 starting......
Epoch:  1463 | train loss: 1.341188e-03 | valid loss: 1.443035e-03 
      	| train loss (relative): 2.621796e-02 | valid loss (relative): 2.827876e-02 
Epoch 1463 use: 523.84 second.

epoch 1464 starting......
Epoch:  1464 | train loss: 1.341524e-03 | valid loss: 1.443959e-03 
      	| train loss (relative): 2.622360e-02 | valid loss (relative): 2.838575e-02 
Epoch 1464 use: 447.10 second.

epoch 1465 starting......
Epoch:  1465 | train loss: 1.339784e-03 | valid loss: 1.445190e-03 
      	| train loss (relative): 2.619014e-02 | valid loss (relative): 2.839387e-02 
Epoch 1465 use: 451.89 second.

epoch 1466 starting......
Epoch:  1466 | train loss: 1.340703e-03 | valid loss: 1.446718e-03 
      	| train loss (relative): 2.620715e-02 | valid loss (relative): 2.830575e-02 
Epoch 1466 use: 424.80 second.

epoch 1467 starting......
Epoch:  1467 | train loss: 1.339904e-03 | valid loss: 1.444051e-03 
      	| train loss (relative): 2.619454e-02 | valid loss (relative): 2.835902e-02 
Epoch 1467 use: 428.03 second.

epoch 1468 starting......
Epoch:  1468 | train loss: 1.339301e-03 | valid loss: 1.445572e-03 
      	| train loss (relative): 2.618065e-02 | valid loss (relative): 2.838550e-02 
Epoch 1468 use: 425.64 second.

epoch 1469 starting......
Epoch:  1469 | train loss: 1.340975e-03 | valid loss: 1.450287e-03 
      	| train loss (relative): 2.621464e-02 | valid loss (relative): 2.852456e-02 
Epoch 1469 use: 425.43 second.

epoch 1470 starting......
Epoch:  1470 | train loss: 1.340198e-03 | valid loss: 1.452832e-03 
      	| train loss (relative): 2.619806e-02 | valid loss (relative): 2.846019e-02 
Epoch 1470 use: 447.16 second.

epoch 1471 starting......
Epoch:  1471 | train loss: 1.343929e-03 | valid loss: 1.449192e-03 
      	| train loss (relative): 2.627355e-02 | valid loss (relative): 2.827792e-02 
Epoch 1471 use: 431.56 second.

epoch 1472 starting......
Epoch:  1472 | train loss: 1.343302e-03 | valid loss: 1.447238e-03 
      	| train loss (relative): 2.625540e-02 | valid loss (relative): 2.832795e-02 
Epoch 1472 use: 419.84 second.

epoch 1473 starting......
Epoch:  1473 | train loss: 1.337232e-03 | valid loss: 1.447149e-03 
      	| train loss (relative): 2.613812e-02 | valid loss (relative): 2.838617e-02 
Epoch 1473 use: 428.24 second.

epoch 1474 starting......
Epoch:  1474 | train loss: 1.341389e-03 | valid loss: 1.449029e-03 
      	| train loss (relative): 2.622027e-02 | valid loss (relative): 2.818019e-02 
Epoch 1474 use: 442.29 second.

epoch 1475 starting......
Epoch:  1475 | train loss: 1.340927e-03 | valid loss: 1.447359e-03 
      	| train loss (relative): 2.621118e-02 | valid loss (relative): 2.842590e-02 
Epoch 1475 use: 422.43 second.

epoch 1476 starting......
Epoch:  1476 | train loss: 1.339479e-03 | valid loss: 1.450378e-03 
      	| train loss (relative): 2.618659e-02 | valid loss (relative): 2.842507e-02 
Epoch 1476 use: 417.82 second.

epoch 1477 starting......
Epoch:  1477 | train loss: 1.339074e-03 | valid loss: 1.450146e-03 
      	| train loss (relative): 2.617610e-02 | valid loss (relative): 2.848192e-02 
Epoch 1477 use: 434.64 second.

epoch 1478 starting......
Epoch:  1478 | train loss: 1.338995e-03 | valid loss: 1.450208e-03 
      	| train loss (relative): 2.617109e-02 | valid loss (relative): 2.840835e-02 
Epoch 1478 use: 437.87 second.

epoch 1479 starting......
Epoch:  1479 | train loss: 1.340362e-03 | valid loss: 1.447929e-03 
      	| train loss (relative): 2.619909e-02 | valid loss (relative): 2.822088e-02 
Epoch 1479 use: 494.07 second.

epoch 1480 starting......
Epoch:  1480 | train loss: 1.337741e-03 | valid loss: 1.453892e-03 
      	| train loss (relative): 2.614842e-02 | valid loss (relative): 2.875432e-02 
Epoch 1480 use: 457.80 second.

epoch 1481 starting......
Epoch:  1481 | train loss: 1.339239e-03 | valid loss: 1.452237e-03 
      	| train loss (relative): 2.617738e-02 | valid loss (relative): 2.843219e-02 
Epoch 1481 use: 449.09 second.

epoch 1482 starting......
Epoch:  1482 | train loss: 1.342067e-03 | valid loss: 1.448262e-03 
      	| train loss (relative): 2.623156e-02 | valid loss (relative): 2.835622e-02 
Epoch 1482 use: 426.22 second.

epoch 1483 starting......
Epoch:  1483 | train loss: 1.337970e-03 | valid loss: 1.449871e-03 
      	| train loss (relative): 2.615060e-02 | valid loss (relative): 2.843180e-02 
Epoch 1483 use: 426.37 second.

epoch 1484 starting......
Epoch:  1484 | train loss: 1.339569e-03 | valid loss: 1.454006e-03 
      	| train loss (relative): 2.618481e-02 | valid loss (relative): 2.865233e-02 
Epoch 1484 use: 430.10 second.

epoch 1485 starting......
Epoch:  1485 | train loss: 1.339820e-03 | valid loss: 1.456796e-03 
      	| train loss (relative): 2.618816e-02 | valid loss (relative): 2.846094e-02 
Epoch 1485 use: 420.47 second.

epoch 1486 starting......
Epoch:  1486 | train loss: 1.339031e-03 | valid loss: 1.450909e-03 
      	| train loss (relative): 2.617459e-02 | valid loss (relative): 2.829877e-02 
Epoch 1486 use: 429.53 second.

epoch 1487 starting......
Epoch:  1487 | train loss: 1.337415e-03 | valid loss: 1.454359e-03 
      	| train loss (relative): 2.614280e-02 | valid loss (relative): 2.863979e-02 
Epoch 1487 use: 426.58 second.

epoch 1488 starting......
Epoch:  1488 | train loss: 1.339966e-03 | valid loss: 1.450218e-03 
      	| train loss (relative): 2.619191e-02 | valid loss (relative): 2.841006e-02 
Epoch 1488 use: 417.89 second.

epoch 1489 starting......
Epoch:  1489 | train loss: 1.340716e-03 | valid loss: 1.453996e-03 
      	| train loss (relative): 2.620792e-02 | valid loss (relative): 2.841093e-02 
Epoch 1489 use: 426.28 second.

epoch 1490 starting......
Epoch:  1490 | train loss: 1.341302e-03 | valid loss: 1.450073e-03 
      	| train loss (relative): 2.621912e-02 | valid loss (relative): 2.842165e-02 
Epoch 1490 use: 417.98 second.

epoch 1491 starting......
Epoch:  1491 | train loss: 1.335013e-03 | valid loss: 1.443189e-03 
      	| train loss (relative): 2.609400e-02 | valid loss (relative): 2.836303e-02 
Epoch 1491 use: 434.55 second.

epoch 1492 starting......
Epoch:  1492 | train loss: 1.330731e-03 | valid loss: 1.447333e-03 
      	| train loss (relative): 2.601156e-02 | valid loss (relative): 2.839364e-02 
Epoch 1492 use: 417.49 second.

epoch 1493 starting......
Epoch:  1493 | train loss: 1.332279e-03 | valid loss: 1.448084e-03 
      	| train loss (relative): 2.604120e-02 | valid loss (relative): 2.851576e-02 
Epoch 1493 use: 440.52 second.

epoch 1494 starting......
Epoch:  1494 | train loss: 1.335064e-03 | valid loss: 1.447796e-03 
      	| train loss (relative): 2.609725e-02 | valid loss (relative): 2.833123e-02 
Epoch 1494 use: 486.47 second.

epoch 1495 starting......
Epoch:  1495 | train loss: 1.331513e-03 | valid loss: 1.453790e-03 
      	| train loss (relative): 2.602438e-02 | valid loss (relative): 2.848616e-02 
Epoch 1495 use: 478.88 second.

epoch 1496 starting......
Epoch:  1496 | train loss: 1.336508e-03 | valid loss: 1.449418e-03 
      	| train loss (relative): 2.612324e-02 | valid loss (relative): 2.845106e-02 
Epoch 1496 use: 438.63 second.

epoch 1497 starting......
Epoch:  1497 | train loss: 1.332487e-03 | valid loss: 1.450265e-03 
      	| train loss (relative): 2.604711e-02 | valid loss (relative): 2.829236e-02 
Epoch 1497 use: 450.15 second.

epoch 1498 starting......
Epoch:  1498 | train loss: 1.334204e-03 | valid loss: 1.449923e-03 
      	| train loss (relative): 2.607860e-02 | valid loss (relative): 2.831266e-02 
Epoch 1498 use: 441.50 second.

epoch 1499 starting......
Epoch:  1499 | train loss: 1.335026e-03 | valid loss: 1.453146e-03 
      	| train loss (relative): 2.609381e-02 | valid loss (relative): 2.845859e-02 
Epoch 1499 use: 434.84 second.

epoch 1500 starting......
Epoch:  1500 | train loss: 1.336445e-03 | valid loss: 1.453526e-03 
      	| train loss (relative): 2.611893e-02 | valid loss (relative): 2.837982e-02 
Epoch 1500 use: 421.82 second.

epoch 1501 starting......
Epoch:  1501 | train loss: 1.333350e-03 | valid loss: 1.447576e-03 
      	| train loss (relative): 2.605847e-02 | valid loss (relative): 2.839100e-02 
Epoch 1501 use: 430.59 second.

epoch 1502 starting......
Epoch:  1502 | train loss: 1.332303e-03 | valid loss: 1.451105e-03 
      	| train loss (relative): 2.604234e-02 | valid loss (relative): 2.857419e-02 
Epoch 1502 use: 430.86 second.

epoch 1503 starting......
Epoch:  1503 | train loss: 1.334027e-03 | valid loss: 1.453104e-03 
      	| train loss (relative): 2.607041e-02 | valid loss (relative): 2.875374e-02 
Epoch 1503 use: 444.90 second.

epoch 1504 starting......
Epoch:  1504 | train loss: 1.333337e-03 | valid loss: 1.453549e-03 
      	| train loss (relative): 2.606305e-02 | valid loss (relative): 2.847039e-02 
Epoch 1504 use: 424.85 second.

epoch 1505 starting......
Epoch:  1505 | train loss: 1.331907e-03 | valid loss: 1.448109e-03 
      	| train loss (relative): 2.603075e-02 | valid loss (relative): 2.843936e-02 
Epoch 1505 use: 459.00 second.

epoch 1506 starting......
Epoch:  1506 | train loss: 1.333909e-03 | valid loss: 1.457751e-03 
      	| train loss (relative): 2.607524e-02 | valid loss (relative): 2.861007e-02 
Epoch 1506 use: 463.63 second.

epoch 1507 starting......
Epoch:  1507 | train loss: 1.337296e-03 | valid loss: 1.448776e-03 
      	| train loss (relative): 2.613715e-02 | valid loss (relative): 2.838092e-02 
Epoch 1507 use: 509.65 second.

epoch 1508 starting......
Epoch:  1508 | train loss: 1.331496e-03 | valid loss: 1.451017e-03 
      	| train loss (relative): 2.602068e-02 | valid loss (relative): 2.853118e-02 
Epoch 1508 use: 452.86 second.

epoch 1509 starting......
Epoch:  1509 | train loss: 1.330802e-03 | valid loss: 1.453148e-03 
      	| train loss (relative): 2.601044e-02 | valid loss (relative): 2.867833e-02 
Epoch 1509 use: 483.55 second.

epoch 1510 starting......
Epoch:  1510 | train loss: 1.333054e-03 | valid loss: 1.446249e-03 
      	| train loss (relative): 2.605357e-02 | valid loss (relative): 2.833915e-02 
Epoch 1510 use: 451.23 second.

epoch 1511 starting......
Epoch:  1511 | train loss: 1.331227e-03 | valid loss: 1.451923e-03 
      	| train loss (relative): 2.602175e-02 | valid loss (relative): 2.838275e-02 
Epoch 1511 use: 456.27 second.

epoch 1512 starting......
Epoch:  1512 | train loss: 1.333291e-03 | valid loss: 1.452866e-03 
      	| train loss (relative): 2.605413e-02 | valid loss (relative): 2.857210e-02 
Epoch 1512 use: 434.92 second.

epoch 1513 starting......
Epoch:  1513 | train loss: 1.333864e-03 | valid loss: 1.448938e-03 
      	| train loss (relative): 2.606981e-02 | valid loss (relative): 2.835601e-02 
Epoch 1513 use: 458.61 second.

epoch 1514 starting......
Epoch:  1514 | train loss: 1.330128e-03 | valid loss: 1.453808e-03 
      	| train loss (relative): 2.599827e-02 | valid loss (relative): 2.846628e-02 
Epoch 1514 use: 476.44 second.

epoch 1515 starting......
Epoch:  1515 | train loss: 1.331101e-03 | valid loss: 1.443190e-03 
      	| train loss (relative): 2.601482e-02 | valid loss (relative): 2.837402e-02 
Epoch 1515 use: 454.16 second.

epoch 1516 starting......
Epoch:  1516 | train loss: 1.329288e-03 | valid loss: 1.448956e-03 
      	| train loss (relative): 2.598037e-02 | valid loss (relative): 2.856969e-02 
Epoch 1516 use: 481.04 second.

epoch 1517 starting......
Epoch:  1517 | train loss: 1.328295e-03 | valid loss: 1.447589e-03 
      	| train loss (relative): 2.595931e-02 | valid loss (relative): 2.840923e-02 
Epoch 1517 use: 447.15 second.

epoch 1518 starting......
Epoch:  1518 | train loss: 1.331179e-03 | valid loss: 1.448873e-03 
      	| train loss (relative): 2.601728e-02 | valid loss (relative): 2.833470e-02 
Epoch 1518 use: 415.20 second.

epoch 1519 starting......
Epoch:  1519 | train loss: 1.332055e-03 | valid loss: 1.450428e-03 
      	| train loss (relative): 2.603444e-02 | valid loss (relative): 2.833248e-02 
Epoch 1519 use: 419.61 second.

epoch 1520 starting......
Epoch:  1520 | train loss: 1.331738e-03 | valid loss: 1.447469e-03 
      	| train loss (relative): 2.602735e-02 | valid loss (relative): 2.838226e-02 
Epoch 1520 use: 400.31 second.

epoch 1521 starting......
Epoch:  1521 | train loss: 1.330938e-03 | valid loss: 1.453692e-03 
      	| train loss (relative): 2.600946e-02 | valid loss (relative): 2.847528e-02 
Epoch 1521 use: 416.25 second.

epoch 1522 starting......
Epoch:  1522 | train loss: 1.330734e-03 | valid loss: 1.452044e-03 
      	| train loss (relative): 2.600408e-02 | valid loss (relative): 2.840721e-02 
Epoch 1522 use: 396.83 second.

epoch 1523 starting......
Epoch:  1523 | train loss: 1.330033e-03 | valid loss: 1.445828e-03 
      	| train loss (relative): 2.599018e-02 | valid loss (relative): 2.839994e-02 
Epoch 1523 use: 410.82 second.

epoch 1524 starting......
Epoch:  1524 | train loss: 1.326317e-03 | valid loss: 1.447697e-03 
      	| train loss (relative): 2.591878e-02 | valid loss (relative): 2.838877e-02 
Epoch 1524 use: 402.93 second.

epoch 1525 starting......
Epoch:  1525 | train loss: 1.327743e-03 | valid loss: 1.446325e-03 
      	| train loss (relative): 2.594840e-02 | valid loss (relative): 2.828823e-02 
Epoch 1525 use: 400.97 second.

epoch 1526 starting......
Epoch:  1526 | train loss: 1.328055e-03 | valid loss: 1.446963e-03 
      	| train loss (relative): 2.595384e-02 | valid loss (relative): 2.825138e-02 
Epoch 1526 use: 442.63 second.

epoch 1527 starting......
Epoch:  1527 | train loss: 1.330747e-03 | valid loss: 1.454772e-03 
      	| train loss (relative): 2.600579e-02 | valid loss (relative): 2.856579e-02 
Epoch 1527 use: 481.81 second.

epoch 1528 starting......
Epoch:  1528 | train loss: 1.331411e-03 | valid loss: 1.447831e-03 
      	| train loss (relative): 2.601847e-02 | valid loss (relative): 2.834102e-02 
Epoch 1528 use: 428.45 second.

epoch 1529 starting......
Epoch:  1529 | train loss: 1.328951e-03 | valid loss: 1.451034e-03 
      	| train loss (relative): 2.597157e-02 | valid loss (relative): 2.864887e-02 
Epoch 1529 use: 420.51 second.

epoch 1530 starting......
Epoch:  1530 | train loss: 1.329849e-03 | valid loss: 1.447313e-03 
      	| train loss (relative): 2.598833e-02 | valid loss (relative): 2.833242e-02 
Epoch 1530 use: 404.46 second.

epoch 1531 starting......
Epoch:  1531 | train loss: 1.327758e-03 | valid loss: 1.448594e-03 
      	| train loss (relative): 2.594574e-02 | valid loss (relative): 2.822150e-02 
Epoch 1531 use: 416.68 second.

epoch 1532 starting......
Epoch:  1532 | train loss: 1.328384e-03 | valid loss: 1.450223e-03 
      	| train loss (relative): 2.596063e-02 | valid loss (relative): 2.834041e-02 
Epoch 1532 use: 421.43 second.

epoch 1533 starting......
Epoch:  1533 | train loss: 1.327510e-03 | valid loss: 1.450837e-03 
      	| train loss (relative): 2.594298e-02 | valid loss (relative): 2.847729e-02 
Epoch 1533 use: 424.80 second.

epoch 1534 starting......
Epoch:  1534 | train loss: 1.327810e-03 | valid loss: 1.446199e-03 
      	| train loss (relative): 2.594883e-02 | valid loss (relative): 2.834553e-02 
Epoch 1534 use: 419.37 second.

epoch 1535 starting......
Epoch:  1535 | train loss: 1.326097e-03 | valid loss: 1.448242e-03 
      	| train loss (relative): 2.591613e-02 | valid loss (relative): 2.846051e-02 
Epoch 1535 use: 415.85 second.

epoch 1536 starting......
Epoch:  1536 | train loss: 1.326602e-03 | valid loss: 1.446776e-03 
      	| train loss (relative): 2.592750e-02 | valid loss (relative): 2.840858e-02 
Epoch 1536 use: 402.06 second.

epoch 1537 starting......
Epoch:  1537 | train loss: 1.326078e-03 | valid loss: 1.450145e-03 
      	| train loss (relative): 2.591579e-02 | valid loss (relative): 2.836469e-02 
Epoch 1537 use: 414.97 second.

epoch 1538 starting......
Epoch:  1538 | train loss: 1.329120e-03 | valid loss: 1.453506e-03 
      	| train loss (relative): 2.597551e-02 | valid loss (relative): 2.854141e-02 
Epoch 1538 use: 406.08 second.

epoch 1539 starting......
Epoch:  1539 | train loss: 1.329804e-03 | valid loss: 1.448538e-03 
      	| train loss (relative): 2.598780e-02 | valid loss (relative): 2.837721e-02 
Epoch 1539 use: 414.58 second.

epoch 1540 starting......
Epoch:  1540 | train loss: 1.330173e-03 | valid loss: 1.452644e-03 
      	| train loss (relative): 2.599405e-02 | valid loss (relative): 2.848442e-02 
Epoch 1540 use: 410.27 second.

epoch 1541 starting......
Epoch:  1541 | train loss: 1.328755e-03 | valid loss: 1.453035e-03 
      	| train loss (relative): 2.596899e-02 | valid loss (relative): 2.851491e-02 
Epoch 1541 use: 409.03 second.

epoch 1542 starting......
Epoch:  1542 | train loss: 1.330676e-03 | valid loss: 1.448949e-03 
      	| train loss (relative): 2.600727e-02 | valid loss (relative): 2.845404e-02 
Epoch 1542 use: 406.94 second.

epoch 1543 starting......
Epoch:  1543 | train loss: 1.326840e-03 | valid loss: 1.450799e-03 
      	| train loss (relative): 2.593014e-02 | valid loss (relative): 2.846556e-02 
Epoch 1543 use: 407.21 second.

epoch 1544 starting......
Epoch:  1544 | train loss: 1.325424e-03 | valid loss: 1.444589e-03 
      	| train loss (relative): 2.590287e-02 | valid loss (relative): 2.831267e-02 
Epoch 1544 use: 401.62 second.

epoch 1545 starting......
Epoch:  1545 | train loss: 1.324126e-03 | valid loss: 1.444807e-03 
      	| train loss (relative): 2.587572e-02 | valid loss (relative): 2.829916e-02 
Epoch 1545 use: 415.76 second.

epoch 1546 starting......
Epoch:  1546 | train loss: 1.323732e-03 | valid loss: 1.443835e-03 
      	| train loss (relative): 2.586599e-02 | valid loss (relative): 2.837287e-02 
Epoch 1546 use: 390.08 second.

epoch 1547 starting......
Epoch:  1547 | train loss: 1.325778e-03 | valid loss: 1.447337e-03 
      	| train loss (relative): 2.590906e-02 | valid loss (relative): 2.841306e-02 
Epoch 1547 use: 420.58 second.

epoch 1548 starting......
Epoch:  1548 | train loss: 1.326053e-03 | valid loss: 1.446239e-03 
      	| train loss (relative): 2.591470e-02 | valid loss (relative): 2.833644e-02 
Epoch 1548 use: 415.37 second.

epoch 1549 starting......
Epoch:  1549 | train loss: 1.324308e-03 | valid loss: 1.449458e-03 
      	| train loss (relative): 2.587816e-02 | valid loss (relative): 2.834350e-02 
Epoch 1549 use: 424.36 second.

epoch 1550 starting......
Epoch:  1550 | train loss: 1.324742e-03 | valid loss: 1.446887e-03 
      	| train loss (relative): 2.588690e-02 | valid loss (relative): 2.840022e-02 
Epoch 1550 use: 421.14 second.

epoch 1551 starting......
Epoch:  1551 | train loss: 1.325012e-03 | valid loss: 1.448388e-03 
      	| train loss (relative): 2.589309e-02 | valid loss (relative): 2.838948e-02 
Epoch 1551 use: 415.28 second.

epoch 1552 starting......
Epoch:  1552 | train loss: 1.327917e-03 | valid loss: 1.446547e-03 
      	| train loss (relative): 2.595213e-02 | valid loss (relative): 2.840931e-02 
Epoch 1552 use: 394.87 second.

epoch 1553 starting......
Epoch:  1553 | train loss: 1.322516e-03 | valid loss: 1.451478e-03 
      	| train loss (relative): 2.584698e-02 | valid loss (relative): 2.841866e-02 
Epoch 1553 use: 416.81 second.

epoch 1554 starting......
Epoch:  1554 | train loss: 1.326285e-03 | valid loss: 1.446109e-03 
      	| train loss (relative): 2.592129e-02 | valid loss (relative): 2.829638e-02 
Epoch 1554 use: 407.10 second.

epoch 1555 starting......
Epoch:  1555 | train loss: 1.324398e-03 | valid loss: 1.443760e-03 
      	| train loss (relative): 2.588223e-02 | valid loss (relative): 2.824657e-02 
Epoch 1555 use: 412.22 second.

epoch 1556 starting......
Epoch:  1556 | train loss: 1.320308e-03 | valid loss: 1.445436e-03 
      	| train loss (relative): 2.579874e-02 | valid loss (relative): 2.829152e-02 
Epoch 1556 use: 400.47 second.

epoch 1557 starting......
Epoch:  1557 | train loss: 1.320940e-03 | valid loss: 1.443880e-03 
      	| train loss (relative): 2.581406e-02 | valid loss (relative): 2.834749e-02 
Epoch 1557 use: 412.25 second.

epoch 1558 starting......
Epoch:  1558 | train loss: 1.323005e-03 | valid loss: 1.447776e-03 
      	| train loss (relative): 2.585087e-02 | valid loss (relative): 2.831082e-02 
Epoch 1558 use: 406.96 second.

epoch 1559 starting......
Epoch:  1559 | train loss: 1.322880e-03 | valid loss: 1.442228e-03 
      	| train loss (relative): 2.584771e-02 | valid loss (relative): 2.824725e-02 
Epoch 1559 use: 401.04 second.

epoch 1560 starting......
Epoch:  1560 | train loss: 1.321170e-03 | valid loss: 1.442636e-03 
      	| train loss (relative): 2.581733e-02 | valid loss (relative): 2.834483e-02 
Epoch 1560 use: 407.01 second.

epoch 1561 starting......
Epoch:  1561 | train loss: 1.320401e-03 | valid loss: 1.445515e-03 
      	| train loss (relative): 2.580447e-02 | valid loss (relative): 2.838871e-02 
Epoch 1561 use: 404.75 second.

epoch 1562 starting......
Epoch:  1562 | train loss: 1.321857e-03 | valid loss: 1.442196e-03 
      	| train loss (relative): 2.583165e-02 | valid loss (relative): 2.816892e-02 
Epoch 1562 use: 394.25 second.

epoch 1563 starting......
Epoch:  1563 | train loss: 1.321039e-03 | valid loss: 1.442487e-03 
      	| train loss (relative): 2.581413e-02 | valid loss (relative): 2.822772e-02 
Epoch 1563 use: 401.69 second.

epoch 1564 starting......
Epoch:  1564 | train loss: 1.321894e-03 | valid loss: 1.443555e-03 
      	| train loss (relative): 2.582872e-02 | valid loss (relative): 2.837778e-02 
Epoch 1564 use: 416.18 second.

epoch 1565 starting......
Epoch:  1565 | train loss: 1.322866e-03 | valid loss: 1.447652e-03 
      	| train loss (relative): 2.585252e-02 | valid loss (relative): 2.830983e-02 
Epoch 1565 use: 408.73 second.

epoch 1566 starting......
Epoch:  1566 | train loss: 1.321672e-03 | valid loss: 1.447009e-03 
      	| train loss (relative): 2.582823e-02 | valid loss (relative): 2.833802e-02 
Epoch 1566 use: 408.57 second.

epoch 1567 starting......
Epoch:  1567 | train loss: 1.324097e-03 | valid loss: 1.448286e-03 
      	| train loss (relative): 2.587201e-02 | valid loss (relative): 2.828217e-02 
Epoch 1567 use: 418.58 second.

epoch 1568 starting......
Epoch:  1568 | train loss: 1.321556e-03 | valid loss: 1.449465e-03 
      	| train loss (relative): 2.582191e-02 | valid loss (relative): 2.851689e-02 
Epoch 1568 use: 390.63 second.

epoch 1569 starting......
Epoch:  1569 | train loss: 1.323756e-03 | valid loss: 1.447634e-03 
      	| train loss (relative): 2.586409e-02 | valid loss (relative): 2.852271e-02 
Epoch 1569 use: 415.04 second.

epoch 1570 starting......
Epoch:  1570 | train loss: 1.323696e-03 | valid loss: 1.451623e-03 
      	| train loss (relative): 2.586730e-02 | valid loss (relative): 2.856357e-02 
Epoch 1570 use: 405.24 second.

epoch 1571 starting......
Epoch:  1571 | train loss: 1.322436e-03 | valid loss: 1.446511e-03 
      	| train loss (relative): 2.583979e-02 | valid loss (relative): 2.840052e-02 
Epoch 1571 use: 392.70 second.

epoch 1572 starting......
Epoch:  1572 | train loss: 1.319723e-03 | valid loss: 1.443500e-03 
      	| train loss (relative): 2.579028e-02 | valid loss (relative): 2.840696e-02 
Epoch 1572 use: 384.35 second.

epoch 1573 starting......
Epoch:  1573 | train loss: 1.320413e-03 | valid loss: 1.447439e-03 
      	| train loss (relative): 2.580005e-02 | valid loss (relative): 2.832167e-02 
Epoch 1573 use: 399.78 second.

epoch 1574 starting......
Epoch:  1574 | train loss: 1.322166e-03 | valid loss: 1.449867e-03 
      	| train loss (relative): 2.583561e-02 | valid loss (relative): 2.845937e-02 
Epoch 1574 use: 401.70 second.

epoch 1575 starting......
Epoch:  1575 | train loss: 1.322588e-03 | valid loss: 1.445817e-03 
      	| train loss (relative): 2.584254e-02 | valid loss (relative): 2.831759e-02 
Epoch 1575 use: 405.93 second.

epoch 1576 starting......
Epoch:  1576 | train loss: 1.319154e-03 | valid loss: 1.453275e-03 
      	| train loss (relative): 2.577471e-02 | valid loss (relative): 2.863339e-02 
Epoch 1576 use: 387.22 second.

epoch 1577 starting......
Epoch:  1577 | train loss: 1.323758e-03 | valid loss: 1.444638e-03 
      	| train loss (relative): 2.586791e-02 | valid loss (relative): 2.825388e-02 
Epoch 1577 use: 406.99 second.

epoch 1578 starting......
Epoch:  1578 | train loss: 1.319646e-03 | valid loss: 1.444208e-03 
      	| train loss (relative): 2.578363e-02 | valid loss (relative): 2.836671e-02 
Epoch 1578 use: 387.59 second.

epoch 1579 starting......
Epoch:  1579 | train loss: 1.318521e-03 | valid loss: 1.442241e-03 
      	| train loss (relative): 2.576568e-02 | valid loss (relative): 2.818689e-02 
Epoch 1579 use: 411.69 second.

epoch 1580 starting......
Epoch:  1580 | train loss: 1.317877e-03 | valid loss: 1.440607e-03 
      	| train loss (relative): 2.574928e-02 | valid loss (relative): 2.819739e-02 
Epoch 1580 use: 396.35 second.

epoch 1581 starting......
Epoch:  1581 | train loss: 1.317233e-03 | valid loss: 1.449083e-03 
      	| train loss (relative): 2.573834e-02 | valid loss (relative): 2.845250e-02 
Epoch 1581 use: 402.59 second.

epoch 1582 starting......
Epoch:  1582 | train loss: 1.322653e-03 | valid loss: 1.446960e-03 
      	| train loss (relative): 2.584510e-02 | valid loss (relative): 2.825273e-02 
Epoch 1582 use: 394.58 second.

epoch 1583 starting......
Epoch:  1583 | train loss: 1.320854e-03 | valid loss: 1.446468e-03 
      	| train loss (relative): 2.580963e-02 | valid loss (relative): 2.830070e-02 
Epoch 1583 use: 408.37 second.

epoch 1584 starting......
Epoch:  1584 | train loss: 1.319669e-03 | valid loss: 1.445411e-03 
      	| train loss (relative): 2.578554e-02 | valid loss (relative): 2.839793e-02 
Epoch 1584 use: 397.50 second.

epoch 1585 starting......
Epoch:  1585 | train loss: 1.320148e-03 | valid loss: 1.451125e-03 
      	| train loss (relative): 2.579680e-02 | valid loss (relative): 2.858361e-02 
Epoch 1585 use: 400.48 second.

epoch 1586 starting......
Epoch:  1586 | train loss: 1.323114e-03 | valid loss: 1.443096e-03 
      	| train loss (relative): 2.585262e-02 | valid loss (relative): 2.830276e-02 
Epoch 1586 use: 395.06 second.

epoch 1587 starting......
Epoch:  1587 | train loss: 1.320215e-03 | valid loss: 1.446981e-03 
      	| train loss (relative): 2.579877e-02 | valid loss (relative): 2.839326e-02 
Epoch 1587 use: 422.57 second.

epoch 1588 starting......
Epoch:  1588 | train loss: 1.320492e-03 | valid loss: 1.450717e-03 
      	| train loss (relative): 2.580264e-02 | valid loss (relative): 2.840111e-02 
Epoch 1588 use: 392.77 second.

epoch 1589 starting......
Epoch:  1589 | train loss: 1.321212e-03 | valid loss: 1.447512e-03 
      	| train loss (relative): 2.581712e-02 | valid loss (relative): 2.850290e-02 
Epoch 1589 use: 396.60 second.

epoch 1590 starting......
Epoch:  1590 | train loss: 1.319791e-03 | valid loss: 1.449474e-03 
      	| train loss (relative): 2.579346e-02 | valid loss (relative): 2.833473e-02 
Epoch 1590 use: 403.55 second.

epoch 1591 starting......
Epoch:  1591 | train loss: 1.321312e-03 | valid loss: 1.449621e-03 
      	| train loss (relative): 2.582208e-02 | valid loss (relative): 2.840191e-02 
Epoch 1591 use: 396.07 second.

epoch 1592 starting......
Epoch:  1592 | train loss: 1.322195e-03 | valid loss: 1.448344e-03 
      	| train loss (relative): 2.583816e-02 | valid loss (relative): 2.847333e-02 
Epoch 1592 use: 398.46 second.

epoch 1593 starting......
Epoch:  1593 | train loss: 1.321658e-03 | valid loss: 1.456481e-03 
      	| train loss (relative): 2.582501e-02 | valid loss (relative): 2.851433e-02 
Epoch 1593 use: 397.55 second.

epoch 1594 starting......
Epoch:  1594 | train loss: 1.324869e-03 | valid loss: 1.449886e-03 
      	| train loss (relative): 2.589041e-02 | valid loss (relative): 2.827332e-02 
Epoch 1594 use: 405.60 second.

epoch 1595 starting......
Epoch:  1595 | train loss: 1.321028e-03 | valid loss: 1.441822e-03 
      	| train loss (relative): 2.581115e-02 | valid loss (relative): 2.820810e-02 
Epoch 1595 use: 419.12 second.

epoch 1596 starting......
Epoch:  1596 | train loss: 1.317924e-03 | valid loss: 1.445042e-03 
      	| train loss (relative): 2.575154e-02 | valid loss (relative): 2.821942e-02 
Epoch 1596 use: 403.06 second.

epoch 1597 starting......
Epoch:  1597 | train loss: 1.318417e-03 | valid loss: 1.443116e-03 
      	| train loss (relative): 2.576438e-02 | valid loss (relative): 2.826040e-02 
Epoch 1597 use: 413.02 second.

epoch 1598 starting......
Epoch:  1598 | train loss: 1.317504e-03 | valid loss: 1.448005e-03 
      	| train loss (relative): 2.574558e-02 | valid loss (relative): 2.849984e-02 
Epoch 1598 use: 397.86 second.

epoch 1599 starting......
Epoch:  1599 | train loss: 1.318763e-03 | valid loss: 1.453218e-03 
      	| train loss (relative): 2.577114e-02 | valid loss (relative): 2.879308e-02 
Epoch 1599 use: 410.33 second.

epoch 1600 starting......
Epoch:  1600 | train loss: 1.319583e-03 | valid loss: 1.444564e-03 
      	| train loss (relative): 2.578535e-02 | valid loss (relative): 2.835614e-02 
Epoch 1600 use: 384.48 second.

test MSE Error: 1.427803e-03 | relative MSE Error: 2.798218e-02 
 Total time used for training: 17.70 hour.
MESLoss saved to  /rds/general/user/jy220/home/new_results/Variational_False_Changelr_False_MSELoss_Latent_256_nearest_neighbouring_True_SFC_nums_3_startlr_0.001_n_epoches_1601.txt
relative MSELoss saved to  /rds/general/user/jy220/home/new_results/Variational_False_Changelr_False_reMSELoss_Latent_256_nearest_neighbouring_True_SFC_nums_3_startlr_0.001_n_epoches_1601.txt
model saved to /rds/general/user/jy220/home/new_results/Variational_False_Changelr_False_Latent_256_Nearest_neighbouring_True_SFC_nums_3_startlr_0.001_n_epoches_1601.pth
model_dict saved to /rds/general/user/jy220/home/new_results/Variational_False_Changelr_False_Latent_256_Nearest_neighbouring_True_SFC_nums_3_startlr_0.001_n_epoches_1601_dict.pth
... Training slugflow data completed, Run finished Thu 26 Aug 03:04:45 BST 2021 ...
